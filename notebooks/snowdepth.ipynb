{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5185c84",
   "metadata": {},
   "source": [
    "# Snow Depth Applications\n",
    "\n",
    "## Author(s)\n",
    "\n",
    "Karina Zikan, Zach Fair\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "* Gain experience in working with SlideRule to access and pre-process ICESat-2 \n",
    "data\n",
    "* Learn how to use projections and interpolation to compare ICESat-2 track data \n",
    "with gridded raster products\n",
    "* Develop a general understanding of how to measure snow depths with LiDAR, \n",
    "and learn about opportunities and challenges when using ICEsat-2 along-track\n",
    "products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4cf5af",
   "metadata": {},
   "source": [
    "## Background\n",
    "### How do we measure snow depth with LiDAR?\n",
    "LiDAR is a useful tool for collecting high resolution snow depth maps over large spatial areas.\n",
    "\n",
    "Snow depth is measured from LiDAR by differencing a snow-free LiDAR map from a snow-covered LiDAR map of the same area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06a484-5889-4969-9461-befce113422f",
   "metadata": {},
   "source": [
    "TODO: Insert Figure 6 from Deems et al. here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fb7f5-3a2e-4764-bebc-205e5a31caca",
   "metadata": {},
   "source": [
    "TODO: Insert Figure 7b from Deems et al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748c3f4-54f4-4fe1-a2a4-53b256b9c24d",
   "metadata": {},
   "source": [
    "### Can we do this with ICESat-2?\n",
    "Yes! By differencing snow-covered ICESat-2 transects from snow-free maps, we can calculate snow depth!\n",
    "\n",
    "Performing the calculation with ICESat-2 is a little different from other LiDAR snow depth methods, given that ICESat-2 is a transect of points rather than gridded raster data. ICESat-2 also has sparse coverage in the mid-latitudes, so generating an effective snow-covered or snow-free map will be difficult.\n",
    "\n",
    "Because of these limitations, we need an independently-collected snow-free map of a region of interest for comparison. We also need to process the snow-free data into a form that can be differenced from snow-on ICESat-2 data.\n",
    "\n",
    "In this tutorial, we will show an example of how to compare ICESat-2 data to raster data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff79cf-0ee9-46a6-9f00-d36a1713403b",
   "metadata": {},
   "source": [
    "TODO: Add Karina's image over Dry Creek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c2599-af50-4e2d-9a58-f51412df941c",
   "metadata": {},
   "source": [
    "### What do we need to calculate snow depth from ICESat-2?\n",
    "1. A region of interest, where snow-free (and snow-covered, for validation) digital elevation models (DEMs) are available.\n",
    "2. ICESat-2 data, ideally from one of the lower-level products (ATL03, ATL06, ATL08, Sliderule Earth).\n",
    "3. A snow-free reference DEM for the snow depth calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93692296-f89a-49b1-b785-a3dc6371ad01",
   "metadata": {},
   "source": [
    "### What do we need to consider when comparing ICESat-2 and raster data?\n",
    "**Geolocation**: To obtain usable results, it is important that we properly align the snow-free raster data with ICESat-2. Even small offsets can create large errors that worsen in rugged terrain.\n",
    "\n",
    "TODO: Add Figure 9 from Nuth and Kabb\n",
    "\n",
    "**Vegetation**: Incorrectly categorized vegetation returns can positively bias ground or snow surface height estimation. Additionally, dense vegetation can reduce the number of photon returns, thereby increasing uncertainty in our height estimates.\n",
    "\n",
    "**Slope Effects**: Rugged terrain increases uncertainty in ICESat-2 returns and increases the impact of geolocation offsets between ICESat-2 and raster data. Additionally, steep slopes can negatively bias ground or snow surface height estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4c1f0-3aac-4da9-b8d9-93692716675b",
   "metadata": {},
   "source": [
    "### Computing Environment\n",
    "We'll be using the following open source Python libraries in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5120c0-3d53-4023-96e7-469b7b536287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "from sliderule import icesat2, sliderule\n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd689c-5db6-4ef7-a610-d20141e6304e",
   "metadata": {},
   "source": [
    "### Data\n",
    "We will use SlideRule to acquire customized ATL06 data. Specific customizations that we will implement include footprint averaging (i.e., along-track sampling rate) and photon identification (signal/noise and ground/vegetation).\n",
    "\n",
    "We will look at snow depth data over Upper Kuparuk/Toolik (UKT) on the Arctic North Slope of Alaska. Because UKT is a relatively flat region with little vegetation, we should expect good agreement between ICESat-2 and our rasters of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c909d-98e7-440d-bf1f-f81164a6b505",
   "metadata": {},
   "source": [
    "### Initialize SlideRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e880a-4092-4be0-a642-fd3f21cb9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "icesat2.init(\"slideruleearth.io\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d6a1e-e4ca-44e9-8ca2-f89d3cdc8713",
   "metadata": {},
   "source": [
    "### Define Region of Interest\n",
    "After we initialize SlideRule, we define our region of interest. Notice that there are two options given below. This is because SlideRule accepts either the coordinates of a box/polygon or a geoJSON for its `region` input.\n",
    "\n",
    "We are going to use the bounding box method in this tutorial, but the syntax for the geoJSON method is included for the user's reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c278dc-90a9-4d37-a2b6-807648450001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define region of interest over Toolik, Alaska\n",
    "region = [{\"lon\":-149.5992624418217, \"lat\":68.63358948385529}, \n",
    "          {\"lon\":-149.5954459662985, \"lat\":68.60200878043223}, \n",
    "          {\"lon\":-149.2821268688734, \"lat\":68.60675802967609}, \n",
    "          {\"lon\":-149.2855031235162, \"lat\":68.63834638180673},\n",
    "          {\"lon\":-149.5992624418217, \"lat\":68.63358948385529}]\n",
    "\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3593b-10e5-4c75-bb0d-d9b1fe64e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate method, with geoJSON\n",
    "path = \"/path/to/geojson/\"\n",
    "region = sliderule.toregion(path)[\"poly\"]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22c263-018a-49ce-ad8d-a068f6d7f674",
   "metadata": {},
   "source": [
    "### Build SlideRule Request\n",
    "Now we are going to build our SlideRule request by defining ICESat-2 parameters.\n",
    "\n",
    "Since we want something close to the ATL06 product, we will use the `icesat2.atl06p()` function in this tutorial. You can find other SlideRule functions and more detail on the `icesat2.atl06p()` function on the SlideRule API reference. (TODO: Add link to API reference)\n",
    "\n",
    "We won't use every parameter in this tutorial, but here is a reference list for some of them. More information can be found in the SlideRule users guide (TODO: Add link to users guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9224a-951c-46a5-a3c5-ffc53673beeb",
   "metadata": {},
   "source": [
    "```{note}\n",
    "**Parameters**\n",
    "* `poly`: Polygon defining region of interest.\n",
    "* `track`: Reference pair track number (1, 2, 3; 0 to include all three; defaults to 0).\n",
    "* `rgt`: Reference ground track (defaults to all).\n",
    "* `cycle`: Counter of 91-day repeat cycles completed by the mission (defaults to all).\n",
    "* `region`: Geographic region for data product (defaults to global).\n",
    "* `t0`: Start time for filtering granules (%Y-%m%dT%h:%M:%SZ format)\n",
    "* `t1`: Stop time for filtering granules (%Y-%m%dT%h:%M:%SZ format).\n",
    "* `srt`: Surface type (0=land, 1=ocean, 2=sea ice, 3=land ice, 4=inland water).\n",
    "* `cnf`: Confidence level for photon selection, in integer or list format.\n",
    "* `atl08_class`: List of ATL08 classifications for photon processing (â€œatl08_noiseâ€, â€œatl08_groundâ€, â€œatl08_canopyâ€, â€œatl08_top_of_canopyâ€, â€œatl08_unclassifiedâ€).\n",
    "* `maxi`: Maximum interations of algorithm, not including initial least-squares-fit selection.\n",
    "* `H_min_win`: Minimum height to which the refined photon-selection window is allowed to shrink, in meters.\n",
    "* `sigma_r_max`: Maximum robust spread (uncertainty) in meters.\n",
    "* `compact`: Return results without most metadata.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e23387-724b-4f1d-8215-86932936a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build SlideRule request\n",
    "# Define parameters (described below)\n",
    "parms = {\n",
    "    \"poly\": region,\n",
    "    \"srt\": icesat2.SRT_LAND,\n",
    "    \"cnf\": icesat2.CNF_SURFACE_HIGH,\n",
    "    \"atl08_class\": [\"atl08_ground\"],\n",
    "    \"ats\": 5.0,\n",
    "    \"len\": 20.0,\n",
    "    \"res\": 10.0,\n",
    "    \"maxi\": 5\n",
    "}\n",
    "\n",
    "# Calculated ATL06 dataframe\n",
    "is2_df = icesat2.atl06p(parms)\n",
    "\n",
    "# Print SlideRule output\n",
    "print(is2_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17ec8e-e5b0-4ce8-9b6a-8c498bde6699",
   "metadata": {},
   "source": [
    "```{note}\n",
    "We defined our `region` above, so let's run through the remaining parameters in our query:\n",
    "\n",
    "* `srt`: Only land photons will be considered.\n",
    "* `cnf`: Only high-confidence photons.\n",
    "* `atl08_class`: Only ground photons, as identified by the ATL08 algorithm.\n",
    "* `ats`: The maximum along-track spread (uncertainty) in aggregated photons will be 5 m.\n",
    "* `len`: The length of each segment of aggregated photons will be 20 m.\n",
    "* `res`: The along-track resolution will be 10 m. Because each segment will be 20 m long, there will be overlap between successive data points.\n",
    "* `maxi`: The SlideRule refinement algorithm will iterate 5 times per segment at maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb509b-2845-41a3-b4c7-2053cc7892da",
   "metadata": {},
   "source": [
    "### Subsetting the Data\n",
    "\n",
    "One may notice that the algorithm took a long time to generate the GeoDataFrame. That is because (i) our region of interest was rather large and (ii) we obtained all ICESat-2 tracks in the ROI since its launch (2018).\n",
    "\n",
    "For the sake of interest, let's take a look at all of the ICESat-2 tracks over Upper Kuparuk/Toolik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db796d-c125-4f5b-b01f-a9d1a0f629ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Convert region to a Polygon\n",
    "coords = [(point[\"lon\"], point[\"lat\"]) for point in region]\n",
    "polygon = Polygon(coords)\n",
    "region_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=\"EPSG:4326\")\n",
    "\n",
    "# Reproject to Web Mercator for contextily\n",
    "is2_df_mercator = is2_df.to_crs(epsg=3857)\n",
    "region_mercator = region_gdf.to_crs(epsg=3857)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Plot surface height\n",
    "is2_df_mercator.plot(column='h_mean', \n",
    "                  ax=ax, \n",
    "                  cmap='viridis',\n",
    "                  legend=True,\n",
    "                  markersize=10,\n",
    "                  alpha=0.8)\n",
    "\n",
    "# Plot the region bounding box\n",
    "region_mercator.plot(ax=ax, \n",
    "                     facecolor='none', \n",
    "                     edgecolor='red', \n",
    "                     linewidth=2)\n",
    "\n",
    "# Add ESRI World Imagery basemap\n",
    "ctx.add_basemap(ax, \n",
    "                crs=is2_df_mercator.crs, \n",
    "                source=ctx.providers.Esri.WorldImagery)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031f5e0-b026-4b35-8688-4841ced576c0",
   "metadata": {},
   "source": [
    "It is cool to see all of the available data, but we only have snow-free lidar DEMs available from March 2022. So, we are going to subset the data to include one ICESat-2 track (**RGT 152**) in **March 2023**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adc2b8-d124-4b5a-b5a2-fc952d45dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset ICESat-2 data to single RGT, time of year\n",
    "is2_df_subset = is2_df[is2_df['rgt']==152]\n",
    "is2_df_subset = is2_df_subset.loc['2023-03-31']\n",
    "\n",
    "# Display top of dataframe\n",
    "print(is2_df_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796181f-3001-4958-8c5c-8040cd00e982",
   "metadata": {},
   "source": [
    "## Sample the Lidar DTM to ICESat-2 ground track\n",
    "\n",
    "The ICESat-2 data is ready to go! Now it's time to load the airborne lidar data, and co-register it with ICESat-2.\n",
    "\n",
    "The lidar data used here is from the University of Alaska, Fairbanks (UAF). The UAF lidar obtains snow-on and snow-off DEMs/digital terrain models (DTMs) with a 1064 nm (near-infrared) laser, from which it can also derive snow depth.\n",
    "\n",
    "The method currently presented uses `earthaccess` to stream the data without any download required. UAF lidar rasters normally have a spatial resolution of 0.5 m, so this process can be slow on a local machine, and may be memory-intensive on a cloud environment. A more streamlined workflow utilizing the SnowEx Database is in the works, though the given method is most effective for non-SnowEx DEM sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8480c-e2fd-4961-8880-eafada9e6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "earthaccess.login(strategy='interactive', persist=True)\n",
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86387ca1-2f69-463b-b4f1-63f3ff8e59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for SW/NE corners\n",
    "lon_min = min([coord[0] for coord in coords])\n",
    "lat_min = min([coord[1] for coord in coords])\n",
    "lon_max = max([coord[0] for coord in coords])\n",
    "lat_max = max([coord[1] for coord in coords])\n",
    "\n",
    "# Data query for lidar snow depth over Fairbanks, AK\n",
    "results = earthaccess.search_data(\n",
    "    short_name='SNEX23_Lidar',\n",
    "    bounding_box = (lon_min, lat_min, lon_max, lat_max),\n",
    "    temporal = ('2023-03-13', '2023-03-14')\n",
    ")\n",
    "\n",
    "files = earthaccess.open(results)\n",
    "lidar_snow_on = xr.open_dataset(files[1], engine='rasterio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115c925-25aa-4ab0-96c4-8ca51fc941fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data query for lidar snow-off elevation over Fairbanks, AK\n",
    "results = earthaccess.search_data(\n",
    "    short_name='SNEX23_Lidar',\n",
    "    bounding_box = (lon_min, lat_min, lon_max, lat_max),\n",
    "    temporal = ('2022-05-20', '2022-05-31')\n",
    ")\n",
    "\n",
    "# Open the resulting GeoTiff into Xarray\n",
    "files = earthaccess.open(results)\n",
    "lidar_snow_off = xr.open_dataset(files[1], engine='rasterio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a3d92-5bb3-4a3c-88c6-c0ec894d25e4",
   "metadata": {},
   "source": [
    "It is not immediately obvious, but the UAF rasters are in a different spatial projection than ICESat-2. UAF is in **EPSG:32606**, and ICESat-2 is in **WGS84/EPSG:4326**.\n",
    "\n",
    "In order to directly compare these two datasets, we are going to add reprojected coordinates to the ICESat-2 GeoDataFrame. In essence, we will go from **latitude/longitude** to **northing/easting**. Luckily, there is an easy way to do this with GeoPandas, specifically with the `geopandas.to_crs()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d275f-3dd6-4b05-a92e-bddc6bf7676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ICESat-2 coordinate projection\n",
    "is2_df_subset = is2_df_subset.set_crs(\"EPSG:4326\")\n",
    "\n",
    "# Change to EPSG:32606\n",
    "is2_df_subset = is2_df_subset.to_crs(\"EPSG:32606\")\n",
    "\n",
    "# Display top of dataframe\n",
    "print(is2_df_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7767b94-d638-409f-aadb-28c7cbd03218",
   "metadata": {},
   "source": [
    "### Co-register rasters and ICESat-2\n",
    "Now, we are going to co-register both rasters to the queried ICESat-2 data. The function below is fairly long, but the gist is that we a re using a spline interpolant to match both the snow-off UAF data (surface height) and UAF snow depths with ICESat-2 surface heights. The resulting GeoDataFrame will have both ICESat-2 and UAF data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04796d9f-7a6d-4ba9-a167-b68085a81b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make coregistration function\n",
    "def coregister_is2(lidar_snow_off, lidar_snow_on, is2_df):\n",
    "    \"\"\"\n",
    "    Co-registers UAF data with ICESat-2 data with a rectangular \n",
    "    bivariate spline.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    lidar_snow_off: rioxarray dataset\n",
    "        Lidar DEM/DTM in rioxarray format.\n",
    "    lidar_snow_on: rioxarray dataset\n",
    "        Lidar-derived snow depth in rioxarray format.\n",
    "    is2_df: GeodataFrame\n",
    "        GeoDataFrame for the ICESat-2 data generated with SlideRule.\n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    is2_uaf_df: GeoDataFrame\n",
    "        Contains the coordinate and elevation data that matches best\n",
    "        between ICESat-2 and UAF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Helper function to prepare lidar data\n",
    "    def prepare_lidar_data(raster):\n",
    "        coords_x = np.array(raster.x)\n",
    "        coords_y = np.array(raster.y)\n",
    "        values = np.array(raster.sel(band=1))[::-1, :]\n",
    "        values[np.isnan(values)] = -9999\n",
    "        return coords_x, coords_y, values\n",
    "\n",
    "    # Get coordinates and height/depth values from lidar data\n",
    "    x0, y0, dem_heights = prepare_lidar_data(lidar_snow_off)\n",
    "    xs, ys, dem_depths = prepare_lidar_data(lidar_snow_on)\n",
    "\n",
    "    # Generate interpolators\n",
    "    interp_height = RectBivariateSpline(y0[::-1], x0, dem_heights)\n",
    "    interp_height = RectBivariateSpline(ys[::-1], xs, dem_depths)\n",
    "\n",
    "    # Pre-filter IS2 data to bounds (apply once instead of per beam)\n",
    "    x_bounds = (is2_df.geometry.x > np.min(x0)) & (is2_df.geometry.x < np.max(x0))\n",
    "    y_bounds = (is2_df.geometry.y > np.min(y0)) & (is2_df.geometry.y < np.max(y0))\n",
    "    is2_filtered = is2_df[x_bounds & y_bounds].copy()\n",
    "\n",
    "    if is2_filtered.empty:\n",
    "        print('Error with GeoDataFrame or raster bounds.')\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "    # Extract coordinates once\n",
    "    xn = is2_filtered.geometry.x.values\n",
    "    yn = is2_filtered.geometry.y.values\n",
    "\n",
    "    # Estimate lidar height and snow depth at the ICESat-2 coordinates\n",
    "    lidar_heights = interp_height(yn, xn, grid=False)\n",
    "    lidar_snow_depths = interp_depth(yn, xn, grid=False)\n",
    "\n",
    "    # Create result DataFrame in one operation\n",
    "    is2_uaf_df = gpd.GeoDataFrame({\n",
    "        'x': xn,\n",
    "        'y': yn,\n",
    "        'time': is2_filtered.index.values,\n",
    "        'beam': is2_filtered['gt'].values,\n",
    "        'lidar_height': lidar_heights,\n",
    "        'lidar_snow_depth': lidar_snow_depths,\n",
    "        'is2_height': is2_filtered['h_mean'].values,\n",
    "        'h_sigma': is2_filtered['h_sigma'].values,\n",
    "        'dh_fit_dx': is2_filtered['dh_fit_dx'].values\n",
    "    })\n",
    "\n",
    "    # Add coordinate transformation\n",
    "    transformer = Transformer.from_crs(\"EPSG:32606\", \"EPSG:4326\", always_xy=True)\n",
    "    is2_uaf_df['lon'], is2_uaf_df['lat'] = transformer.transform(\n",
    "        is2_uaf_df['x'], is2_uaf_df['y']\n",
    "    )\n",
    "\n",
    "    return is2_uaf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8491b9-d66e-44ae-aa04-eae83357c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-locate ICESat-2 and UAF using the above function\n",
    "is2_uaf_df = coregister_is2(lidar_snow_off, \n",
    "                            lidar_snow_on, \n",
    "                            is2_df_subset\n",
    "                           )\n",
    "# Convert to a GeoDataFrame\n",
    "geom = gpd.points_from_xy(is2_uaf_df.lon, is2_uaf_df.lat)\n",
    "is2_uaf_gdf = gpd.GeoDataFrame(is2_uaf_df,\n",
    "                               geometry=geom,\n",
    "                               crs=\"EPSG:4326\"\n",
    "                              )\n",
    "# Print head of GeoDataFrame\n",
    "is2_uaf_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80786a-8d31-48a0-8fab-69cea47b4b59",
   "metadata": {},
   "source": [
    "As one can see, we now have a GeoDataFrame that includes several useful variables:\n",
    "* `beam`: ICESat-2 beam (gt1l, gt2l, etc.)\n",
    "* `lidar_height`: Snow-off surface height from UAF lidar.\n",
    "* `lidar_snow_depth`: Snow depth derived from UAF.\n",
    "* `is2_height`: ICESat-2 surface height (snow-on, in this case).\n",
    "* `h_sigma`: ICESat-2 height uncertainty.\n",
    "* `dh_fit_dx`: Along-track slope of the terrain.\n",
    "\n",
    "With this GeoDataFrame, it is very simple to derive snow depth!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0de535-4bda-4066-92c1-c4d9c90240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive snow depth using snow-on/snow-off differencing\n",
    "is2_uaf_gdf['is2_snow_depth'] = is2_uaf_gdf['is2_height'] - is2_uaf_gdf['lidar_height']\n",
    "\n",
    "# Estimate the residual (bias) between IS-2 and UAF depths\n",
    "is2_uaf_gdf['snow_depth_residual'] = is2_uaf_gdf['is2_snow_depth'] - is2_uaf_gdf['lidar_snow_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e8609-9909-4df0-ab85-38e4f62e9157",
   "metadata": {},
   "source": [
    "Horray! We finally have ICESat-2 snow depths! Let's make a couple of plots with the data we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff95f6-6763-431e-8bee-910220812e1e",
   "metadata": {},
   "source": [
    "### Map Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457a20e-657f-48b7-9418-ea0860a06922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# Plot surface height\n",
    "is2_uaf_gdf.to_crs(\"EPSG:3857\").plot(column='is2_snow_depth', \n",
    "                  ax=ax, \n",
    "                  cmap='viridis',\n",
    "                  legend=True,\n",
    "                  markersize=10,\n",
    "                  alpha=0.8)\n",
    "\n",
    "# Plot the region bounding box\n",
    "region_mercator.plot(ax=ax, \n",
    "                     facecolor='none', \n",
    "                     edgecolor='red', \n",
    "                     linewidth=2)\n",
    "\n",
    "# Add ESRI World Imagery basemap\n",
    "ctx.add_basemap(ax, \n",
    "                crs=\"EPSG:3857\", \n",
    "                source=ctx.providers.Esri.WorldImagery)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf48acec-060a-4eff-b3d2-763e52bcae20",
   "metadata": {},
   "source": [
    "### Along-track plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710356d6-b246-4439-8524-a429d0bea50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot snow depths for the three strong beams\n",
    "fig,axs = plt.subplots(3)\n",
    "\n",
    "#Left strong beam\n",
    "tmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==10]\n",
    "axs[0].plot(tmp_df['lat'], tmp_df['is2_snow_depth'], label='ICESat-2')\n",
    "axs[0].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'], label='UAF')\n",
    "axs[0].set_title('gt1l')\n",
    "axs[0].legend()\n",
    "\n",
    "# Central strong beam\n",
    "tmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==30]\n",
    "axs[1].plot(tmp_df['lat'], tmp_df['is2_snow_depth'])\n",
    "axs[1].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'])\n",
    "axs[1].set_ylabel('Snow depth [m]', fontsize=18)\n",
    "axs[1].set_title('gt2l')\n",
    "\n",
    "# Right strong beam\n",
    "tmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==50]\n",
    "axs[2].plot(tmp_df['lat'], tmp_df['is2_snow_depth'])\n",
    "axs[2].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'])\n",
    "axs[2].set_xlabel('Latitude [m]', fontsize=18)\n",
    "axs[2].set_title('gt3l')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Only include outer axis labels\n",
    "for ax in axs:\n",
    "    ax.label_outer()\n",
    "    ax.set_ylim([0, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7bd9a1-37c9-400b-8831-571227eab6ae",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf06a63-9331-486c-a156-df3d51dce630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "s = is2_uaf_gpd.plot.scatter(ax=ax,\n",
    "                             x='lidar_snow_depth',\n",
    "                             y='is2_snow_depth',\n",
    "                             c='snow_depth_residual',\n",
    "                             vmin=-0.5, vmax=0.5\n",
    "                            )\n",
    "ax.set_xlabel(\"UAF snow depth [m]\", fontsize=18)\n",
    "ax.set_ylabel(\"ICESat-2 snow depth [m]\", fontsize=18)\n",
    "ax.set_xlim([0, 1.5])\n",
    "ax.set_ylim([0, 1.5])\n",
    "cbar = fig.colorbar(s, ax=ax)\n",
    "cbar.set_label(\"Snow depth residual [m]\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3062e27-df81-4700-a5c0-cb7f3143f6fe",
   "metadata": {},
   "source": [
    "## Summary\n",
    "ğŸ‰ Congratulations! You have completed this tutorial and have seen how to compare ICESat-2 to raster data, how to obtain ICESat-2 data with SlideRule, and how to calculate snow depths from ICESat-2 data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a631f2-0fbe-418f-8c12-5cfa7e46fc0b",
   "metadata": {},
   "source": [
    "## Reference\n",
    "To further explore the topics of this tutorial, see the following detailed documentation: (TODO: ADD LINKS TO SITES AND PAPERS)\n",
    "* SlideRule Website\n",
    "* SlideRule online demo\n",
    "\n",
    "### Papers\n",
    "Deems, Jeffrey S., et al. â€œLidar Measurement of Snow Depth: A Review.â€ Journal of Glaciology, vol. 59, no. 215, 2013, pp. 467â€“79. DOI.org (Crossref), https://doi.org/10.3189/2013JoG12J154.\n",
    "\n",
    "Nuth, C., and A. KÃ¤Ã¤b. â€œCo-Registration and Bias Corrections of Satellite Elevation Data Sets for Quantifying Glacier Thickness Change.â€ The Cryosphere, vol. 5, no. 1, Mar. 2011, pp. 271â€“90. DOI.org (Crossref), https://doi.org/10.5194/tc-5-271-2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070c25a-16ef-4a3e-9980-7e3cb2de6d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
