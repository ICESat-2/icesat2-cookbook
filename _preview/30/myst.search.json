{"version":"1","records":[{"hierarchy":{"lvl1":"ICESat-2 Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"ICESat-2 Cookbook"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"ICESat-2 Cookbook"},"type":"lvl1","url":"/#icesat-2-cookbook","position":2},{"hierarchy":{"lvl1":"ICESat-2 Cookbook"},"content":"\n\n\n\n\n\n\n\nThis Project Pythia Cookbook is a compilation of tutorials developed from 2019\nto present as part of the NASA / UW eScience hackweek program. The purpose of\nthe tutorials is to help people with data access and to demonstrate a variety\nof disciplinary use cases.","type":"content","url":"/#icesat-2-cookbook","position":3},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":4},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Motivation"},"content":"The ICESat-2 mission provides valuable data for measuring changes in glaciers,\nice sheets, sea ice, clouds and land surface systems. There are numerous data\nproducts and methods for accessing and analyzing data. The goal of these\ntutorials is to streamline data access, reduce duplication of effort and\nbuild an open science community around ICESat-2 algorithms and software.","type":"content","url":"/#motivation","position":5},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":6},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Authors"},"content":"Ben Smith,\n\n\nMichalea King,\n\n\nTyler Sutterley,\n\n\nAnthony Arendt,\n\n\nJessica Scheick,\n\n\nMark Welden-Smith\n\nmore to be added","type":"content","url":"/#authors","position":7},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":8},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":9},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":10},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two main sections - “Foundations”\nand “Example Workflows.”","type":"content","url":"/#structure","position":11},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Section 1: Foundations","lvl2":"Structure"},"type":"lvl3","url":"/#section-1-foundations","position":12},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Section 1: Foundations","lvl2":"Structure"},"content":"Mission Overview\n\nData Access\n\nFiltering\n\nGeospatial Transforms\n\nIntegration\n\nCloud Computing\n\nMachine Learning\n\nVisualization","type":"content","url":"/#section-1-foundations","position":13},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Section 2: Example Workflows for Specific Disciplines","lvl2":"Structure"},"type":"lvl3","url":"/#section-2-example-workflows-for-specific-disciplines","position":14},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Section 2: Example Workflows for Specific Disciplines","lvl2":"Structure"},"content":"Land Ice\n\nSea Ice\n\nInland Hydrology\n\nBathymetry\n\nSnowdepth","type":"content","url":"/#section-2-example-workflows-for-specific-disciplines","position":15},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":16},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":17},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":18},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":19},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":20},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer,\nyou will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/icesat2-cookbook repository: git clone https://github.com/ProjectPythia/icesat2-cookbook.git\n\nMove into the icesat2-cookbook directorycd cookbook-example\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate icesat2-cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":21},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running with Pixi","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-with-pixi","position":22},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl3":"Running with Pixi","lvl2":"Running the Notebooks"},"content":"Alternatively, you can use \n\nPixi for a more streamlined environment management experience:\n\nInstall Pixi following the \n\ninstallation instructions\n\nClone the https://github.com/ProjectPythia/icesat2-cookbook repository: git clone https://github.com/ProjectPythia/icesat2-cookbook.git\n\nMove into the icesat2-cookbook directorycd icesat2-cookbook\n\nInstall dependencies and start JupyterLab with a single command:pixi run start\n\nThis will automatically create the environment, install all dependencies, and launch JupyterLab in the notebooks directory.","type":"content","url":"/#running-with-pixi","position":23},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl4":"Exporting Conda Environment with Pixi","lvl3":"Running with Pixi","lvl2":"Running the Notebooks"},"type":"lvl4","url":"/#exporting-conda-environment-with-pixi","position":24},{"hierarchy":{"lvl1":"ICESat-2 Cookbook","lvl4":"Exporting Conda Environment with Pixi","lvl3":"Running with Pixi","lvl2":"Running the Notebooks"},"content":"If you’re using pixi and want to generate a conda-compatible environment.yml file for sharing or reproducibility:pixi run export-env\n\nThis command will export the pixi workspace to a conda environment file (environment.yml) that can be used with conda or mamba.","type":"content","url":"/#exporting-conda-environment-with-pixi","position":25},{"hierarchy":{"lvl1":"Awesome ICESat-2"},"type":"lvl1","url":"/additional-resources/awesome","position":0},{"hierarchy":{"lvl1":"Awesome ICESat-2"},"content":"The following page is rendered from \n\nhttps://​icesat​-2​.github​.io​/awesome​-icesat2/\n\n \n\n\n\nA curated (and slightly opinionated) list of awesome ICESat-2 software, libraries, services, portals, and learning resources.\n\nInspired by \n\nawesome-sar.\nInitial listing generated by GPT5 during ICESat-2 Hackweek 2025. \n\nContributions welcome.","type":"content","url":"/additional-resources/awesome","position":1},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Contents"},"type":"lvl2","url":"/additional-resources/awesome","position":2},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Contents"},"content":"General / Multi-Purpose\n\nData Discovery & Access\n\nCloud & Scalable Processing\n\nData Analysis Tools\n\nRegional and domain-specific resources\n\nVisualization & Exploration\n\nTutorials, Courses & Notebooks\n\nStandard Product Generation\n\nQuality, Calibration & Ancillary Data\n\nRelated Missions & Complementary Datasets\n\nCommunity & Communication\n\nContributing","type":"content","url":"/additional-resources/awesome","position":3},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"General / Multi-Purpose"},"type":"lvl2","url":"/additional-resources/awesome","position":4},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"General / Multi-Purpose"},"content":"NASA ICESat-2 Landing Page\n\nNSIDC ICESat-2 Data Guide - Official product documentation, user guides, and ancillary references for all ATL datasets.","type":"content","url":"/additional-resources/awesome","position":5},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Data Discovery & Access"},"type":"lvl2","url":"/additional-resources/awesome","position":6},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Data Discovery & Access"},"content":"Earthaccess - Search for, and download or stream NASA Earth science data with just a few lines of code.   \n\nicepyx - Unified interface for discovery, access, subsetting, and basic analysis of ICESat-2 (ATL*) products via NASA APIs.   \n\nEarthdata Search - NASA web interface to discover, subset, and order ICESat-2 granules with custom spatial/temporal filters. \n\nNASA CMR API - REST search endpoint for programmatic discovery of ICESat-2 granules and collections.\n\nHarmony API - NASA cloud orchestration API for standardized reformatting, reprojection, and subsetting (emerging ICESat-2 support).","type":"content","url":"/additional-resources/awesome","position":7},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Cloud & Scalable Processing"},"type":"lvl2","url":"/additional-resources/awesome","position":8},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Cloud & Scalable Processing"},"content":"SlideRule Earth - Server-side, scalable ICESat-2 photon subsetting, filtering, and custom processing.    ","type":"content","url":"/additional-resources/awesome","position":9},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Data Analysis Tools"},"type":"lvl2","url":"/additional-resources/awesome","position":10},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Data Analysis Tools"},"content":"pointCollection - A library of code for basic interactions with point data (including ICESat-2 tools)  \n\npointAdvection - A library of code for advecting ice features using velocity data for analyses in a Lagrangian frame of reference  \n\naltimetryFit - A framework for fitting smooth surfaces to a variety of types of altimetry data.  \n\nCapToolkit - A do-it-all library of code for working with cryospheric altimetry data.  ","type":"content","url":"/additional-resources/awesome","position":11},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Regional and domain-specific resources"},"type":"lvl2","url":"/additional-resources/awesome","position":12},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Regional and domain-specific resources"},"content":"PhoREAL - A collection of software for analysis of ICESat-2 land and vegetation data. \n\nThe Antarctic Rift Catalog Project - A project to map rifts in ice shelves around Antarctica. \n\nGrounding-Zones - Tools for Estimating Grounding Zone Locations with data from NASA Polar Altimetry Missions. ","type":"content","url":"/additional-resources/awesome","position":13},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Visualization & Exploration"},"type":"lvl2","url":"/additional-resources/awesome","position":14},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Visualization & Exploration"},"content":"OpenAltimetry - Web platform for interactive browsing, filtering, and quicklooks of ICESat-2 and ICESat elevation tracks.\n\nSlideRule Earth Example Notebooks - Notebook examples for dynamic photon queries and quick visual diagnostic plots. ","type":"content","url":"/additional-resources/awesome","position":15},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Tutorials, Courses, & Notebooks"},"type":"lvl2","url":"/additional-resources/awesome","position":16},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Tutorials, Courses, & Notebooks"},"content":"ICESat-2 Pythia Cookbook - Compilation of tutorials developed from 2019 to present as part of the NASA / UW eScience hackweek program.  \n\nICESat-2 Hackweek GitHub Organization - Reusable Jupyter/Cloud workflow examples from community hackweeks.\n\nICESat-2 Hackweek Websites - JupyterBook websites for ICESat-2 Hackweeks hosted at University of Washington 2019-2025.\n\nNSIDC Data Tutorials - Official step-by-step Python notebooks for opening, filtering, and plotting ATL datasets.  \n\nOpenAltimetry Tutorials - Usage guides for track selection, filtering, and downloading subsets.\n\nCryoCloud Tutorials - JupyterBook for cloud computing including tutorials working with ICESat-2 data. ","type":"content","url":"/additional-resources/awesome","position":17},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Standard Product Generation"},"type":"lvl2","url":"/additional-resources/awesome","position":18},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Standard Product Generation"},"content":"ATL11 - Code to generate the ATL11 (Slope-Corrected Land Ice Height Time Series) product based on the ATL06 (Land-ice height) product. \n\nATL14/15 - Code to generate the gridded ice-sheet DEM and height-change products from ATL11. ","type":"content","url":"/additional-resources/awesome","position":19},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Quality, Calibration & Ancillary Data"},"type":"lvl2","url":"/additional-resources/awesome","position":20},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Quality, Calibration & Ancillary Data"},"content":"ATL02 - Raw telemetry with photon time-of-flight and instrument engineering for advanced calibration research.\n\nATL09 - Atmospheric layer & cloud flag data supporting photon filtering and canopy penetration assessment.","type":"content","url":"/additional-resources/awesome","position":21},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Related Missions & Complementary Datasets"},"type":"lvl2","url":"/additional-resources/awesome","position":22},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Related Missions & Complementary Datasets"},"content":"ICESat (GLAS) - Predecessor laser altimetry mission enabling multi-epoch elevation change assessment.\n\nGEDI - Spaceborne waveform lidar complementing ICESat-2 canopy height sampling for biomass analyses.\n\nCryoSat-2 - Radar altimetry mission offering complementary sea ice thickness and ice sheet elevation trends.\n\nSentinel-1 SAR - Active microwave backscatter supporting surface type classification and change detection alongside elevation trends.\n\nLandsat Collection - Multispectral imagery for land cover context and seasonal melt pond / vegetation mapping.\n\nMODIS / VIIRS Snow & Sea Ice - Daily snow/ice products enabling temporal context for elevation/freeboard retrievals.\n\nDEM Auxiliary Data (REMA/ArcticDEM) - Polar DEM mosaics used for reference elevation and geolocation QA.\n\nICESat GLAS (Legacy) - Historical laser altimetry providing multi-decadal context for elevation change.\n\nGRACE/GRACE-FO Mascon - Complementary mass balance signals to compare with ICESat-2 elevation change in ice sheets.\n\nERA5 Reanalysis - Atmospheric state variables for correcting backscatter or interpreting surface processes.","type":"content","url":"/additional-resources/awesome","position":23},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Community & Communication"},"type":"lvl2","url":"/additional-resources/awesome","position":24},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Community & Communication"},"content":"NSIDC User Support - Helpdesk for data access, documentation, and product interpretation questions.\n\nEarthdata Forum - Official Q&A forum covering API access, subsetting, and dataset usage topics.","type":"content","url":"/additional-resources/awesome","position":25},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Contributing"},"type":"lvl2","url":"/additional-resources/awesome","position":26},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"Contributing"},"content":"Contributions welcome! Please open an issue or pull request adding a resource with: (1) Name, (2) URL, (3) one-sentence description, (4) (sub)category suggestion. Keep descriptions concise, neutral, and avoid promotional language. Duplicates or out-of-scope links (non-ICESat-2 focused) may be declined to maintain curation quality.","type":"content","url":"/additional-resources/awesome","position":27},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"License"},"type":"lvl2","url":"/additional-resources/awesome","position":28},{"hierarchy":{"lvl1":"Awesome ICESat-2","lvl2":"License"},"content":"Distributed under the MIT License. See LICENSE for details.","type":"content","url":"/additional-resources/awesome","position":29},{"hierarchy":{"lvl1":"CryoCloud"},"type":"lvl1","url":"/additional-resources/cryocloud","position":0},{"hierarchy":{"lvl1":"CryoCloud"},"content":"The following page is rendered from \n\nhttps://​book​.cryointhecloud​.com\n\nCryoCloud is a NASA-supported community and cloud platform built in partnership with the International Interactive Computing Collaboration (\n\n2i2c) and designed to advance collaborative, data-intensive Earth science across all disciplines. CryoCloud embraces a broad vision—breaking down silos, fostering intellectual generosity, and empowering scientists to make the most of NASA’s vast data resources through streamlined data workflows.","type":"content","url":"/additional-resources/cryocloud","position":1},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"🚀 Our Mission"},"type":"lvl2","url":"/additional-resources/cryocloud","position":2},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"🚀 Our Mission"},"content":"We aim to create an welcoming, interconnected research ecosystem that:\n\nReduces barriers: Simplifies cloud adoption with cost-efficient and user-friendly tools and data workflows\n\nFosters collaboration: Brings together data producers, engineers, computational experts, and domain scientists in a shared virtual space\n\nDrives innovation: Accelerates impactful science with cutting-edge workflows and a commitment to open science\n\nPromotes sustainability: Ensures long-term access to state-of-the-art computing and data resources","type":"content","url":"/additional-resources/cryocloud","position":3},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"📚 What You’ll Find Here"},"type":"lvl2","url":"/additional-resources/cryocloud","position":4},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"📚 What You’ll Find Here"},"content":"This JupyterBook is your gateway to the resources, tutorials, and tools developed by and for our community. Whether you’re new to cloud computing or an experienced researcher, you’ll find:\n\nInteractive \n\ntutorials to get started with cloud-based data workflows\n\nOpen-source tools and datasets tailored to NASA’s Earth Science disciplines\n\nA community ethos of sharing and collaboration, extending across the entire geoscience community","type":"content","url":"/additional-resources/cryocloud","position":5},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"🌐 Join the Community"},"type":"lvl2","url":"/additional-resources/cryocloud","position":6},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"🌐 Join the Community"},"content":"Since 2022, we have grown from a cryosphere-focused project into a community ecosystem that supports hundreds of domestic and international scientists across geoscience disciplines. Our goal is to empower Earth scientists by providing the community and technical mechanisms that accelerate time to science for their broad range of data workflows. Whether you’re looking to build workflows, share insights, or connect with others, you belong here.","type":"content","url":"/additional-resources/cryocloud","position":7},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"💡 Contact Us"},"type":"lvl2","url":"/additional-resources/cryocloud","position":8},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"💡 Contact Us"},"content":"Have questions or ideas? Reach out at cryocloud@mines.edu or explore our open resources on \n\nGitHub and \n\nZenodo.","type":"content","url":"/additional-resources/cryocloud","position":9},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"Funding Sources"},"type":"lvl2","url":"/additional-resources/cryocloud","position":10},{"hierarchy":{"lvl1":"CryoCloud","lvl2":"Funding Sources"},"content":"\n\nQuick links for the event\n\nJupyterHub: \n\nhttps://​hub​.cryointhecloud​.com\n\nGitHub organization: \n\nhttps://​github​.com​/CryoInTheCloud","type":"content","url":"/additional-resources/cryocloud","position":11},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications"},"type":"lvl1","url":"/notebooks/bathymetry","position":0},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications"},"content":"","type":"content","url":"/notebooks/bathymetry","position":1},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/bathymetry#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Author(s)"},"content":"Jonathan Markel","type":"content","url":"/notebooks/bathymetry#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/bathymetry#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Existing Notebooks"},"content":"Bathymetry Applications","type":"content","url":"/notebooks/bathymetry#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/bathymetry#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl2":"Learning Outcomes"},"content":"Learn what ICESat-2 bathymetry looks like, where to find it, and how to\nvisualize it\n\nUnderstand pros / cons of different signal finding approaches for bathymetry\n\nExtract water surface and seafloor returns from the photon data\n\nApply refraction correction to subsurface photon heights","type":"content","url":"/notebooks/bathymetry#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/bathymetry#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Bathymetry Applications","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"","type":"content","url":"/notebooks/bathymetry#notes","position":9},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing"},"type":"lvl1","url":"/notebooks/cloud-computing","position":0},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing"},"content":"","type":"content","url":"/notebooks/cloud-computing","position":1},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/cloud-computing#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Author(s)"},"content":"Aimee Barciauskas, Tasha Snow","type":"content","url":"/notebooks/cloud-computing#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/cloud-computing#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Existing Notebooks"},"content":"Cloud Computing","type":"content","url":"/notebooks/cloud-computing#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/cloud-computing#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl2":"Learning Outcomes"},"content":"What is cloud computing?\n\nWhat is cloud object storage and the difference between data stored in the\ncloud, data on a local file system and data stored in on-premise data centers.\n\nHow to optimize data for reading from cloud object storage.","type":"content","url":"/notebooks/cloud-computing#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/cloud-computing#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Cloud Computing","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"Unsure whether to point parts of this to an existing CryoCloud tutorial.\nThe content specific to ICESat-2 definitely belongs here.","type":"content","url":"/notebooks/cloud-computing#notes","position":9},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines"},"type":"lvl1","url":"/notebooks/contributing","position":0},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines"},"content":"Purpose\n\nThis cookbook provides guidelines for contributing to the ICESat-2 Cookbook. It is intended to promote openness, reproducibility, and accessibility.\n\nDisclaimer\n\nThis cookbook is an open source project.\nWe welcome any help in maintaining and developing the tutorials and documentation from users at any career stage and with any level of coding experience.\nPlease read our code of conduct before contributing towards this project.","type":"content","url":"/notebooks/contributing","position":1},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Ways to Contribute 🪄"},"type":"lvl2","url":"/notebooks/contributing#ways-to-contribute","position":2},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Ways to Contribute 🪄"},"content":"Fixing typographical or coding errors\n\nSubmitting bug reports or feature requests through the use of \n\nGitHub issues\n\nImproving documentation and testing\n\nSharing tutorials or workflows","type":"content","url":"/notebooks/contributing#ways-to-contribute","position":3},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Requesting a Feature 🚀"},"type":"lvl2","url":"/notebooks/contributing#requesting-a-feature","position":4},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Requesting a Feature 🚀"},"content":"Check the \n\nproject issues tab to see if the feature has already been suggested.\nIf not, please submit a new issue describing your requested feature or enhancement using the New Tutorial Request template.\nPlease give your feature request both a clear title and description.\nLet us know if this is something you would like to contribute to the icesat2-cookbook.","type":"content","url":"/notebooks/contributing#requesting-a-feature","position":5},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Reporting a Bug 🐛"},"type":"lvl2","url":"/notebooks/contributing#reporting-a-bug","position":6},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Reporting a Bug 🐛"},"content":"Check the \n\nproject issues tab to see if the problem has already been reported.\nIf not, please submit a new issue so that we are made aware of the problem.\nPlease provide as much detail as possible when writing the description of your bug report.\nProviding information and examples will help us resolve issues faster.\n\n","type":"content","url":"/notebooks/contributing#reporting-a-bug","position":7},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"General Guidelines"},"type":"lvl2","url":"/notebooks/contributing#general-guidelines","position":8},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"General Guidelines"},"content":"Make each pull request as small and simple as possible\n\nCommit messages should be clear and describe the changes\n\nLarger changes should be broken down into their basic components and integrated separately\n\nBug fixes should be their own pull requests with an associated \n\nGitHub issue using the Bug Report template.\n\nWrite a descriptive pull request message with a clear title\n\nPlease be patient as reviews of pull requests take time","type":"content","url":"/notebooks/contributing#general-guidelines","position":9},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl3":"Steps to Contribute","lvl2":"General Guidelines"},"type":"lvl3","url":"/notebooks/contributing#steps-to-contribute","position":10},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl3":"Steps to Contribute","lvl2":"General Guidelines"},"content":"Fork the repository to your personal GitHub account by clicking the “Fork” button on the project \n\nmain page. This creates your own server-side copy of the repository.\n\nEither by cloning to your local system or working on a hosted JupyterHub (such as \n\nCryoCloud), create a work environment to make your changes using either conda or pixi.\n\nAdd your fork as the origin remote and the original project repository as the upstream remote. While this step isn’t a necessary, it allows you to keep your fork up to date in the future.\n\nCreate a new branch to do your work.\n\nMake your changes on the new branch.\n\nPush your work to GitHub under your fork of the project.\n\nSubmit a \n\nPull Request from your forked branch to the project repository.\n\n","type":"content","url":"/notebooks/contributing#steps-to-contribute","position":11},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Continuous Integration"},"type":"lvl2","url":"/notebooks/contributing#continuous-integration","position":12},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Continuous Integration"},"content":"We use \n\nGitHub Actions continuous integration (CI) services to build the Jupyterbook.\nThe configuration files for this service are in the \n\nGitHub workflows directory.\nThe workflows use the \n\ncookbook-actions provided by Project Pythia.\n\n","type":"content","url":"/notebooks/contributing#continuous-integration","position":13},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Semantic Commit Messages"},"type":"lvl2","url":"/notebooks/contributing#semantic-commit-messages","position":14},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Contribution Guidelines","lvl2":"Semantic Commit Messages"},"content":"Please follow the \n\nConventional Commits specification for your commit messages to help organize the pull requests:<type>: <subject>\n\n[optional message body]\n\nwhere <type> is one of the following:\n\nfeat: adding new features or programs\n\nfix: fixing bugs or problems\n\ndocs: changing the documentation\n\nstyle: changing the line order or adding comments\n\nrefactor: changing the names of variables or programs\n\nci: changing the continuous integration configuration files or scripts","type":"content","url":"/notebooks/contributing#semantic-commit-messages","position":15},{"hierarchy":{"lvl1":"DRAFT: Data Access"},"type":"lvl1","url":"/notebooks/data-access","position":0},{"hierarchy":{"lvl1":"DRAFT: Data Access"},"content":"","type":"content","url":"/notebooks/data-access","position":1},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/data-access#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Author(s)"},"content":"Rachel Wegener, Amy Steiker, Jessica Scheick, JP Swinski, many others","type":"content","url":"/notebooks/data-access#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/data-access#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Existing Notebooks"},"content":"Accessing ICESat-2 Data\n\n(assuming that the 2024 notebook is most updated for now)","type":"content","url":"/notebooks/data-access#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/data-access#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl2":"Learning Outcomes"},"content":"learn about all the tools currently available for accessing ICESat-2 data,\nand the decisions that influence which one to choose\n\nlearn recommended best practices for data access depending on your application","type":"content","url":"/notebooks/data-access#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/data-access#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Data Access","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"Suggest we wait to work on these tutorials until after the 2025 Developers’\nHackweek in Seattle.","type":"content","url":"/notebooks/data-access#notes","position":9},{"hierarchy":{"lvl1":"DRAFT: Data Integration"},"type":"lvl1","url":"/notebooks/data-integration","position":0},{"hierarchy":{"lvl1":"DRAFT: Data Integration"},"content":"","type":"content","url":"/notebooks/data-integration","position":1},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/data-integration#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Author(s)"},"content":"Michalea King, Tyler Sutterley, Ian Joughin, Zach Fair, Tasha Snow","type":"content","url":"/notebooks/data-integration#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/data-integration#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Existing Notebooks"},"content":"-\n\nData Integration Part 1\n\n-\n\nData Integration Part 2","type":"content","url":"/notebooks/data-integration#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/data-integration#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl2":"Learning Outcomes"},"content":"Retrieve image mosaics from NSIDC\n\nSubset and view imagery with GrIMP and NISAR tools\n\nRetrieve customized ICESat-2 data with SlideRule\n\nSample imagery at ICESat-2 photon locations\n\nAccess NSIDC data sets and acquire IS-2 using icepyx\n\nAnalyze point and raster data together with IS-2\n\nAdvanced visualizations of multiple datasets","type":"content","url":"/notebooks/data-integration#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/data-integration#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Data Integration","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"","type":"content","url":"/notebooks/data-integration#notes","position":9},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering"},"type":"lvl1","url":"/notebooks/filtering","position":0},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering"},"content":"\n\n","type":"content","url":"/notebooks/filtering","position":1},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Overview"},"type":"lvl3","url":"/notebooks/filtering#overview","position":2},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Overview"},"content":"The ICESat-2 land-ice product (ATL06) was designed to measure the heights of snow and ice surfaces.  But when we’re making these measurements, sometimes clouds get in the way, and the measured heights aren’t as precise or accurate as we would like. This tutorial covers some of the reasons you might see weird results over ice when clouds start to blot out the surface signals.  The learning objectives I’d like to get to are:\n\nUnderstanding how clouds affect laser-altimetry signals\n\nRecognizing how these effects are manifest in the ATL06 product\n\nGaining familiarity with the ATL06 parameters that can identify cloudy returns\n\n","type":"content","url":"/notebooks/filtering#overview","position":3},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Prerequisites","lvl3":"Overview"},"type":"lvl4","url":"/notebooks/filtering#prerequisites","position":4},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Prerequisites","lvl3":"Overview"},"content":"Concepts\n\nImportance\n\nNotes\n\npandas\n\nNecessary\n\nICESat-2 data in this tutorial will appear as geopandas dataframes\n\nnumpy/matplotlib\n\nNecessary\n\nWe will do our plotting with matplotlib\n\nICESat-2 Mission Overview\n\nNecessary\n\nHere is where to go to understand the ICESat-2 mission and its goals\n\nTime to learn:  30 min.\n\nTip\n\nThis tutorial was developed on CryoCloud under the default environment.  If you’re using CryoCloud, you’ll need to pick an instance that uses at least 7 GB of memory to keep the kernel from running out of memory and resetting.\n\n\n\n","type":"content","url":"/notebooks/filtering#prerequisites","position":5},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Imports"},"type":"lvl3","url":"/notebooks/filtering#imports","position":6},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Imports"},"content":"We’ll use the \n\nSlideRule computational platfrom to access ATL06 segments and ATL03 photons, and will use an image of the ice shelf from the REMA project to visualize the location.\n\n# General packages for the tutorial\nimport pprint\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport geopandas as gpd\n%matplotlib widget\n\n# packages needed for the basemap \nimport PIL.Image\nimport urllib.request\nimport urllib.parse\n\n#sliderule\nfrom sliderule import icesat2\nimport sliderule\n# We'll initialize sliderule with the verbosity flag set to 'False.'  If you like to see lots of text scrolling by, set it to 'True'\nicesat2.init(\"slideruleearth.io\", False)\n\n","type":"content","url":"/notebooks/filtering#imports","position":7},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl2":"Background: ATL06 signal processing"},"type":"lvl2","url":"/notebooks/filtering#background-atl06-signal-processing","position":8},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl2":"Background: ATL06 signal processing"},"content":"\n\nRecall that ATL06 gives us surface heights based on the heights of collections of photons in a 40-m (horizontal) by w_surface_window (vertical) window.  It uses a variety of techniques to shrink the window to the smallest size that contains the surface without clipping off any signal photons.\n\nThere’s a general philosophy that went into the design of ATL06:\n\nUse the best available information to identiy the surface\n\nIf there’s a chance that we’ve found a weak surface return, report it\n\nProvide enough parameters that users can decide which returns are worth using, and which are not\n\nWhen there are no thick clouds between ICESat-2 and the surface, finding the surface return and reporting its height is straightforward: ATL03 provides a tight cluster of high-confidence photons, and ATL06 calculates a weighted average of their heights.\n\nOnce clouds start to block some of the laser light, the number of photons that return to ATLAS from each return becomes progressively smaller.  Unfortunately, even if there are no laser photons to measure, during daylight there is no shortage of other photons to track, which come primarily from sunlight reflecting ground and from clouds.  ATLAS does a very good job of filtering out almost all of these photons, but on a sunny day, over a white surface, the measured background rate can be as high as 12 MHz.  Converting to dimensions that we’ll be seeing this is:\\frac{1.2\\times10^7 photons}{second} \\times \\frac{1 second}{1.5\\times10^8 m} = \\frac{1 photon}{12.5 m}\n\nThis doesn’t sound like a lot, but over a 10-meter-high window that’s 40 m long (typical for the kind of windows you might use to look for the surface if you didn’t know where to find it) we can expect to find 45 photons.\n\nUnlike surface-return photons, background photons are uniformally distributed in height, and any clustering of these photons will be due to random chance.  When the signal quality is marginal, ATL03 may flag photons only as low- and medium- confidence for a particular segment, or may flag no photons at all.  If ATL03 hasn’t told ATL06 which photons are the surface, the algorithm uses a backup signal-finding strategy that initializes surface finding using the strongest cluster of photons available.  It then attempts to converge its surface window on a tight cluster of photons.  This occasionally works, but if there really is no signal, the size of the window generally remains large, and we can evaluate the results based on the signal-to-noise ratio (SNR) of whatever ends up inside the window.  Only those segments with at least 10 photons, for which the probability of converging to an SNR equal to the observed SNR or better for random-noise inputs is less thatn 5% are reported.  This cuts down on false positives considerably.\n\nLet’s take a look at some data from Antarctica to see what different problematic data might look like.\n\n","type":"content","url":"/notebooks/filtering#background-atl06-signal-processing","position":9},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Geographic Setting","lvl2":"Background: ATL06 signal processing"},"type":"lvl3","url":"/notebooks/filtering#geographic-setting","position":10},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Geographic Setting","lvl2":"Background: ATL06 signal processing"},"content":"We’ll be working on Cook Ice Shelf, a heavily crevassed and rifted ice shelf that drains East Antarctica.  I’ve defined a polygon that covers the transition between grounded ice (at the top) floating ice (within the polygon).  The region we’ll be working in is about 70 km x 60 km, and is covered by 20-30 ICESat-2 repeat tracks.  We can get an image of the shelf from the ArcticDEM project, using a urllib-based request.  Note: This code can be used to obtain a basic image for almost anywhere in the Arctic and Antarctic, which might be helpful in other work.\n\nThe location information is stored in a kml file in the assets directory, but you can substitute your own kml if you’d like to look at data from somewhere else.  Just make sure not to make your query too large to avoid running out of memory.\n\n# read in a polygon defining our area of interest:\ndf = gpd.read_file('assets/filtering/Cook_subset.kml')\ngeom_xy = df.to_crs(3031).geometry[0]\ngeom_ll = df.geometry[0]\n\n# get a shaded relief DEM to use as a basemap. This uses the ArcticDEM image server.\n\nHOST = 'https://elevation2.arcgis.com/arcgis/rest/services/Polar/AntarcticDEM/ImageServer/exportImage?'\nparams = []\nparams.append('bboxSR=3031')\nparams.append('imageSR=3031')\nparams.append('format=jpgpng')\nparams.append('noDataInterpretation=esriNoDataMatchAll')\nparams.append('f=image')\n\n[xmin, xmax], [ymin, ymax] = np.array(geom_xy.bounds).reshape(2,2).T\n# include a little bit more area at the top:\nymax += 2.e4 \nbbox = f'{xmin},{ymin},{xmax},{ymax}'\nparams.append(f'bbox={urllib.parse.quote(bbox)}')\n\nimage_service_url = HOST + '&'.join(params)\nshaded_relief_img = {'data': np.array(PIL.Image.open(urllib.request.urlopen(image_service_url))),\n    'extent':[xmin, xmax, ymin, ymax]}\nplt.figure()\nplt.imshow(shaded_relief_img['data'], extent=shaded_relief_img['extent'])\nx_poly, y_poly, _ = [*np.c_[geom_xy.exterior.coords].T]\nplt.plot(x_poly, y_poly,'r')\n\nplt.gca().set_xlabel('polar-stereographic E, m')\nplt.gca().set_xlabel('polar-stereographic N, m')\n\n","type":"content","url":"/notebooks/filtering#geographic-setting","position":11},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"type":"lvl3","url":"/notebooks/filtering#icesat-2-data-over-cook-ice-shelf","position":12},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"content":"For this tutorial, we’ll use the SlideRule service to download ATL06 (height measurements) and ATL03 (photon clouds).  SlideRule offers a quick and efficient way to search for and access data for limited areas of the ice sheet without the need to subset or download entire granules of data.","type":"content","url":"/notebooks/filtering#icesat-2-data-over-cook-ice-shelf","position":13},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Preliminary data download","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"type":"lvl4","url":"/notebooks/filtering#preliminary-data-download","position":14},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Preliminary data download","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"content":"Let’s begin by looking at the distibution of tracks for the region, using the ATL06 (land-ice height) product. We’ll first request a subset of data covering 2020.  To run SlideRule, we need a polygon (defined as a list of dictionaries, each of which has a ‘lat’ and a ‘lon’ element) and a start and stop time.  We’ll use the ATL06sp endpoint, which subsets all the granules in the region for a standard set of ATL06 fields.  The polygon we’re using comes from a kml file called Cook_subset.kml, which is in the assets/filtering directory.  You can substitute your own file if you want to work on a different area.\n\n# Define a polygon in sliderule format.\npoly=[{'lat':jj[1], 'lon':jj[0]} for jj in geom_ll.exterior.coords]\n\n#Define the request (a dictionary of parameters, \n#see: https://slideruleearth.io/web/rtd/user_guide/icesat2.html#parameters\nsliderule_parms= {\n    \"poly\":poly,\n    \"t0\": \"2020-01-01T01:00:00Z\",\n    \"t1\": \"2021-01-01T01:01:01Z\",\n  }\n# submit the request, which should take 10-15 seconds\nD6=icesat2.atl06sp(sliderule_parms)\n# transform the output to polar stereographic coordinates\nD6.to_crs(3031, inplace=True)\n\n\nWe can take a look at the data that SlideRule returned to see what fields are present:\n\nD6\n\nThere are 21 columns here, which describe:\n\nsegment location (geometry)\n\nsegment location along-track coordinates ( x_atc, y_atc )\n\nsurface height and accuracy (h_li, h_li_sigma, atl06_quality_summary)\n\nsurface slope (dh_fit_dx, dh_fit_dy)\n\nsignal (r_eff, n_fit_photons)\n\ntrack and timing parameters (cycle, gt, cycle, spot, delta_time)\n\nThe list of fields is designed to cover almost all users’ needs, and we’ll only end up using a few of them in this tutorial.  Let’s look at the elevations (h_li) that came back in the current request in map view.\n\nplt.figure()\nax_scat = plt.gca()\nplt.imshow(shaded_relief_img['data'], extent=shaded_relief_img['extent'])\n\nxx=np.array(D6.geometry.x)\nyy=np.array(D6.geometry.y)\nhh = np.array(D6.h_li)\n\n# sort the data by abs(height) to make the outliers show up\nii=np.argsort(np.abs(hh))\nii=ii[np.isfinite(hh[ii])]\nh_scat=plt.scatter(xx[ii], yy[ii], 3,  c=hh[ii], clim=[-200, 200], cmap='RdBu')\nplt.colorbar(h_scat, label='h_li')\n\n# suggested area to look at a poorly performing segment:\nxl, yl = [np.array([1079194.72014081, 1080624.2833137 ]), np.array([-2089358.21884508, -2088030.7673274 ])]\n\nplt.plot(xl[[0, 0, 1, 1, 0]], yl[[0, 1, 1, 0, 0]],'--', color='palegreen', marker='*', linewidth=2)\n\nWe can see on this plot that most of the surface heights are close to sea level, but a few tracks are reporting heights that are probably far too high.","type":"content","url":"/notebooks/filtering#preliminary-data-download","position":15},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Selecting a track that has cloud problems","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"type":"lvl4","url":"/notebooks/filtering#selecting-a-track-that-has-cloud-problems","position":16},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Selecting a track that has cloud problems","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"content":"If you see a plot like this where there is a track that has problems, you need to figure out which track is affected.  To do this, you need to know which RGT (repeat ground track) has the problem, and which beams from that track are affected.\n\nOne way to do this is to use the zoom tool to find a track with large positive h_li values, and capture the axes x_lim and y_lim properties, then use the dataframe’s cx method to capture the subset of the dataframe within the axes.  You can do this by setting ‘interactive’ to True in the next cell.\n\nFor puruposes of making the tutorial run without any interaction, I’ve also defined some limits in the next cell, and I’ll be talking about the results that come from those limits.\n\nTip\n\nThe next cell is where you can change the ‘interactive’ variable to True, and use the zoom tool to find different tracks for which you can plot the ATL03 photons\n\n# if interactive is False, we'll use the xl, yl defined in the previous code cell\ninteractive=False\n\nif interactive:\n    xl=ax_scat.get_xlim() ; yl=ax_scat.get_ylim()\nD6_sub= D6.cx[xl[0]:xl[1], yl[0]:yl[1]]\nD6_sub\n\nIf you run this for the default region, you’ll see that there is one rgt (1259), and two gts (10 and 20) in the polygon.  Let’s do a plot of the height against the along-track coordinate:\n\nplt.figure()\nhs=plt.scatter(D6_sub.x_atc, D6_sub.h_li,5, c=D6_sub.cycle)\nplt.colorbar(hs, label='cycle_number')\nplt.gca().set_xlabel('along-track x (x_atc), m')\nplt.gca().set_ylabel('h, m')\n\n\nIf you’re using the default location, this plot shows heights near zero for cycle 8, and elevations far above and below the surface for cycles 7 and 9.  If we zoom in on cycle 8, we can see something that looks like ice-shelf terrain, so we can guess that this is probably “right” and cycles 7 and 9 are wrong.\n\n","type":"content","url":"/notebooks/filtering#selecting-a-track-that-has-cloud-problems","position":17},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Getting ATL03 data for a problematic track","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"type":"lvl4","url":"/notebooks/filtering#getting-atl03-data-for-a-problematic-track","position":18},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Getting ATL03 data for a problematic track","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"content":"The next step is to look at the ATL03 photon cloud for each cycle to see what has worked and what has not.\n\nTip\n\nIf you’re running in interactive mode, copy the track (RGT) and pair track from the subsetted dataframe above.\n\n# set the rgt and pair track here:\nthis_rgt=1259\nthis_track=1\n\n# Get ATL03.  this should take <1 minute to run.\n\nicesat2.init(\"slideruleearth.io\", True)\nsliderule_ATL03_parms= {\n    \"poly\":poly, \n    \"t0\": \"2020-01-01T01:00:00Z\",\n    \"t1\": \"2021-01-01T01:00:00Z\",\n    \"rgt\":this_rgt,\n    \"srt\":icesat2.SRT_LAND_ICE,\n    \"cnf\":-2,\n    \"track\": this_track,\n  }\n# run sliderule for track\nD3=sliderule.run('atl03x', sliderule_ATL03_parms).to_crs(3031)\n\n# make a subset for our geographic region\nD3_sub = D3.cx[xl[0]:xl[1], yl[0]:yl[1]]\n\nLet’s plot the photons from ATL03, and the segments from ATL06 for each beam in pair 1 for each cycle.\n\nNote that SlideRule has numeric codes for the different groundtracks, sogt=10 -> gt1l\n\ngt=20 -> gt1r\n\nThe SlideRule icesat2 module has ‘GT1L’,‘GT1R’,‘GT2L’ attributes that provide these numeric codes.\n\nhf, hax= plt.subplots(3, 2, layout='constrained', sharex=True, figsize=[8, 8])\n\nfor ax1, cycle in zip(hax, np.unique(np.array(D6_sub.cycle))):\n    for ax, gt in zip(ax1, np.unique(np.array(D6_sub['gt']))):\n        i3=(D3_sub['gt']==gt) & (D3_sub.cycle==cycle)\n        ax.plot(D3_sub.x_atc[i3], D3_sub.height[i3],'k.', markersize=1, label='ATL03')\n        i6=(D6_sub['gt']==gt) & (D6_sub.cycle==cycle)\n        ax.plot(D6_sub.x_atc[i6], D6_sub.h_li[i6],'.', color='steelblue', label='ATL06')\n        ax.set_title(f'cycle={cycle}, gt={gt}')\nhax[1, 1].legend()\n\nfor ax in hax[2,:]:\n    ax.set_xlabel('x_atc, m')\nfor ax in hax[:,0]:\n    ax.set_ylabel('WGS84 height, m')\n\nWe can see a few things going on here.  The photons in ATL03 come from vertical bands of data (telemetry bands) that the algorithms running onboard ATLAS have identified as possibly containing a ground return.  In some cases the algorithm is correct (e.g. cycle 8), in other cases it returns only a band of photons far from the ground (gt 10 for cycles 7 and 9) or returns a band of photons that contains the ground for which there is no usable return (gt 20 for cycles 7 and 9).\n\nWe can also see bands of photons above the ground in gt 10 for cycles 7 and 8: these are most likely clouds, and the photons in these bands are much farther apart than the photons from true ground returns (see cycle 8).\n\nAll of the tracks contain at least some background photons, which are uniformly distributed over the telemetry bands.  If you check the dates for the different cycles, you’ll see that cycle 7 comes from June (Antarctic winter), cycle 8 comes from mid September (late winter / early spring) and cycle 9 comes from mid December (high summer).  As a result, there are very few background photons in cycle 7, and very many in cycle 9.\n\n","type":"content","url":"/notebooks/filtering#getting-atl03-data-for-a-problematic-track","position":19},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Plotting ATL03 signal classifications","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"type":"lvl4","url":"/notebooks/filtering#plotting-atl03-signal-classifications","position":20},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl4":"Plotting ATL03 signal classifications","lvl3":"ICESat-2 data over Cook Ice Shelf","lvl2":"Background: ATL06 signal processing"},"content":"It’s instructive to see how the ATL03 classification algorithm sees these points.  Let’s do the plot again, but color code by signal classification.  These are stored in the ATL03 atl03_cnf field.  the confidence values are:\n\n-- -1: Events not associated with a specific surface type\n\n--  0: noise\n\n--  1: noise photons within a +-10 m vertical buffer of a detected photon\n\n--  2: low confidence signal\n\n--  3: medium confidence signal\n\n--  4: high confidence signal\n\nhf, hax= plt.subplots(3, 2, layout='constrained', sharex=True, figsize=[8, 8])\n\nfor ax1, cycle in zip(hax, np.unique(np.array(D6_sub.cycle))):\n    for ax, gt in zip(ax1, np.unique(np.array(D6_sub['gt']))):\n        for cnf, name, color in zip([-1, 0, 1, 2, 3, 4], ['unclassified', 'noise','buffer','low','medium','high'],['gray', 'black','skyblue','green','orange','red']):\n            i3=(D3_sub['gt']==gt) & (D3_sub.cycle==cycle) & (D3_sub.atl03_cnf==cnf)\n            ax.plot(D3_sub.x_atc[i3], D3_sub.height[i3],'.', markersize=1, color=color, label=name)\n        ax.set_title(f'cycle={cycle}, gt={gt}')\nhax[1, 0].legend()\n\nfor ax in hax[2,:]:\n    ax.set_xlabel('x_atc, m')\nfor ax in hax[:,0]:\n    ax.set_ylabel('WGS84 height, m')\n\nIf you zoom around a little bit, you’ll see that cycles 7 and 9 have essentially all photons classified as noise, but cycle 8 has a mixture of high-confidence and (for gt==20) medium/low photons.  The low - confidence photons come from places where the surface is unusually dim, probably because of cloud attenuation.\n\n","type":"content","url":"/notebooks/filtering#plotting-atl03-signal-classifications","position":21},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Relating cloud effects to ATL06 data parameters","lvl2":"Background: ATL06 signal processing"},"type":"lvl3","url":"/notebooks/filtering#relating-cloud-effects-to-atl06-data-parameters","position":22},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Relating cloud effects to ATL06 data parameters","lvl2":"Background: ATL06 signal processing"},"content":"Our problem comes when the ground return is not strong enough to trigger the signal finder, and we start to see triggers associated with:\n\nCloud tops\n\nRandom clusterings of background photons\n\nThese should both be statistically distinct from surface returns because:\n\nThe returns are less intense than a high-quality surface return\n\nThe photons are more widely vertcally spread than those in surface returns\n\nThe surface window cannot converge on a small vertical window around the surface\n\nSurface heights and slopes are not consistent between adjacent segments\n\nThere are a few ATL06 parameters that help quantify these distinctions.\n\nh_li_sigma : the estimated error in the surface-height estimate\n\nn_fit_photons : The number of photons found in each segment\n\nw_surface_window_final : The size of the converged surface window\n\nh_robust_sprd : A percentile-based estimate of the spread of the photons, corrected for background\n\nsnr : the observed signal-to-noise ratio for the selected photons\n\nsnr_significance : The estimated probability that a random clustering of photons would produce the observed SNR\n\ndh_fit_dx : the along-track segment slope\n\nr_eff : the effective reflectance of the surface\n\nThere’s one more parameter that puts a few of these ideas together, in /gtxx/land_ice_segments:\n\natl06_quality_summary : a combination of parameters (h_li_sigma, n_fit_photons/w_surface_window_final, and signal_selection_source).  Zero indicates a good segment, 1 indicates a possibly bad segment.\n\nFor most purposes selecting those points for which atl06_quality_summary==0 will filter out most of the bad returns.  Let’s regenerate the map of Cook ice shelf to see how this works:\n\nplt.figure()\nax_scat_clean = plt.gca()\nplt.imshow(shaded_relief_img['data'], extent=shaded_relief_img['extent'])\n\nxx=np.array(D6.geometry.x)\nyy=np.array(D6.geometry.y)\nhh = np.array(D6.h_li)\nqq = np.array(D6.atl06_quality_summary)\n\n# sort the data by abs(height) to make the outliers show up\nii=np.argsort(np.abs(hh))\n# here is where we filter out the atl06_quality_summary==1 points\nii=ii[np.isfinite(hh[ii]) & (qq[ii]==0)]\nh_scat_clean=plt.scatter(xx[ii], yy[ii], 3,  c=hh[ii], clim=[-200, 200], cmap='RdBu')\nplt.colorbar(h_scat_clean, label='h_li', extend='both')\n\n\nPresto!  all of the too-high and too-low returns from the first map are gone!\n\n\n\n","type":"content","url":"/notebooks/filtering#relating-cloud-effects-to-atl06-data-parameters","position":23},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Summary","lvl2":"Background: ATL06 signal processing"},"type":"lvl3","url":"/notebooks/filtering#summary","position":24},{"hierarchy":{"lvl1":"Cloud effects on ICESat-2 data,  and Data Filtering","lvl3":"Summary","lvl2":"Background: ATL06 signal processing"},"content":"We have taken a look at a location in Antarctica where ICESat-2 has (mostly) successfully measured surface elevations over an ice shelf.  The default code in the cells shows an example for one track, but by switching the ‘interactive’ variable above, you should be able to find different kinds features in the data.\n\nIf you have time, take a few minutes to go back to the first cell after Getting ATL03 data for a problematic track and set ‘interactive’ to True. Then you can try zooming in on the map to identify the different tracks, and downloading the ATL03 to go with them (see the cell marked “select your track here”). You should be able to find:* Clouds\n* Crevasses\n* Rifts in the ice shelf\n* Sea ice or open water.","type":"content","url":"/notebooks/filtering#summary","position":25},{"hierarchy":{"lvl1":"Geospatial Transforms"},"type":"lvl1","url":"/notebooks/geospatial-transforms","position":0},{"hierarchy":{"lvl1":"Geospatial Transforms"},"content":"","type":"content","url":"/notebooks/geospatial-transforms","position":1},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/geospatial-transforms#author-s","position":2},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Author(s)"},"content":"Tyler Sutterley, Hannah Besso, Scott Henderson, David Shean","type":"content","url":"/notebooks/geospatial-transforms#author-s","position":3},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/geospatial-transforms#existing-notebooks","position":4},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Existing Notebooks"},"content":"Geospatial Transforms","type":"content","url":"/notebooks/geospatial-transforms#existing-notebooks","position":5},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/geospatial-transforms#learning-outcomes","position":6},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Learning Outcomes"},"content":"Review fundamental concepts of geospatial coordinate reference systems (CRS)\n\nLearn how to access CRS metadata\n\nLearn basic coordinate transformations relevant to ICESat-2\n\nICESat-2 elevations are spatial point data. Spatial data contains information about where on the surface of the Earth a certain feature is located, and there are many different ways to define this location. While this seems straightforward, two main characteristics of the Earth make defining locations difficult:\n\nEarth is 3-dimensional (working with spatial data would be a lot easier if the world were flat)!\n\nPaper maps and computer screens are flat, which causes issues when we try to use them to display rounded shapes (like the Earth’s surface). Making things even more difficult, the irregular shape of the Earth means there is no one perfect model of its surface on which we could place our spatial data points! Instead, we’re left with many models of the Earth’s surface that are optimized for different locations and purposes.\n\nimport os\nimport pyproj\nimport warnings\nimport numpy as np\nimport rioxarray\nimport xarray as xr\nimport earthaccess\nimport geodatasets\nimport geopandas as gpd\nimport shapely.geometry\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom mpl_toolkits import mplot3d\nwarnings.filterwarnings('ignore')\nAWS_DEFAULT_REGION = os.environ.get('AWS_DEFAULT_REGION', '')\n\n%matplotlib inline\n\nIn this notebook, we will explore coordinate systems, map projections, geophysical concepts and available geospatial software tools.\n\nWe’re going to use \n\ngeopandas, \n\nxarray, and \n\nmatplotlib for visualization.\n\ngeopandas is built on top of other great computing and geospatial tools, which will make our lives easier on this notebook.\n\nnumpy: Scientific Computing Tools For Python\n\npandas: Python Data Analysis Library\n\nshapely: PostGIS-ish operations outside a database context for Python\n\nGEOS: geometry, spatial operations\n\nGDAL/OGR: Pythonic interface to the Geospatial Data Abstraction Library (GDAL)\n\nfiona: Python wrapper for vector data access functions from the OGR library\n\nPROJ: cartographic projection and coordinate transformation library\n\npyproj: Python interface to PROJ library\n\n","type":"content","url":"/notebooks/geospatial-transforms#learning-outcomes","position":7},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Let’s Start by Making a Map"},"type":"lvl2","url":"/notebooks/geospatial-transforms#lets-start-by-making-a-map","position":8},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Let’s Start by Making a Map"},"content":"Q: Why are maps a good method to communicate geographic data?\n\n### geopandas vector data from geodatasets\nworld = gpd.read_file(geodatasets.get_path('naturalearth.land'))\nworld.head()\n\nfig,ax1 = plt.subplots(num=1, figsize=(10,4.55))\nminlon,maxlon,minlat,maxlat = (-180,180,-90,90)\nworld.plot(ax=ax1, color='0.8', edgecolor='none')\n# set x and y limits\nax1.set_xlim(minlon,maxlon)\nax1.set_ylim(minlat,maxlat)\nax1.set_aspect('equal', adjustable='box')\n# add x and y labels\nax1.set_xlabel('Longitude')\nax1.set_ylabel('Latitude')\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98)\n\n","type":"content","url":"/notebooks/geospatial-transforms#lets-start-by-making-a-map","position":9},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Geographic Coordinate Systems"},"type":"lvl2","url":"/notebooks/geospatial-transforms#geographic-coordinate-systems","position":10},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Geographic Coordinate Systems"},"content":"Locations on Earth are usually specified in a geographic coordinate system consisting of\n\nLongitude specifies the angle east and west from the Prime Meridian (102 meters east of the Royal Observatory at Greenwich)\n\nLatitude specifies the angle north and south from the Equator\n\nThe map above projects geographic data from the Earth’s 3-dimensional geometry on to a flat surface.  \n\nThe three common types of projections are cylindric, conic and planar.  Each type is a different way of flattening the Earth’s geometry into 2-dimensional space.\n\nCylindric\n\nConic\n\nPlanar\n\n\n\n\n\n\n\nThe above map is in an Equirectangular Projection (Plate Carrée), where latitude and longitude are equally spaced.  Equirectangular is cylindrical projection, which has benefits as latitudes and longitudes form straight lines.\n\nWarning\n\nWhile simple conceptually, equirectangular projections distort both shape and distance, particularly at higher latitudes! So it is not a great choice for data analysis.\n\nTo illustrate distortion on this map below 👇, we’ve colored the normalized grid area at different latitudes below:\n\nfig,ax1 = plt.subplots(num=1, figsize=(10.375,5.0))\nminlon,maxlon,minlat,maxlat = (-180,180,-90,90)\ndlon,dlat = (1.0,1.0)\nlongitude = np.arange(minlon,maxlon+dlon,dlon)\nlatitude = np.arange(minlat,maxlat+dlat,dlat)\n# calculate and plot grid area\ngridlon,gridlat = np.meshgrid(longitude, latitude)\nim = ax1.imshow(np.cos(gridlat*np.pi/180.0),\n    extent=(minlon,maxlon,minlat,maxlat), \n    interpolation='nearest',\n    cmap=plt.get_cmap('plasma'),\n    origin='lower')\n# add coastlines\nworld.plot(ax=ax1, color='none', edgecolor='black')\n# set x and y limits\nax1.set_xlim(minlon,maxlon)\nax1.set_ylim(minlat,maxlat)\nax1.set_aspect('equal', adjustable='box')\n# add x and y labels\nax1.set_xlabel('Longitude')\nax1.set_ylabel('Latitude')\n# add colorbar\ncbar = plt.colorbar(im, cax=fig.add_axes([0.92, 0.08, 0.025, 0.90]))\ncbar.ax.set_ylabel('Normalized Grid Area')\ncbar.solids.set_rasterized(True)\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.9,bottom=0.08,top=0.98)\n\n","type":"content","url":"/notebooks/geospatial-transforms#geographic-coordinate-systems","position":11},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"The Components of a Coordinate Reference System (CRS):","lvl2":"Geographic Coordinate Systems"},"type":"lvl3","url":"/notebooks/geospatial-transforms#the-components-of-a-coordinate-reference-system-crs","position":12},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"The Components of a Coordinate Reference System (CRS):","lvl2":"Geographic Coordinate Systems"},"content":"Projection Information: the mathematical equation used to flatten objects that are on a round surface (e.g. the earth) so you can view them on a flat surface (e.g. your computer screens or a paper map).\n\nCoordinate System: the X, Y, and Z grid upon which your data is overlaid and how you define where a point is located in space.\n\nHorizontal and vertical units: The units used to define the grid along the x, y (and z) axis.\n\nDatum: A modeled version of the shape of the earth which defines the origin used to place the coordinate system in space.\n\n👆 Borrowed from \n\nEarth Data Science Coursework\n\n","type":"content","url":"/notebooks/geospatial-transforms#the-components-of-a-coordinate-reference-system-crs","position":13},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Map Projections","lvl2":"Geographic Coordinate Systems"},"type":"lvl3","url":"/notebooks/geospatial-transforms#map-projections","position":14},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Map Projections","lvl2":"Geographic Coordinate Systems"},"content":"There is no perfect projection for all purposes\n\nNot all maps are good for ocean or land navigation\n\nNot all projections are good for polar mapping\n\nEvery projection will distort either shape, area, distance or direction:\n\nconformal projections minimize distortion in shape\n\nequal-area projections minimize distortion in area\n\nequidistant projections minimize distortion in distance\n\ntrue-direction projections minimize distortion in direction\n\nWhile there are \n\nprojections that are better suited for specific purposes, \n\nchoosing a map projection is a bit of an art 🦋\n\n👆 Obligatory \n\nxkcd\n\nQ: What is your favorite projection? 🌎\n\nQ: What projections do you use in your research? 🌏\n\n","type":"content","url":"/notebooks/geospatial-transforms#map-projections","position":15},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Determine your data’s CRS","lvl3":"Map Projections","lvl2":"Geographic Coordinate Systems"},"type":"lvl4","url":"/notebooks/geospatial-transforms#determine-your-datas-crs","position":16},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Determine your data’s CRS","lvl3":"Map Projections","lvl2":"Geographic Coordinate Systems"},"content":"Using \n\ngeopandas, we can get CRS information about our data:\n\nworld.crs\n\nThere are many different ways of \n\ndetailing a coordinate reference system (CRS).  Three common CRS formats are:\n\nWell-Known Text (WKT): can describe any coordinate reference system and is the standard for a lot of softwareGEOGCS[\"WGS 84\",\n    DATUM[\"WGS_1984\",\n        SPHEROID[\"WGS 84\",6378137,298.257223563,\n            AUTHORITY[\"EPSG\",\"7030\"]],\n        AUTHORITY[\"EPSG\",\"6326\"]],\n    PRIMEM[\"Greenwich\",0,\n        AUTHORITY[\"EPSG\",\"8901\"]],\n    UNIT[\"degree\",0.01745329251994328,\n        AUTHORITY[\"EPSG\",\"9122\"]],\n    AUTHORITY[\"EPSG\",\"4326\"]]\n\nPROJ string: shorter with some less information but can also describe any coordinate reference system+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs \n\nEPSG code: simple and easy to rememberEPSG:4326\n\nEPSG: European Petroleum Survey Group. Back in the day, this group created codes to standardize how different reference systems were referred to, and now EPSG codes are widely used in geospatial work! There are several websites that let you navigate the entire EPSG database: \n\nhttps://​epsg​.io​/4326\n\nImportant\n\nIf CRS metadata on any products isn’t included within the data product, make sure it’s in the right projection and datum. Often metadata reports or readme files will provide this information.\n\n","type":"content","url":"/notebooks/geospatial-transforms#determine-your-datas-crs","position":17},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"type":"lvl3","url":"/notebooks/geospatial-transforms#crs-transforms-of-geodataframes","position":18},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"content":"The Coordinate Reference System of a \n\ngeopandas GeoDataFrame can be transformed to another using the to_crs() function.  The to_crs() function can import different forms including WKT strings, PROJ strings, EPSG codes and pyproj CRS objects.\n\nWarning\n\nGeoDataFrames must have an associated CRS before converting them to a new CRS\n\nworld_antarctic = world[world.scalerank == 0].to_crs(3031)\n\n","type":"content","url":"/notebooks/geospatial-transforms#crs-transforms-of-geodataframes","position":19},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl5":"Did it work?","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"type":"lvl5","url":"/notebooks/geospatial-transforms#did-it-work","position":20},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl5":"Did it work?","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"content":"\n\nworld_antarctic.crs\n\n🎉🎉🎉\n\n","type":"content","url":"/notebooks/geospatial-transforms#did-it-work","position":21},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Let’s plot our new Antarctic map","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"type":"lvl4","url":"/notebooks/geospatial-transforms#lets-plot-our-new-antarctic-map","position":22},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Let’s plot our new Antarctic map","lvl3":"CRS Transforms of GeoDataFrames","lvl2":"Geographic Coordinate Systems"},"content":"🐧🐧🐧\n\nfig,ax3 = plt.subplots(num=3, figsize=(10,7.5))\nxmin,xmax,ymin,ymax = (-3100000,3100000,-2600000,2600000)\n# add Antarctic coastlines\nworld_antarctic.plot(ax=ax3, color='0.8', edgecolor='none')\n# set x and y limits\nax3.set_xlim(xmin,xmax)\nax3.set_ylim(ymin,ymax)\nax3.set_aspect('equal', adjustable='box')\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98)\n\nStereographic projections are common for mapping in polar regions.  A lot of legacy data products for both Greenland and Antarctica use polar stereographic projections. Some other polar products, such as NSIDC EASE/EASE-2 grids, are in equal-area projections.\n\nWarning\n\nStereographic projections are conformal, preserving angles but not distances or areas.  Equal-area map projection cannot be conformal, nor can a conformal map projection be equal-area.\n\nHere, we’ll use the transform to get the latitude and longitude coordinates of points in this projection (an inverse tranformation), and get the polar stereographic coordinates for plotting a circle around the standard parallel (-71°) of this projection (a forward transformation).\n\nThe standard parallel of a stereographic projection is the latitude where there is no scale distortion.\n\ndef scale_factors(\n        lat: np.ndarray,\n        flat: float = 1.0/298.257223563,\n        reference_latitude: float = 70.0,\n        metric: str = 'area'\n    ):\n    \"\"\"\n    Calculates scaling factors to account for polar stereographic\n    distortion including special case of at the exact pole\n\n    Parameters\n    ----------\n    lat: np.ndarray\n        latitude (degrees north)\n    flat: float, default 1.0/298.257223563\n        ellipsoidal flattening\n    reference_latitude: float, default 70.0\n        reference latitude (true scale latitude)\n    metric: str, default 'area'\n        metric to calculate scaling factors\n\n            - ``'distance'``: scale factors for distance\n            - ``'area'``: scale factors for area\n\n    Returns\n    -------\n    scale: np.ndarray\n        scaling factors at input latitudes\n    \"\"\"\n    assert metric.lower() in ['distance', 'area'], 'Unknown metric'\n    # convert latitude from degrees to positive radians\n    theta = np.abs(lat)*np.pi/180.0\n    # convert reference latitude from degrees to positive radians\n    theta_ref = np.abs(reference_latitude)*np.pi/180.0\n    # square of the eccentricity of the ellipsoid\n    # ecc2 = (1-b**2/a**2) = 2.0*flat - flat^2\n    ecc2 = 2.0*flat - flat**2\n    # eccentricity of the ellipsoid\n    ecc = np.sqrt(ecc2)\n    # calculate ratio at input latitudes\n    m = np.cos(theta)/np.sqrt(1.0 - ecc2*np.sin(theta)**2)\n    t = np.tan(np.pi/4.0 - theta/2.0)/((1.0 - ecc*np.sin(theta)) / \\\n        (1.0 + ecc*np.sin(theta)))**(ecc/2.0)\n    # calculate ratio at reference latitude\n    mref = np.cos(theta_ref)/np.sqrt(1.0 - ecc2*np.sin(theta_ref)**2)\n    tref = np.tan(np.pi/4.0 - theta_ref/2.0)/((1.0 - ecc*np.sin(theta_ref)) / \\\n        (1.0 + ecc*np.sin(theta_ref)))**(ecc/2.0)\n    # distance scaling\n    k = (mref/m)*(t/tref)\n    kp = 0.5*mref*np.sqrt(((1.0+ecc)**(1.0+ecc))*((1.0-ecc)**(1.0-ecc)))/tref\n    if (metric.lower() == 'distance'):\n        # distance scaling\n        scale = np.where(np.isclose(theta, np.pi/2.0), 1.0/kp, 1.0/k)\n    elif (metric.lower() == 'area'):\n        # area scaling\n        scale = np.where(np.isclose(theta, np.pi/2.0), 1.0/(kp**2), 1.0/(k**2))\n    return scale\n\ncrs4326 = pyproj.CRS.from_epsg(4326)    # WGS84\ncrs3031 = pyproj.CRS.from_epsg(3031)    # Antarctic Polar Stereographic\ntransformer = pyproj.Transformer.from_crs(crs4326, crs3031, always_xy=True)\n\nfig,ax3 = plt.subplots(num=3, figsize=(10,7.5))\nxmin,xmax,ymin,ymax = (-3100000,3100000,-2600000,2600000)\ndx,dy = (10000,10000)\n# create a grid of polar stereographic points\nX = np.arange(xmin,xmax+dx,dx)\nY = np.arange(ymin,ymax+dy,dy)\ngridx,gridy = np.meshgrid(X, Y)\n# convert polar stereographic points to latitude/longitude (WGS84)\ngridlon,gridlat = transformer.transform(gridx, gridy,\n    direction=pyproj.enums.TransformDirection.INVERSE)\n# calculate and plot grid area\ncf = crs3031.to_cf()\nflat = 1.0/cf['inverse_flattening']\nsp = cf['standard_parallel']\ngridarea = scale_factors(gridlat, flat=flat, reference_latitude=sp)\nim = ax3.imshow(gridarea,\n    extent=(xmin,xmax,ymin,ymax), \n    interpolation='nearest',\n    cmap=plt.get_cmap('plasma'),\n    origin='lower')\n# add circle around standard parallel\nref_lon = np.arange(360)\nref_lat = np.ones((360))*sp\n# convert latitude/longitude (WGS84) points to polar stereographic\nref_x,ref_y = transformer.transform(ref_lon, ref_lat,\n    direction=pyproj.enums.TransformDirection.FORWARD)\nl, = ax3.plot(ref_x, ref_y, '--', color='w', dashes=(8,4), label='Standard Parallel')\n# add coastlines\nworld_antarctic.plot(ax=ax3, color='none', edgecolor='black')\n# set x and y limits\nax3.set_xlim(xmin,xmax)\nax3.set_ylim(ymin,ymax)\nax3.set_aspect('equal', adjustable='box')\n# add x and y labels\nx_info,y_info = crs3031.axis_info\nax3.set_xlabel('{0} [{1}]'.format(x_info.name,x_info.unit_name))\nax3.set_ylabel('{0} [{1}]'.format(y_info.name,y_info.unit_name))\n# add colorbar\ncbar = plt.colorbar(im, cax=fig.add_axes([0.92, 0.08, 0.025, 0.90]))\ncbar.ax.set_ylabel('Normalized Grid Area')\ncbar.solids.set_rasterized(True)\n# add legend\nlgd = ax3.legend(loc=4,frameon=False)\nlgd.get_frame().set_alpha(1.0)\nfor line in lgd.get_lines():\n    line.set_linewidth(6)\nfor i,text in enumerate(lgd.get_texts()):\n    text.set_color(l.get_color())\nfig.subplots_adjust(left=0.06,right=0.9,bottom=0.08,top=0.98)\n\nWhy is there a black line to the pole?  Because this coastline was reprojected from a Equirectangular projection.  That’s the bottom of the Equirectangular map.\n\n","type":"content","url":"/notebooks/geospatial-transforms#lets-plot-our-new-antarctic-map","position":23},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reproject other data","lvl2":"Geographic Coordinate Systems"},"type":"lvl3","url":"/notebooks/geospatial-transforms#reproject-other-data","position":24},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reproject other data","lvl2":"Geographic Coordinate Systems"},"content":"Often you have other data or contextual information that you need to get into your data’s CRS to visualize.\n\nFor example, McMurdo Research Station is at (-77.846° S, 166.676° E). How to we plot this without using geopandas?\n\npyproj transform objects can be used to change the Coordinate Reference System of arrays\n\nImportant\n\nNote that most Python libraries do NOT check to make sure your data shares the same CRS. Plotting libraries are not “CRS aware” and will happily plot things in incorrect positions. It is up to you to make sure your positions are accurate.\n\nThis will transform our latitude and longitude coordinates into coordinates in meters from the map origin\n\n# convert location of McMurdo station to polar stereographic\nMcMurdo = (166.676, -77.846)\nMcMurdo_3031 = transformer.transform(*McMurdo)\n\nfig, ax = plt.subplots()\nworld_antarctic.plot(ax=ax, color='0.8', edgecolor='none')\nax.plot(McMurdo_3031[0], McMurdo_3031[1], 'ro')\n# set x and y limits\nxmin,xmax,ymin,ymax = (-3100000,3100000,-2600000,2600000)\nax.set_xlim(xmin,xmax)\nax.set_ylim(ymin,ymax)\nax.set_aspect('equal', adjustable='box')\nax.set_title(f'McMurdo Station {McMurdo}');\n\n","type":"content","url":"/notebooks/geospatial-transforms#reproject-other-data","position":25},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Reference Systems and Datums"},"type":"lvl2","url":"/notebooks/geospatial-transforms#reference-systems-and-datums","position":26},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Reference Systems and Datums"},"content":"Coordinates are defined to be in reference to the origins of the coordinate system\n\nHorizontally, coordinates are in reference to the Equator and the Prime Meridian\n\nVertically, heights are in reference to a \n\ndatum\n\nTwo common vertical datums are the reference ellipsoid and the reference geoid.\n\nWhat are they and what is the difference?\n\nTo ﬁrst approximation, the Earth is a sphere (🐄) with a radius of 6371 kilometers.\n\nTo a better approximation, the Earth is a slightly flattened ellipsoid with the polar axis 22 kilometers shorter than the equatorial axis.\n\nTo an even better approximation, the Earth’s shape can be described using a reference geoid, which undulates 10s of meters above and below the reference ellipsoid. The difference in height between the ellipsoid and the geoid are known as geoid heights.\n\nThe geoid is an equipotential surface, perpendicular to the force of gravity at all points and with a constant geopotential. Reference ellipsoids and geoids are both created to largely coincide with mean sea level if the oceans were at rest.\n\nAn ellipsoid can be considered a simplification of a geoid.\n\nPROJ hosts grids for shifting both the horizontal and vertical datum, such as gridded \n\nEGM2008 geoid height values\n\nTip\n\nIf you work with vertical datum offset grids regularly or offline: use the projsync command\nprojsync --all --quiet\n\nAdditional geoid height values can be calculated at the \n\nInternational Centre for Global Earth Models (ICGEM)\n\nVertically exaggerated, the Earth is sort of like a potato 🥔\n\n","type":"content","url":"/notebooks/geospatial-transforms#reference-systems-and-datums","position":27},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Why Does This Matter?"},"type":"lvl2","url":"/notebooks/geospatial-transforms#why-does-this-matter","position":28},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Why Does This Matter?"},"content":"ICESat-2 elevations are in reference to a specific version of the WGS84 ellipsoid. There are different “realizations” of the WGS84 ellipsoid. The accuracy of your positioning improves when the specific realization, rather than the ensemble, is used!\n\nTip\n\nRecall above we saw EPSG:4326 used “Datum: World Geodetic System 1984 ensemble”, which is common for older or low-accuracy datasets. \n\nRead more here\n\nICESat-2 data products also include geoid heights from the \n\nEGM2008 geoid.  Different ground-based, airborne or satellite-derived elevations may use a separate datum entirely.\n\nImportant\n\nElevations have to be in the same reference frame when comparing heights.\n\nDifferent datums have different purposes.  Heights above mean sea level are needed for ocean and sea ice heights, and are also commonly used for terrestrial mapping (e.g. as elevations of mountains).  Ellipsoidal heights are commonly used for estimating land ice height change.\n\n\n\nModified from: Tapley, B. D. & M-C. Kim, Applications to Geodesy, Chapt. 10 in Satellite Altimetry and Earth Sciences, ed. by L-L. Fu & A. Cazenave, Academic Press, pp. 371-406, 2001.\n\nTip\n\nAnother piece to consider is the permanent tide system. ICESat-2 is tide-free but a lot of datasets are mean tide. Checkout the \n\nICESat-2 Data Comparison User’s Guide produced by the ICESat-2 Project Science Office (PSO) for more info.\n\n","type":"content","url":"/notebooks/geospatial-transforms#why-does-this-matter","position":29},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Terrestrial Reference System","lvl2":"Why Does This Matter?"},"type":"lvl3","url":"/notebooks/geospatial-transforms#terrestrial-reference-system","position":30},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Terrestrial Reference System","lvl2":"Why Does This Matter?"},"content":"Locations of satellites are determined in an Earth-centered cartesian coordinate system\n\nX, Y, and Z measurements from the Earth’s center of mass\n\nUp to Release-06, ICESat-2 has been set in the \n\n2014 realization of the International Terrestrial Reference Frame (ITRF). For Release-07 onward, ICESat-2 will be set in the \n\n2020 realization. Other satellite and airborne altimetry missions may be in a different ITRF entirely.\n\nAs opposed to simple vertical offsets, changing the terrestial reference system can involve both \n\ntranslation and rotation of the reference system.  This involves converting from a geographic coordinate system into a Cartesian coordinate system.\n\nLet’s visualize what the Cartesian coordinate system looks like:\n\ndef to_cartesian(lon,lat,h=0.0,a_axis=6378137.0,flat=1.0/298.257223563):\n    \"\"\"\n    Converts geodetic coordinates to Cartesian coordinates\n\n    Inputs:\n        lon: longitude (degrees east)\n        lat: latitude (degrees north)\n\n    Options:\n        h: height above ellipsoid (or sphere)\n        a_axis: semimajor axis of the ellipsoid (default: WGS84)\n            * for spherical coordinates set to radius of the Earth\n        flat: ellipsoidal flattening (default: WGS84)\n            * for spherical coordinates set to 0\n    \"\"\"\n    # verify axes\n    lon = np.atleast_1d(lon)\n    lat = np.atleast_1d(lat)\n    # fix coordinates to be 0:360\n    lon[lon < 0] += 360.0\n    # Linear eccentricity and first numerical eccentricity\n    lin_ecc = np.sqrt((2.0*flat - flat**2)*a_axis**2)\n    ecc1 = lin_ecc/a_axis\n    # convert from geodetic latitude to geocentric latitude\n    dtr = np.pi/180.0\n    # geodetic latitude in radians\n    latitude_geodetic_rad = lat*dtr\n    # prime vertical radius of curvature\n    N = a_axis/np.sqrt(1.0 - ecc1**2.0*np.sin(latitude_geodetic_rad)**2.0)\n    # calculate X, Y and Z from geodetic latitude and longitude\n    X = (N + h) * np.cos(latitude_geodetic_rad) * np.cos(lon*dtr)\n    Y = (N + h) * np.cos(latitude_geodetic_rad) * np.sin(lon*dtr)\n    Z = (N * (1.0 - ecc1**2.0) + h) * np.sin(latitude_geodetic_rad)\n    # return the cartesian coordinates\n    return (X,Y,Z)\n\nfig,ax2 = plt.subplots(num=2, subplot_kw=dict(projection='3d'))\nminlon,maxlon,minlat,maxlat = (-180,180,-90,90)\ndlon,dlat = (10.0,10.0)\nlongitude = np.arange(minlon,maxlon+dlon,dlon)\nlatitude = np.arange(minlat,maxlat+dlat,dlat)\ngridlon,gridlat = np.meshgrid(longitude, latitude)\nheight = np.zeros_like(gridlon)\nX,Y,Z = to_cartesian(gridlon, gridlat, h=height)\nax2.scatter3D(X, Y, Z, c=gridlat)\nplt.show()\n\nYep, that looks like an ellipsoid\n\n","type":"content","url":"/notebooks/geospatial-transforms#terrestrial-reference-system","position":31},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"pyproj CRS Tricks"},"type":"lvl2","url":"/notebooks/geospatial-transforms#pyproj-crs-tricks","position":32},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"pyproj CRS Tricks"},"content":"pyproj CRS objects can:\n\nBe converted to different methods of describing the CRS, such a to a PROJ string or WKT\n\nproj3031 = crs3031.to_proj4()\nwkt3031 = crs3031.to_wkt()\nassert(crs3031.is_exact_same(pyproj.CRS.from_wkt(wkt3031)))\nprint(proj3031)\n\nProvide information about each coordinate reference system, such as the name, area of use and axes units.\n\nfor EPSG in (3031,3413,5936,6931,6932):\n  crs = pyproj.CRS.from_epsg(EPSG)\n  x_info,y_info = crs.axis_info\n  print(f'{crs.name} ({EPSG})')\n  print(f'\\tRegion: {crs.area_of_use.name}')\n  print(f'\\tScope: {crs.scope}')\n  print(f'\\tAxes: {x_info.name} ({x_info.unit_name}), {y_info.name} ({y_info.unit_name})')\n\nGet coordinate reference system metadata for including in files\n\nprint('Climate and Forecast (CF) conventions')\ncf = pyproj.CRS.from_epsg(5936).to_cf()\nfor key,val in cf.items():\n    print(f'\\t{key}: {val}')\n\nYou can also manually create a pipeline to do coordinate reference systems conversions. These are like recipes for converting coordinate reference systems.\n\nRemember converting latitude and longitude into cartesian coordinates? We can do that with a pipeline!\n\nfig,ax2 = plt.subplots(num=2, subplot_kw=dict(projection='3d'))\nminlon,maxlon,minlat,maxlat = (-180,180,-90,90)\ndlon,dlat = (10.0,10.0)\nlongitude = np.arange(minlon,maxlon+dlon,dlon)\nlatitude = np.arange(minlat,maxlat+dlat,dlat)\ngridlon,gridlat = np.meshgrid(longitude, latitude)\nheight = np.zeros_like(gridlon)\npipeline = \"\"\"+proj=pipeline\n    +step +proj=unitconvert +xy_in=deg +z_in=m +xy_out=rad +z_out=m\n    +step +proj=cart +ellps=WGS84\"\"\"\ntransform = pyproj.Transformer.from_pipeline(pipeline)\nX,Y,Z = transform.transform(gridlon,gridlat,height)\nax2.scatter3D(X,Y,Z, c=gridlat)\nplt.show()\n\nprojinfo can list possible pipelines for converting between coordinate reference systems\n\nHere is the pipeline PROJ chose to convert from latitude and longitude into polar stereographic\n\n!projinfo -s EPSG:4326 -t EPSG:3031 -o PROJ --hide-ballpark --spatial-test intersects\n\n","type":"content","url":"/notebooks/geospatial-transforms#pyproj-crs-tricks","position":33},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Geospatial Data"},"type":"lvl2","url":"/notebooks/geospatial-transforms#geospatial-data","position":34},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Geospatial Data"},"content":"What is Geospatial Data?  Data that has location information associated with it.\n\nGeospatial data comes in two flavors: vector and raster\n\nVector data is composed of points, lines, and polygons\n\nRaster data is composed of individual grid cells\n\n\n\nVector vs. Raster from \n\nPlanet\n\nQ: When would we use vector over raster?\n\nQ: When would we use raster over vector?\n\nVector data will provide geometric information for every point or vertex in the geometry.\n\nRaster data will provide geometric information for a particular corner, which can be combined with the grid cell sizes and grid dimensions to get the grid cell coordinates.\n\nCommon vector file formats:\n\nGeoJSON\n\nshapefile\n\nGeoPackage\n\nESRI geodatabase\n\nkml/kmz\n\ngeoparquet\n\nCommon raster file formats:\n\nGeoTIFF/cog\n\njpeg\n\npng\n\nFile formats used for both:\n\nnetCDF4\n\nHDF5\n\nzarr\n\nAll geospatial data (raster and vector) should have metadata for extracting the coordinate reference system of the data.  Some of this metadata is not included with the files but can be found in the documentation.\n\nQ: Are you more familiar with using vector or raster data?\n\nQ: Do you more often use GIS software or command-line tools?\n\nThere are different tools for working with raster and vector data.  Some are more advantageous for one data type over the other.\n\nLet’s find the coordinate reference system of some data products using some common geospatial tools.\n\n","type":"content","url":"/notebooks/geospatial-transforms#geospatial-data","position":35},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Geospatial Data Abstraction Library","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#geospatial-data-abstraction-library","position":36},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Geospatial Data Abstraction Library","lvl2":"Geospatial Data"},"content":"The \n\nGeospatial Data Abstraction Library (GDAL/OGR) is a powerful piece of software.\n\nIt can read, write and query a wide variety of raster and vector geospatial data formats, transform the coordinate system of images, and manipulate other forms of geospatial data.\n\nIt is the backbone of a large suite of geospatial libraries and programs.\n\nThere are a number of wrapper libraries (e.g. \n\nrasterio, \n\nrioxarray, \n\nshapely, \n\nfiona) that provide more user-friendly interfaces with GDAL functionality.\n\nSimilar to pyproj CRS objects, GDAL SpatialReference functions can provide a lot of information about a particular Coordinate Reference System\n\nWith GDAL, we can access raster and vector data that are available over network-based file systems and virtual file systems\n\n/vsicurl/: http/https/ftp files\n\n/vsis3/: AWS S3 files\n\n/vsigs/: Google Cloud Storage files\n\n/vsizip/: zip archives\n\n/vsitar/: tar/tgz archives\n\n/vsigzip/: gzipped files\n\nThese can be chained together to access compressed files over networks\n\n","type":"content","url":"/notebooks/geospatial-transforms#geospatial-data-abstraction-library","position":37},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Vector Data","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#vector-data","position":38},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Vector Data","lvl2":"Geospatial Data"},"content":"We can use GDAL virtual file systems to access the intermediate resolution shapefile of the \n\nGlobal Self-consistent, Hierarchical, High-resolution Geography Database from its https server.\n\nogrinfo is a GDAL/OGR tool for inspecting vector data.  We’ll get a summary (-so) of all data (-al) in read-only mode (-ro).\n\n!ogrinfo -so -al -ro /vsizip//vsicurl/http://www.soest.hawaii.edu/pwessel/gshhg/gshhg-shp-2.3.7.zip/GSHHS_shp/i/GSHHS_i_L1.shp\n\n","type":"content","url":"/notebooks/geospatial-transforms#vector-data","position":39},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reading Vector Data","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#reading-vector-data","position":40},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reading Vector Data","lvl2":"Geospatial Data"},"content":"\n\ngshhg_i = gpd.read_file('/vsizip//vsicurl/http://www.soest.hawaii.edu/pwessel/gshhg/gshhg-shp-2.3.7.zip/GSHHS_shp/i/GSHHS_i_L1.shp')\nprint(gshhg_i.crs)\n\nLet’s use these coastlines to make a plot of Greenland in a \n\nPolar Stereographic projection (EPSG:3413)\n\nfig,ax4 = plt.subplots(num=4, figsize=(9,9))\ncrs3413 = pyproj.CRS.from_epsg(3413)\nxmin,xmax,ymin,ymax = (-1530000, 1610000,-3600000, -280000)\n# add coastlines\ngshhg_i.to_crs(crs3413).plot(ax=ax4, color='0.8', edgecolor='none')\n# set x and y limits\nax4.set_xlim(xmin,xmax)\nax4.set_ylim(ymin,ymax)\nax4.set_aspect('equal', adjustable='box')\n# add x and y labels\nx_info,y_info = crs3413.axis_info\nax4.set_xlabel('{0} [{1}]'.format(x_info.name,x_info.unit_name))\nax4.set_ylabel('{0} [{1}]'.format(y_info.name,y_info.unit_name))\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98)\n\nEven with intermediate resolution, we can add much better coastlines than the ones that ship with geodatasets!\n\nAll coastline resolutions available:\n\nc: coarse\n\nl: low\n\ni: intermediate\n\nh: high\n\nf: full\n\n","type":"content","url":"/notebooks/geospatial-transforms#reading-vector-data","position":41},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Raster Data","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#raster-data","position":42},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Raster Data","lvl2":"Geospatial Data"},"content":"The same virtual file system commands can be used with raster images.\n\nLet’s inspect some elevation data from the COP3 DEM.\n\ngdalinfo allows us to inspect the format, size, geolocation and Coordinate Reference System of raster imagery.  Appending the -proj4 option will additionally output the PROJ string associated with this geotiff image.\n\n! gdalinfo -proj4 \"https://opentopography.s3.sdsc.edu/raster/COP30/COP30_hh/Copernicus_DSM_10_N47_00_W123_00_DEM.tif\"\n\n","type":"content","url":"/notebooks/geospatial-transforms#raster-data","position":43},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reading Raster Data","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#reading-raster-data","position":44},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Reading Raster Data","lvl2":"Geospatial Data"},"content":"We can read geotiff files using rasterio, which is a wrapper of GDAL for reading raster data\n\nurl = \"https://opentopography.s3.sdsc.edu/raster/COP30/COP30_hh/Copernicus_DSM_10_N47_00_W123_00_DEM.tif\"\nds = rioxarray.open_rasterio(url, masked=True).isel(band=0)\nds\n\n# plot location of DEM\nfig,ax1 = plt.subplots(num=1, figsize=(10.375,5.0))\nminlon,maxlon,minlat,maxlat = (-180,180,-90,90)\n# add geometry of image\nxmin, ymin, xmax, ymax = ds.rio.transform_bounds('EPSG:4326')\nbox = gpd.GeoSeries(shapely.geometry.box(xmin, ymin, xmax, ymax))\nbox.plot(ax=ax1,facecolor='red',edgecolor='red',alpha=0.5)\n# add annotation\nax1.annotate(\"Here!\", xy=(xmin,ymin), xytext=(xmin-15.0, ymin-15.0),\n    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3,rad=0.3\",color='red'),\n    bbox=dict(boxstyle=\"square\", fc=\"w\", ec=\"w\", pad=0.1),\n    color='red', weight='bold', xycoords='data', ha='center')\n# add GSHHG coastlines\ngshhg_i.plot(ax=ax1, color='none', edgecolor='black')\n# set x and y limits\nax1.set_xlim(minlon,maxlon)\nax1.set_ylim(minlat,maxlat)\nax1.set_aspect('equal', adjustable='box')\n# add x and y labels\nax1.set_xlabel('Longitude')\nax1.set_ylabel('Latitude')\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98)\n\nOkay! It covers Seattle and the University of Washington.\n\nLet’s see what the DEM looks like for this granule\n\n# create figure axis\nfig, ax = plt.subplots(num=5)\nim = ds.plot.imshow(ax=ax, interpolation='nearest',\n    vmin=ds.values.min(), vmax=ds.values.max(),\n    cmap=plt.cm.gray_r)\nx,y = (-122.3117, 47.6533)\nax.plot(x, y, 'r*')\n# add annotation\nax.annotate(\"UW eScience!\", xy=(x,y-0.005), xytext=(x-0.1, y-0.1),\n    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3,rad=0.3\",color='red'),\n    color='red', weight='bold', xycoords='data', ha='center')\n# turn of frame and ticks\nax.set_frame_on(False)\nax.set_xticks([])\nax.set_yticks([])\nplt.axis('off')\n# adjust subplot within figure\nfig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n\n","type":"content","url":"/notebooks/geospatial-transforms#reading-raster-data","position":45},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"type":"lvl3","url":"/notebooks/geospatial-transforms#warping-raster-imagery","position":46},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"content":"Warping transfers a raster image from one Coordinate Reference System (CRS) into another.\n\nWe can use \n\nGDAL to reproject the imagery data into another CRS or change the pixel resolution of the raster image.\n\nGround control points (GCPs) can also be applied to georeference raw maps or imagery.\n\n\n\nRaster Georeferencing from \n\nESRI\n\n","type":"content","url":"/notebooks/geospatial-transforms#warping-raster-imagery","position":47},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Rasterio Transforms","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"type":"lvl4","url":"/notebooks/geospatial-transforms#rasterio-transforms","position":48},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Rasterio Transforms","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"content":"For every rasterio object, there is an associated affine transform (ds.transform), which allows you to \n\ntransfer from image coordinates to geospatial coordinates.\n\n\nx = A*row + B*col + C\\\\\ny = D*row + E*col + F\n\nAffine Transformation: maps between pixel locations in (row, col) coordinates to (x, y) spatial positions:\n\nx,y = ds.transform*(row,col)\n\nUpper left coordinate:\n\nrow = 0\n\ncol = 0\n\nLower right coordinate:\n\nrow = ds.width\n\ncol = ds.height\n\n\n\nRaster Georeferencing from \n\nESRI\n\nrioxarray does these affine transformations under the hood when reprojecting images. We can use these tools to warp our raster image into a lower resolution.\n\n# degrade resolution from 1 arcsecond to 8 arcseconds\ndst_res = 8.0/3600.0\nwarped = ds.rio.reproject(crs4326, resolution=(dst_res,dst_res))\n\n# plot warped DEM\nfig,ax1 = plt.subplots(num=1, figsize=(10.375,5.0))\n# add geometry of image\nim = warped.plot.imshow(ax=ax1, interpolation='nearest',\n    vmin=ds.values.min(), vmax=ds.values.max(),\n    cmap=plt.cm.gray_r)\n# add coastlines\ngshhg_i.plot(ax=ax1, color='none', edgecolor='black')\n# set x and y limits\nax1.set_xlim(warped.x.min(), warped.x.max())\nax1.set_ylim(warped.y.min(), warped.y.max())\nax1.set_aspect('equal', adjustable='box')\n# add x and y labels\nax1.set_xlabel('Longitude')\nax1.set_ylabel('Latitude')\n# adjust subplot and show\nfig.subplots_adjust(left=0.06,right=0.98,bottom=0.08,top=0.98)\n\nTip\n\nWe might have wanted to use the full resolution coastlines!\n\n","type":"content","url":"/notebooks/geospatial-transforms#rasterio-transforms","position":49},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Saving Raster Data with rioxarray","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"type":"lvl4","url":"/notebooks/geospatial-transforms#saving-raster-data-with-rioxarray","position":50},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl4":"Saving Raster Data with rioxarray","lvl3":"Warping Raster Imagery","lvl2":"Geospatial Data"},"content":"\n\n# write an array as a raster band\n# copernicus DEM naming convention for spacing:\n# 03: 0.3-arcsecond grid, 04: 0.4-arcsecond grid, 10: 1-arcsecond grid, 30: 3-arcsecond grid\nwarped.rio.to_raster('Copernicus_DSM_80_N47_00_W123_00_DEM.tif', driver='cog')\n\n","type":"content","url":"/notebooks/geospatial-transforms#saving-raster-data-with-rioxarray","position":51},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Applying Concepts: ICESat-2"},"type":"lvl2","url":"/notebooks/geospatial-transforms#applying-concepts-icesat-2","position":52},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Applying Concepts: ICESat-2"},"content":"Let’s take what we just learned and apply it to ICESat-2\n\nWe’ll download a granule of ICESat-2 ATL06 land ice heights from the \n\nNational Snow and Ice Data Center (NSIDC).  ATL06 is along-track data stored in an HDF5 file with geospatial coordinates latitude and longtude (WGS84).  Within an ATL06 file, there are six beam groups (gt1l, gt1r, gt2l, gt2r, gt3l, gt3r) that correspond to the orientation of the beams on the ground.\n\ndef build_granule_name(short_name, track, cycle, hemisphere=None, granule=None):\n    # repeat ground track (RGT)\n    tttt = str(track).zfill(4)\n    # orbital cycle\n    cc = str(cycle).zfill(2)\n    # ice hemisphere flag (01=north, 02=south) \n    hh = str(hemisphere).zfill(2) if hemisphere is not None else \"??\"\n    # granule number (ranges from 1-14, always 01 for atmosphere products)\n    nn = str(granule).zfill(2) if granule is not None else \"??\"\n    # patterns vary by product\n    along_track_products = (\"ATL03\", \"ATL04\", \"ATL06\", \"ATL08\",\n        \"ATL09\", \"ATL10\", \"ATL12\", \"ATL13\", \"ATL16\", \"ATL17\",\n        \"ATL19\", \"ATL22\", \"ATL24\")\n    sea_ice_products = (\"ATL07\", \"ATL10\", \"ATL20\", \"ATL21\")\n    # use single character wildcards \"?\" for any unset parameters\n    if short_name in sea_ice_products:\n        return f\"{short_name}-{hh}_{14 * '?'}_{tttt}{cc}??_*\"\n    elif short_name in along_track_products:\n        return f\"{short_name}_{14 * '?'}_{tttt}{cc}{nn}_*\"\n\n# build credentials for accessing ICESat-2 data\nauth = earthaccess.login(strategy=\"environment\")\n# query CMR for ATL06 files\npattern = build_granule_name(short_name=\"ATL06\", track=9, cycle=14, granule=12)\ngranules = earthaccess.search_data(\n    short_name=\"ATL06\",\n    granule_name=pattern,\n)\ngranules[0]\n\n# download or stream ATL06 granules\nif (AWS_DEFAULT_REGION == 'us-west-2'):\n    buffers = earthaccess.open(granules)\nelse:\n    buffers = earthaccess.download(granules, local_path='.')\n# read multiple HDF5 groups and merge into a dataset\ngroups = ['gt1l/land_ice_segments', 'gt1l/land_ice_segments/dem']\nds = xr.merge([xr.open_dataset(buffers[0], group=g) for g in groups])\n# inspect ATL06 data for beam group\nds\n\nxarray has a handy to_dataframe function to convert to pandas\n\n# For simplicity take first 500 high-quality points into a Geopandas Geodataframe\ndf = ds.where(ds.atl06_quality_summary==0).isel(delta_time=slice(0,500)).to_dataframe()\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs='epsg:7661')\ngdf.head()\n\nuse explore to create an interactive map of our ICESat-2 points\n\ngdf.explore(column='h_li')\n\n","type":"content","url":"/notebooks/geospatial-transforms#applying-concepts-icesat-2","position":53},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Copernicus DEM","lvl2":"Applying Concepts: ICESat-2"},"type":"lvl3","url":"/notebooks/geospatial-transforms#copernicus-dem","position":54},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Copernicus DEM","lvl2":"Applying Concepts: ICESat-2"},"content":"Let’s compare ICESat-2 elevations against a public, gridded global digital elevation model (DEM), the \n\nCopernicus DEM. This DEM is with respect to the EGM2008 geoid, and so we’ll have to convert our ICESat-2 points to be comparable.\n\nJust as Geopandas adds CRS-aware capabilities to Dataframes, RioXarray adds CRS-aware functions to XArray multidimensional arrays (e.g. sets of images).\n\nCOP30 = rioxarray.open_rasterio('https://opentopography.s3.sdsc.edu/raster/COP30/COP30_hh.vrt', chunks=True)\n# Crop by Bounding box of all the ATL06 points\nminx, miny, maxx, maxy = gdf.total_bounds\nCOP30 = COP30.rio.clip_box(minx, miny, maxx, maxy).sel(band=1)\nCOP30\n\n","type":"content","url":"/notebooks/geospatial-transforms#copernicus-dem","position":55},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Convert ATL06 Ellipsoidal Heights to Orthometric","lvl2":"Applying Concepts: ICESat-2"},"type":"lvl3","url":"/notebooks/geospatial-transforms#convert-atl06-ellipsoidal-heights-to-orthometric","position":56},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Convert ATL06 Ellipsoidal Heights to Orthometric","lvl2":"Applying Concepts: ICESat-2"},"content":"Check out the \n\nICESat-2 User Comparison Guide for more info\n\ngdf['h_ortho'] = gdf.h_li - (gdf.geoid_h + gdf.geoid_free2mean)\n# calculate elevation difference between ATL06 and COP30\nx = xr.DataArray(gdf.geometry.x.values, dims='z')\ny = xr.DataArray(gdf.geometry.y.values, dims='z')\ngdf['dh'] = gdf.h_ortho - COP30.sel(x=x, y=y, method='nearest')\n\n","type":"content","url":"/notebooks/geospatial-transforms#convert-atl06-ellipsoidal-heights-to-orthometric","position":57},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Compare COP30 DEM with ATL06","lvl2":"Applying Concepts: ICESat-2"},"type":"lvl3","url":"/notebooks/geospatial-transforms#compare-cop30-dem-with-atl06","position":58},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl3":"Compare COP30 DEM with ATL06","lvl2":"Applying Concepts: ICESat-2"},"content":"\n\nfig, ax = plt.subplots(ncols=3, sharex=True, sharey=True)\ncmap1 = plt.get_cmap('viridis')\ncmap2 = plt.get_cmap('coolwarm')\nvmin = np.minimum(COP30.min().values, gdf.h_ortho.min())\nvmax = np.maximum(COP30.max().values, gdf.h_ortho.max())\nCOP30.plot.imshow(ax=ax[0], cmap=cmap1, vmin=vmin, vmax=vmax, add_labels=False, add_colorbar=False)\ngdf.plot(column=\"h_ortho\", ax=ax[1], cmap=cmap1, vmin=vmin, vmax=vmax, markersize=1, legend=True)\ngdf.plot(column=\"dh\", ax=ax[2], cmap=cmap2, norm=mcolors.CenteredNorm(), markersize=1, legend=True)\nfig.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/geospatial-transforms#compare-cop30-dem-with-atl06","position":59},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Resources"},"type":"lvl2","url":"/notebooks/geospatial-transforms#resources","position":60},{"hierarchy":{"lvl1":"Geospatial Transforms","lvl2":"Resources"},"content":"There is a lot of great educational material to learn more about these topics. We recommend checking out:\n\nUW Cryo 3D CRS Guide\n\nUW Geospatial Data Analaysis with Python\n\nPennState GPS & GNSS for Geospatial Professionals\n\nQinsy Geodetic Documentation\n\nGISGeography","type":"content","url":"/notebooks/geospatial-transforms#resources","position":61},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance"},"type":"lvl1","url":"/notebooks/governance","position":0},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance"},"content":"","type":"content","url":"/notebooks/governance","position":1},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl2","url":"/notebooks/governance#governance-for-the-nasa-icesat-2-mission-cookbook","position":2},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Purpose\n\nThis cookbook provides an open, community driven, and sustainable space to consolidate workflows, tools, and tutorials related to NASA’s ICESat-2 mission. It draws from successful governance structures used in \n\nProject Pythia and promotes openness, reproducibility, and accessibility.","type":"content","url":"/notebooks/governance#governance-for-the-nasa-icesat-2-mission-cookbook","position":3},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"1. Scope","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-1-scope","position":4},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"1. Scope","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"The NASA ICESat-2 Cookbook aims to:\n\nProvide foundational tutorials and example workflows for ICESat-2 data products\n\nImprove accessibility of training materials\n\nEnsure high-quality, reproducible examples that can be run via Binder or cloud platforms\n\nFoster collaboration between mission scientists, tool developers, educators, and learners","type":"content","url":"/notebooks/governance#id-1-scope","position":5},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-2-governance-structure","position":6},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"","type":"content","url":"/notebooks/governance#id-2-governance-structure","position":7},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Steering Committee","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#steering-committee","position":8},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Steering Committee","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"The Steering Committee oversees the vision, content quality, and community processes. Suggested roles include:\n\nChair / Lead Maintainer – provides overall coordination and direction\n\nTechnical Lead – manages infrastructure (CI/CD, Binder, etc.)\n\nContent Lead – ensures tutorial clarity, structure, and mission alignment\n\nCommunity Liaison – coordinates community engagement and outreach\n\nMembership includes NASA ICESat‑2 scientists, data tool developers, educators, and open science advocates.","type":"content","url":"/notebooks/governance#steering-committee","position":9},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Community Contributors","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#community-contributors","position":10},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Community Contributors","lvl3":"2. Governance Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Open to all contributors via GitHub pull requests\n\nAll contributions are governed by this document, a Code of Conduct, and our Contributor Guide\n\nReview occurs via GitHub and requires sign-off from at least one Steering Committee member","type":"content","url":"/notebooks/governance#community-contributors","position":11},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-3-policies-and-licensing","position":12},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"","type":"content","url":"/notebooks/governance#id-3-policies-and-licensing","position":13},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Licensing","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#licensing","position":14},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Licensing","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Code: Apache License 2.0\n\nContent: Creative Commons Attribution 4.0 (CC BY 4.0)","type":"content","url":"/notebooks/governance#licensing","position":15},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Contributor Guide","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#contributor-guide","position":16},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Contributor Guide","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Contributions must follow the structure:\n\nFoundations – Conceptual explanations and mission overviews\n\nExample Workflows – Reproducible scientific applications using real data\n\nUse clear narrative, well-commented Python code, and accessible language","type":"content","url":"/notebooks/governance#contributor-guide","position":17},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Code of Conduct","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#code-of-conduct","position":18},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Code of Conduct","lvl3":"3. Policies and Licensing","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"All participants agree to a Code of Conduct that promotes a respectful, inclusive, and harassment-free environment.","type":"content","url":"/notebooks/governance#code-of-conduct","position":19},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-4-review-and-continuous-integration","position":20},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"","type":"content","url":"/notebooks/governance#id-4-review-and-continuous-integration","position":21},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Contribution Workflow","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#contribution-workflow","position":22},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Contribution Workflow","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Pull Request → Peer Review by Leads → CI Tests & Binder Checks → Merge","type":"content","url":"/notebooks/governance#contribution-workflow","position":23},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Infrastructure","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#infrastructure","position":24},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Infrastructure","lvl3":"4. Review and Continuous Integration","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Hosted on GitHub\n\nBuilt using Jupyter Book\n\nContinuous Integration with GitHub Actions:\n\nBuilds the book\n\nChecks notebook execution\n\nVerifies Binder launch\n\nInteractive Binder and/or JupyterHub (e.g., 2i2c) links provided","type":"content","url":"/notebooks/governance#infrastructure","position":25},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-5-content-structure","position":26},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"","type":"content","url":"/notebooks/governance#id-5-content-structure","position":27},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Foundations","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#foundations","position":28},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Foundations","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Tutorials in this section explain core ICESat‑2 mission concepts and tools:\n\nData products: ATL03, ATL06, ATL07, ATL24, etc.\n\nPhoton filtering and quality assessment\n\nAccess methods (e.g., NSIDC, Earthdata, SlideRule)","type":"content","url":"/notebooks/governance#foundations","position":29},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Example Workflows","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl4","url":"/notebooks/governance#example-workflows","position":30},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl4":"Example Workflows","lvl3":"5. Content Structure","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Hands-on workflows for using ICESat‑2 data in real-world analyses:\n\nLand Ice Elevation: SlideRule + ATL06, cloud-based elevation profiles\n\nSea Ice Heights: ATL07 ridge and lead mapping\n\nBathymetry: Coastal bathymetry using ATL03/ATL24\n\nCross-Mission Fusion: Examples with ICESat‑2, Landsat, Sentinel, SWOT\n\nEach notebook should include:\n\nClear objectives\n\nRequired libraries/environment\n\nCode and narrative\n\nOutput plots or maps","type":"content","url":"/notebooks/governance#example-workflows","position":31},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"6. Community Engagement & Sustainability","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-6-community-engagement-sustainability","position":32},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"6. Community Engagement & Sustainability","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Periodic “Cookbook Hackweeks” or sprint events\n\nIntegration with NASA Openscapes, Pangeo, and Earthdata tutorials\n\nOutreach via Discourse, GitHub Discussions, and webinars\n\nQuarterly content audits to ensure relevance and quality","type":"content","url":"/notebooks/governance#id-6-community-engagement-sustainability","position":33},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"7. Governance Summary Table","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"type":"lvl3","url":"/notebooks/governance#id-7-governance-summary-table","position":34},{"hierarchy":{"lvl1":"ICESat-2 Cookbook Governance","lvl3":"7. Governance Summary Table","lvl2":"Governance for the NASA ICESat‑2 Mission Cookbook"},"content":"Element\n\nDescription\n\nSteering Committee\n\nLeads vision, content standards, CI, and maintenance\n\nContributors\n\nOpen community contributors via PRs, reviewed by Leads\n\nLicense\n\nCode: Apache 2.0, Content: CC BY 4.0\n\nWorkflow\n\nPR → Review → CI → Merge\n\nInfrastructure\n\nGitHub, GitHub Actions, Jupyter Book, Binder, 2i2c\n\nContent Format\n\nFoundations + Example Workflows\n\nCommunity\n\nHackweeks, partnerships, discourse channels\n\nSustainability\n\nVersioned releases and maintenance aligned with mission & data updates\n\nGet Involved!\n\nTo contribute, visit our \n\nGitHub repository and follow the Contributor Guide. We welcome tutorials, bug fixes, and suggestions!","type":"content","url":"/notebooks/governance#id-7-governance-summary-table","position":35},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology"},"type":"lvl1","url":"/notebooks/inland-hydrology","position":0},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology"},"content":"","type":"content","url":"/notebooks/inland-hydrology","position":1},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/inland-hydrology#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Author(s)"},"content":"Shamsudeen Temitope Yekeen","type":"content","url":"/notebooks/inland-hydrology#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/inland-hydrology#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Existing Notebooks"},"content":"Inland Hydrology Applications","type":"content","url":"/notebooks/inland-hydrology#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/inland-hydrology#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl2":"Learning Outcomes"},"content":"Understanding the ICESat-2 ATL13 product and its usage in inland hydrology\n\nAbility to access and extract required subset variables ATL13 data product\n\nParticipants would be able to create a water surface elevation dynamics","type":"content","url":"/notebooks/inland-hydrology#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/inland-hydrology#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Inland Hydrology","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"","type":"content","url":"/notebooks/inland-hydrology#notes","position":9},{"hierarchy":{"lvl1":"Land Ice Applications"},"type":"lvl1","url":"/notebooks/land-ice","position":0},{"hierarchy":{"lvl1":"Land Ice Applications"},"content":"","type":"content","url":"/notebooks/land-ice","position":1},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/land-ice#author-s","position":2},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"Author(s)"},"content":"Ben Smith, Rohaiz Haris","type":"content","url":"/notebooks/land-ice#author-s","position":3},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/land-ice#learning-outcomes","position":4},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"Learning Outcomes"},"content":"How different ICESat-2 land ice products (ATL14/15, ATL11, ATL06) relate to each other\n\nLearn the basics of retrieving land ice products using icepyx\n\nLearn how ICESat-2 land ice products can be used to study ice-surface height changes\n\nOpen, plot, and explore gridded and along-track data","type":"content","url":"/notebooks/land-ice#learning-outcomes","position":5},{"hierarchy":{"lvl1":"Land Ice Applications","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/land-ice#notes","position":6},{"hierarchy":{"lvl1":"Land Ice Applications","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"\n\n","type":"content","url":"/notebooks/land-ice#notes","position":7},{"hierarchy":{"lvl1":"Land Ice Applications","lvl3":"Prerequisites","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/land-ice#prerequisites","position":8},{"hierarchy":{"lvl1":"Land Ice Applications","lvl3":"Prerequisites","lvl2":"Learning Outcomes"},"content":"Concepts\n\nImportance\n\nNotes\n\nxarray\n\nNecessary\n\nICESat-2 data in this tutorial will appear as xarray dataframes\n\nnumpy/matplotlib\n\nNecessary\n\nWe will do our plotting with matplotlib\n\nICESat-2 Mission Overview\n\nNecessary\n\nHere is where to go to understand the ICESat-2 mission and its goals\n\nTime to learn:  30 min.\n\n# import packages:\nimport numpy as np                   # Numeric Python\nimport matplotlib.pyplot as plt      # Plotting routines\nimport h5py                          # general HDF5 reading/writing library\nimport xarray as xr\nfrom pyproj import Transformer, CRS  # libraries to allow coordinate transforms\nimport glob                          # Package to locate files on disk\nimport os                            # File-level utilities\nimport re                            # regular expressions for string interpretation\nimport icepyx as ipx                 # Package to interact with ICESat-2 online resources\nimport earthaccess\nfrom matplotlib import cm\nimport matplotlib as mpl\n#%matplotlib widget\n\n","type":"content","url":"/notebooks/land-ice#prerequisites","position":9},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"What is Land Ice?"},"type":"lvl2","url":"/notebooks/land-ice#what-is-land-ice","position":10},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"What is Land Ice?"},"content":"Land ice is frozen water that is grounded on land. They are formed through the accumulation of snowfall in regions where annual snowfall exceeds annual snow melt. The accumulation of snow over thousands of years leads to the compression of snow into dense ice. Over 99 percent of Earth’s land ice is present in the Antarctic and Greenland Ice Sheets, and the remaining are glaciers located in alpine regions. Land ice heights evolve with time due to ice flow and accumulation/ablation.","type":"content","url":"/notebooks/land-ice#what-is-land-ice","position":11},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"How ICESat-2 measures land ice height"},"type":"lvl2","url":"/notebooks/land-ice#how-icesat-2-measures-land-ice-height","position":12},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"How ICESat-2 measures land ice height"},"content":"Laser altimeters are valuable instruments for measuring land ice height across large spatial areas. ICESat-2 works by sending out photons that bounce off the ice surface; by recording how long it takes for the photons to travel to the ice and back, the satellite can calculate land ice height. ICESat-2’s 91-day repeat cycle enables the monitoring of both seasonal and annual variations in ice surface height. For more details of the ICESat-2 mission, check out the \n\nmission overview page\n\nATL06 provides geolocated land-ice surface heights relative to the WGS84 ellipsoid. It is derived from geolocated photons of the ATL03 product over short segments (40 m).\n\nATL11 provides a time-series of land-ice surface heights derived from the ATL06 product.\n\nATL14 is a spatially continuous gridded product of land-ice surface heights derived from the ATL11 product. ATL15 provides gridded surface height-change maps over time intervals as fine as 3 months.\n\n","type":"content","url":"/notebooks/land-ice#how-icesat-2-measures-land-ice-height","position":13},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"The Problem"},"type":"lvl2","url":"/notebooks/land-ice#the-problem","position":14},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"The Problem"},"content":"We will be looking at Svalbard in the Norwegian Arctic, focusing on the massive surge from the Austfonna ice cap. This started in 2010, and the ice cap is still adjusting to the rapid loss of ice, so we expect to see large thinning rates in the area affected by the surge. We will use the ICESat-2 ATL15 product for a look at the mass-loss pattern over the last three years.\n\n\n\n“Photo credit: Schuler et. al, Front. Earth Sci., 27 May 2020 | \n\nSchuler et al. (2020)”\n\n","type":"content","url":"/notebooks/land-ice#the-problem","position":15},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL15"},"type":"lvl2","url":"/notebooks/land-ice#atl15","position":16},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL15"},"content":"ATL15 is one of the various ICESat-2 data products. ATL15 provides various resolutions (1 km, 10 km, 20 km, and 40 km) of gridded raster data of height change at 3-month intervals, allowing for visualization of height-change patterns and calculation of integrated active subglacial lake volume change (Smith and others, 2022).\n\nATL14 is an accompanying high-resolution (100 m) digital elevation model (DEM) that provides spatially continuous gridded data of ice sheet surface height.\n\nATL14 and ATL15 are higher level products derived from lower level products (ATL11) that allow for simplified volume change calculations. However, the finest temporal resolution is 3 months which may be too coarse for certain applications. ATL14 estimates also degrade where measurements are unavailable. Potential use cases for ATL14 and ATL15 are gridded estimates of height change for ice sheet models or the creation of land ice mass balance estimates\n\nWe can use the icepyx library to access ICESat-2 data. For a deeper dive into icepyx, check out their \n\ndocumentation. We first query for the spatial region and the time period that we are interested in\n\nregion_a = ipx.Query('ATL15',[10, 79, 30, 81],['2019-01-01','2023-01-01'])\n\nWe can visualize this spatial extent also.\n\nregion_a.visualize_spatial_extent()\n\n\nLet us now place an order for the granules that are available over our spatial region and time period and download the files. This following cell will prompt you for your earthdata account username and password. Creating an account is free and can be done \n\nhere.\n\ncheck_fileexist = glob.glob('./data/ATL15*')\nif not check_fileexist:\n    order = region_a.order_granules(subset=True) \n    files = order.download_granules(\"./data\")\nelse:\n    print(\"ATL15 files already exist\")\n\n\nATL15 data comes in NetCDF format. Let’s take a look at the structure of these files.\n\nf_name = glob.glob(\"./data/ATL15*\")\nf = xr.open_datatree(f_name[0])\nprint(f)\n\nWe can see that there are many groups in this file. We’ll be plotting the delta_h data variable in this tutorial, here’s what we can learn about from these sources:\n\nATL14/15’s \n\noverview page: this is likely the ‘quarterly height changes’ described, but let’s dive deeper to be sure\n\nATL14/15’s Xarray Dataset imbedded metadata tells us a couple things: delta_h =height change at 1 km (the resolution selected earlier) and height change relative to the datum (Jan 1, 2020) surface\n\nATL14/15’s \n\ndata dictionary: delta_h = quarterly height change at 40 km\n\nOk, since the data is relative to a datum, we have two options:\n\nDifference individual time slices to subtract out the datum, like so:\n\n(time0 - datum) - (time1 - datum) = time0 - datum - time1 + datum = time0 - time1\n\nSubtract out the datum directly. The datum is the complementary dataset high-resolution DEM surface contained in tha accompanying dataset ATL14.\n\nIn this tutorial we’ll use the first method to look at how the ice surface height has evolved in time.\n\nLets look at the structure of the file\n\nds = xr.open_dataset(\"./data/ATL15_SV_0325_01km_004_05.nc\",group='delta_h')\nds\n\nLets look at the difference in ice-surface height over the first quarter and plot them\n\nfig, ax = plt.subplots(figsize=(4,5), tight_layout=True)\ndhdt = ds['delta_h'][1,:,:] - ds['delta_h'][0,:,:]\nextent=np.array([np.min(ds['x'])-500, np.max(ds['x'])+500, np.min(ds['y'])-500, np.max(ds['y'])+500])\ncb = ax.imshow(dhdt, origin='lower', cmap='coolwarm_r', extent=extent, aspect=\"auto\", vmin=dhdt.min(), vmax=-dhdt.min())\nax.set_xlabel('Polar Stereographic X (m)'); ax.set_ylabel('Polar Stereographic Y (m)')\nplt.colorbar(cb, fraction=0.02, label='height change [m]')\nplt.show()\n\nWe see the difference in ice surface height for all of Svalbard. Let us zoom in to the feature of interest in Austfonna Glacier.\n\nxlim = [1e6, 1.1e6]\nylim = [-4.5e5, -3.5e5]\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\ndhdt = ds['delta_h'][1,:,:] - ds['delta_h'][0,:,:]\nextent=np.array([np.min(ds['x'])-500, np.max(ds['x'])+500, np.min(ds['y'])-500, np.max(ds['y'])+500])\ncb = ax.imshow(dhdt, origin='lower', cmap='coolwarm_r', extent=extent, aspect=\"auto\", vmin=dhdt.min(), vmax=-dhdt.min())\nax.set_xlabel('Polar Stereographic X (m)'); ax.set_ylabel('Polar Stereographic Y (m)')\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nplt.colorbar(cb, fraction=0.02, label='height change [m]')\n\n\nWe can see a clear signal of significant decrease in height at the center of this glacier leading out into the coastline. Now what if we want to see how the ice surface height evolves over a transect? Let’s try that.\n\n### TBC Code\n\nTBC what we are seeing in the profiles\n\nWhat if we don’t want to deal with interpolated data, and would rather see the data collected over an ICESat-2 reference ground track? Enter ATL11\n\n","type":"content","url":"/notebooks/land-ice#atl15","position":17},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL11"},"type":"lvl2","url":"/notebooks/land-ice#atl11","position":18},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL11"},"content":"We might be interested to see where these height changes come from. ATL15 is derived from the ATL11 (slope-corrected along-track height change) product, which maps height changes for individual ICESat-2 reference tracks. It contains data for all cycles with along-track data following the Reference Ground Tracks (RGTs) and allows for the easy calculation of along-track height-change through time. However, it may not work well over complex surfaces and its 120m resolution might be too coarse for certain use cases. Potential use cases would be to make large-scale estimates of glacier and ice sheet height change.\n\nWe can use icepyx to find out what track has contributed to the height change at any given point, but for the purpose of this tutorial we shall use track 0548 which we know crosses over our region of interest. The icepyx library takes in spatial extent search parameters as latitude and longitude while our ICESat-2 data is in polar stereographic coordinates. As such, we make some coordinate transformations first in order to search for ATL11 data.\n\n# Prepare coordinate transformations between lat/lon and the ATL15 coordinate system\ncrs=CRS.from_epsg(3413)\nto_xy_crs=Transformer.from_crs(crs.geodetic_crs, crs)\nto_geo_crs=Transformer.from_crs(crs, crs.geodetic_crs)\n\n\ncorners_lat, corners_lon=to_geo_crs.transform(np.array(xlim)[[0, 1, 1, 0, 0]], np.array(ylim)[[0, 0, 1, 1, 0]])\nlatlims=[np.min(corners_lat), np.max(corners_lat)]\nlonlims=[np.min(corners_lon), np.max(corners_lon)]\n\nNow that we’ve made the necessary coordinate transformations, let us make a query for the data we want.\n\nregion_a = ipx.Query('ATL11', [lonlims[0], latlims[0], lonlims[1], latlims[1]], ['2019-01-01','2023-01-01'], \\\n                          start_time='00:00:00', end_time='23:59:59', tracks = ['0548'])\n\nWe can now order and download the data.\n\ncheck_fileexist = glob.glob('./data/ATL11*')\nif not check_fileexist:\n    region_a.avail_granules()\n    order = region_a.order_granules(subset=True) \n    files = order.download_granules(\"./data\")\nelse:\n    print(\"ATL11 files already exist\")\n\n\n\nWe retrieve two files. Based on the naming convention, the ‘ATL11_054803’ file is the ascending track in the northern mid latitudes and the ‘ATL11_054804’ file is the descending track in the mid-northern-hemisphere. You can read more about the naming convention in the ATL11 \n\nuser guide.\n\nATL11 files are in HDF5 format. We can use the glob package to find the files in the folder we’ve downloaded and the h5py package to open the ascending track file and look at its structure.\n\nATL11_file=glob.glob('./data/ATL11_054803*')[0]\nATL11 = h5py.File(ATL11_file)\nlist(ATL11.keys())\n\nThe ‘pt1’, ’pt2’, and ‘pt3’ groups contain data for the left, middle and right pair tracks. It’s in these tracks that we find the data. Let’s take a look at the middle beam, ‘pt2’.\n\nlist(ATL11['pt2'].keys())\n\nWe are interested in ‘h_corr’, the corrected ice surface height. ‘cycle_number’ lists the cycles that are used for this file and are continually being updated as the ICESat-2 mission progresses. We only want the points over our feature of interest so let us subset the file based on our plot limits as follows.\n\nlat = ATL11['pt2']['latitude'][:]\nlon = ATL11['pt2']['longitude'][:]\nh_corr = ATL11['pt2']['h_corr'][:,:]\ncyc_num = ATL11['pt2']['cycle_number'][:]\nh_corr[h_corr==ATL11['pt2']['h_corr'].attrs['_FillValue']]=np.nan\n\nx_atl11,y_atl11 = to_xy_crs.transform(lat, lon)\n\nind = x_atl11 > xlim[0]\nind &= x_atl11 < xlim[1]\nind &= y_atl11 > ylim[0]\nind &= y_atl11 < ylim[1]\n\nWe can now go ahead and plot the 0548 track over our previous ATL15 data to understand the spatial context of our downloaded ATL11 file.\n\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\nax.imshow(dhdt, origin='lower', cmap='coolwarm_r', extent=extent, aspect=\"auto\", vmin=dhdt.min(), vmax=-dhdt.min())\n#plt.gca().set_aspect(1)\nplt.plot(x_atl11,y_atl11,'.')\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nplt.gca().set_xlabel('Polar Stereographic X (m)')\nplt.gca().set_ylabel('Polar Stereographic Y (m)')\n\nplt.tight_layout()\n\nOur ATL11 file crosses over the high signal of height change. Let us see how the height profile along this track evolves with each cycle (essentially as a function of time).\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\n\nnorm = mpl.colors.Normalize(vmin=min(cyc_num), vmax=max(cyc_num))\ncmap = cm.get_cmap('viridis')\n\n\nfor cycle in cyc_num:\n    cax = ax.plot(x_atl11[ind],h_corr[ind,cycle-3],color=cmap(norm(cycle)))\nplt.colorbar(mpl.cm.ScalarMappable(cmap=cmap, norm=norm), ax=ax, label = \"Cycle Number\")\nplt.legend()\nplt.gca().set_xlabel('Polar Stereographic X (m)')\nplt.gca().set_ylabel('ATL11 Height (m)')\n\nWe can see that at the right and left edges of plot, the ice surface height remains mostly constant. However, in the middle (which lies over the region of strong height change signal), we can see the height decrease as the cycle number increases (and time passes).\n\nWhat if we want to look at the data that went into making ATL11? Let’s take a look at ATL06.\n\n","type":"content","url":"/notebooks/land-ice#atl11","position":19},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL06"},"type":"lvl2","url":"/notebooks/land-ice#atl06","position":20},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"ATL06"},"content":"ATL11 data are generated by combining ALT06 data collected over the same ground track, for different cycles. We can use CMR to identify data from a specific ground track. ATL06 contains overlapping 40-meter linear segments that are fit to land and land-ice photons. It provides estimated surface heights with cm-level corrections and is a lighter and higher-level data product than the ATL03 geolocated photon product. However, its 40m resolution is too coarse for some applications and it is only designed for single surface returns. Potential use cases include making large-scale repeatable measurements of glaciers and ice sheets.\n\nLet’s use icepyx to get the ATL06 files for the 0548 track we have been looking at. To avoid downloading too much data for this tutorial, let’s look into the ATL06 files collected over cycle 3.\n\nregion_b = ipx.Query('ATL06', spatial_extent=[lonlims[0], latlims[0], lonlims[1], latlims[1]], date_range=['2019-01-01','2023-01-01'], \\\n    cycles = [\"03\"], tracks=['0548'])\n\ncheck_fileexist = glob.glob('./data/*ATL06*')\nif not check_fileexist:\n    region_b.avail_granules()\n    order = region_b.order_granules(subset=True)\n    files = order.download_granules(\"./data\")\nelse:\n    print(\"ATL06 files already exist\")\n\n\nNow that we have our ATL06 files, let’s take a look at the structure of one of our files.\n\nATL06_file=glob.glob('./data/*ATL06*0303*')[0]\nATL06 = h5py.File(ATL06_file)\nlist(ATL06.keys())\n\nThe ‘gtxx’ tracks refer to the ground tracks for the six beams on ICESat-2. Each ground track is numbered according to the pattern of tracks on the ground from left to right (GT1L, GT1R, GT2L, GT2R, GT3L, GT3R).  The labeling was chosen such that the beam names do not change when the observatory orientation changes. Let us take a look at the beam data for GT2R, which resides in the ‘land_ice_segments’ group.\n\nlist(ATL06['gt2r']['land_ice_segments'].keys())\n\nWe are interested in ‘h_li’, the land ice height. Let’s plot the ground tracks over our ATL15 data.\n\nlat = ATL06['gt2r']['land_ice_segments']['latitude'][:]\nlon = ATL06['gt2r']['land_ice_segments']['longitude'][:]\nh_li = ATL06['gt2r']['land_ice_segments']['h_li'][:]\nh_li[h_li==ATL06['gt2r']['land_ice_segments']['h_li'].attrs['_FillValue']]=np.nan\n\nx_atl06,y_atl06 = to_xy_crs.transform(lat, lon)\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\nax.imshow(dhdt, origin='lower', cmap='coolwarm_r', extent=extent, aspect=\"auto\", vmin=dhdt.min(), vmax=-dhdt.min())\n#plt.gca().set_aspect(1)\nplt.plot(x_atl06,y_atl06,'.')\nax.set_xlim(xlim)\nax.set_ylim(ylim)\nplt.gca().set_xlabel('Polar Stereographic X (m)')\nplt.gca().set_ylabel('Polar Stereographic Y (m)')\n\nplt.tight_layout()\n\nWe can now plot the ATL06 data over our ATL11 data for the third cycle and see how they compare.\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\n\nax.plot(x_atl11[ind],h_corr[ind,0], label=\"ATL11\")\nax.plot(x_atl06,h_li, label = \"ATL06\")\nplt.legend()\nplt.gca().set_xlabel('Polar Stereographic X (m)')\nplt.gca().set_ylabel('Ice Surface height (m)')\n\nWhat gives? It’s likely that some of the ATL06 data is bad. Fortunately, ATL06 comes with a quality flag (atl06_quality_summary) that identifies segments that are likely good (zero means no problems). Let’s filter out the bad data and try this again with the good data.\n\nfig, ax = plt.subplots(figsize=(5,4), tight_layout=True)\n\ngood=(ATL06['gt2r']['land_ice_segments']['atl06_quality_summary'][:]==0)\nif np.any(good):\n        plt.plot(x_atl06[good],h_li[good],'.', label = \"ATL06\")\nplt.plot(x_atl11[ind],h_corr[ind,0], label = \"ATL11\")\nplt.legend()\nplt.gca().set_xlabel('Polar Stereographic X (m)')\nplt.gca().set_ylabel('Ice Surface Height (m)')\n\n\nGreat success! We see that our ATL06 data is colocated with the ATL11 data now.\n\n","type":"content","url":"/notebooks/land-ice#atl06","position":21},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"TBC Conclusion"},"type":"lvl2","url":"/notebooks/land-ice#tbc-conclusion","position":22},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"TBC Conclusion"},"content":"We have briefly explored how to use different ICESat-2 land ice products to study ice mass loss in Svalbard and how to interact with these datasets. It is worth noting that ICESat-2 land ice products have been used in many other ways, here is a list of some publications that have used these products.\n\nTBC papers that have used these datasets and are good references\n\n","type":"content","url":"/notebooks/land-ice#tbc-conclusion","position":23},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"References"},"type":"lvl2","url":"/notebooks/land-ice#references","position":24},{"hierarchy":{"lvl1":"Land Ice Applications","lvl2":"References"},"content":"Smith, B., Fricker, H. A., Holschuh, N., Gardner, A. S., Adusumilli, S., Brunt, K. M., et al. (2019). Land ice height-retrieval algorithm for NASA’s ICESat-2 photon-counting laser altimeter. Remote Sensing of Environment, 233, 111352. doi:Smith et al. (2019)\n\nSmith, B., T. Sutterley, S. Dickinson, B. P. Jelley, D. Felikson, T. A. Neumann, H. A. Fricker, A. Gardner, L. Padman, T. Markus, N. Kurtz, S. Bhardwaj, D. Hancock, and J. Lee. (2022). ATLAS/ICESat-2 L3B Gridded Antarctic and Arctic Land Ice Height Change, Version 2 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. Smith et al. (2022).\n\nSmith, B., T. Sutterley, S. Dickinson, B. P. Jelley, D. Felikson, T. A. Neumann, H. A. Fricker, A. Gardner, L. Padman, T. Markus, N. Kurtz, S. Bhardwaj, D. Hancock, and J. Lee. “ATL15 Data Dictionary (V01).” National Snow and Ice Data Center (NSIDC), 2021-11-29. \n\nhttps://​nsidc​.org​/data​/documentation​/atl15​-data​-dictionary​-v01.\n\nSauthoff, W., L. Lopez, J. Scheick, T. Snow. IS2-ATL15 Surface-Height Anomalies. CryoCloud: Accelerating discovery for NASA Cryosphere communities. Retrieved August 20, 2025, from \n\nhttps://​book​.cryointhecloud​.com​/is2​-atl15​-surface​-height​-anomalies.","type":"content","url":"/notebooks/land-ice#references","position":25},{"hierarchy":{"lvl1":"DRAFT: Machine Learning"},"type":"lvl1","url":"/notebooks/machine-learning","position":0},{"hierarchy":{"lvl1":"DRAFT: Machine Learning"},"content":"","type":"content","url":"/notebooks/machine-learning","position":1},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/machine-learning#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Author(s)"},"content":"Yara Mohajerani, Shane Grigsby, Wei Ji Leong","type":"content","url":"/notebooks/machine-learning#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/machine-learning#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Existing Notebooks"},"content":"ML with ICESat-2 Data\n\nML Neural Networks, Bayesian","type":"content","url":"/notebooks/machine-learning#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/machine-learning#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl2":"Learning Outcomes"},"content":"Convert ICESat-2 point cloud data into an analysis/ML-ready format\n\nRecognize the different levels of complexity of ML approaches and\nthe benefits/challenges of each\n\nLearn the potential of using ML for ICESat-2 point cloud classification","type":"content","url":"/notebooks/machine-learning#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/machine-learning#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Machine Learning","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"Probably focus on Wei Ji’s tutorial, but could point to the earlier work\nof Yara and Shane for more advanced/theoretical concepts?","type":"content","url":"/notebooks/machine-learning#notes","position":9},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview"},"type":"lvl1","url":"/notebooks/mission-overview","position":0},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview"},"content":"","type":"content","url":"/notebooks/mission-overview","position":1},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl3":"Author(s)"},"type":"lvl3","url":"/notebooks/mission-overview#author-s","position":2},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl3":"Author(s)"},"content":"Tyler Sutterley\n\nExisting Tutorials\n\nMission Overview - 2024 ICESat-2 hackweek\n\nMission Overview and Data - 2023 ICESat-2 hackweek\n\nLearning Outcomes\n\nunderstand the technology used to acquire ICESat-2 data products and how that\ninforms data coverage, resolution and frequency\n\nlearn about the hierarchy of data products and the factors influencing\ndecisions on which products to use\n\n","type":"content","url":"/notebooks/mission-overview#author-s","position":3},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl2","url":"/notebooks/mission-overview#part-1-mission-and-instrument-overview","position":4},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\n","type":"content","url":"/notebooks/mission-overview#part-1-mission-and-instrument-overview","position":5},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Science Objectives","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-science-objectives","position":6},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Science Objectives","lvl2":"Part 1: Mission and Instrument Overview"},"content":"Quantify polar ice sheet contributions to current and recent sea level change and the linkages to climate conditions\n\nQuantify regional signatures of ice sheet changes\n\nAssess mechanisms driving recent changes\n\nImprove predictive ice sheet models\n\nEstimate sea ice thickness to examine ice-ocean-atmosphere exchanges of energy, mass and moisture\n\nMeasure vegetation canopy height as a basis for estimating large-scale biomass and biomass change\n\n\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-science-objectives","position":7},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Advanced Topographic Laser Altimeter System (ATLAS)","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#advanced-topographic-laser-altimeter-system-atlas","position":8},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Advanced Topographic Laser Altimeter System (ATLAS)","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 1:ICESat-2 beam configuration \n\n(Neuenschwander, 2019)\n\nSingle 10kHz 532nm laser micro-pulse → split into 6 beams\n\nDetectors sensitive to green light returns at the single photon level\n\nOn-the-ground 3 km spacing between pairs to increase spatial coverage\n\nOn-the-ground 90 m pair spacing for slope determination\n\nDifferent beam energies to provide dynamic range for varying surface reflectances\n\nHigh-energy beams (4×) for better performance over low-reflectivity targets\n\n","type":"content","url":"/notebooks/mission-overview#advanced-topographic-laser-altimeter-system-atlas","position":9},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Transmitter","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#atlas-transmitter","position":10},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Transmitter","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 2:ATLAS transmitter diagram (ATL03 ATBD)\n\n","type":"content","url":"/notebooks/mission-overview#atlas-transmitter","position":11},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Receiver","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#atlas-receiver","position":12},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Receiver","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 3:ATLAS receiver diagram (ATL03 ATBD)\n\n","type":"content","url":"/notebooks/mission-overview#atlas-receiver","position":13},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Photon Timing","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#atlas-photon-timing","position":14},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATLAS Photon Timing","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 4:ATLAS photon timing diagram (ATL03 ATBD)\n\n","type":"content","url":"/notebooks/mission-overview#atlas-photon-timing","position":15},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-photon-geolocation","position":16},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"content":"","type":"content","url":"/notebooks/mission-overview#icesat-2-photon-geolocation","position":17},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Photon time of flight","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl5","url":"/notebooks/mission-overview#photon-time-of-flight","position":18},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Photon time of flight","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"content":"Measuring the two-way return time of transmitted photons","type":"content","url":"/notebooks/mission-overview#photon-time-of-flight","position":19},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Position of observatory in space","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl5","url":"/notebooks/mission-overview#position-of-observatory-in-space","position":20},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Position of observatory in space","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"content":"Precision Orbit Determination (POD) – NASA GSFC\n\nBased on Ruag GPS receivers\n\nVerified with Satellite Laser Ranging (SLR)\n\nOrbit known to < 2 cm radial","type":"content","url":"/notebooks/mission-overview#position-of-observatory-in-space","position":21},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Pointing vectors for ATLAS laser beams","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl5","url":"/notebooks/mission-overview#pointing-vectors-for-atlas-laser-beams","position":22},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Pointing vectors for ATLAS laser beams","lvl4":"ICESat-2 Photon Geolocation","lvl2":"Part 1: Mission and Instrument Overview"},"content":"Precision Pointing Determination (PPD) – UT Austin Applied Research Lab\n\nBased on Sodern Star Trackers and Laser Reference System (LRS)\n\nVerified with cal/val data comparisons with photon returns\n\nPutting the pieces together\n\nPhoton TOF + POD + PPD →\nphoton return bounce point\n\n","type":"content","url":"/notebooks/mission-overview#pointing-vectors-for-atlas-laser-beams","position":23},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Primary Measurements","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-primary-measurements","position":24},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Primary Measurements","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 5:ICESat-2 measurement schematic (ATL02 ATBD)\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-primary-measurements","position":25},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Orbits","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-orbits","position":26},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Orbits","lvl2":"Part 1: Mission and Instrument Overview"},"content":"500 km altitude\n\n88° S to 88° N\n\n15 revolutions/day\n\n1387 repeat ground tracks\n\n91-day revisit time\n\n\n\nFigure 6:ICESat-2 Orbits (NASA Science Visualization Studio)\n\nTip\n\nkml files with predicted ground tracks available at \n\nhttps://​icesat​-2​.gsfc​.nasa​.gov\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-orbits","position":27},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Along-Track Sampling","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-along-track-sampling","position":28},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Along-Track Sampling","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 7:ICESat-2 beam configuration \n\n(Smith et al., 2019)\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-along-track-sampling","position":29},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Spacecraft Orientation","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#spacecraft-orientation","position":30},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Spacecraft Orientation","lvl2":"Part 1: Mission and Instrument Overview"},"content":"\n\nFigure 8:ICESat-2 spacecraft orientation (NSIDC)\n\n","type":"content","url":"/notebooks/mission-overview#spacecraft-orientation","position":31},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Local Coordinate System","lvl2":"Part 1: Mission and Instrument Overview"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-local-coordinate-system","position":32},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Local Coordinate System","lvl2":"Part 1: Mission and Instrument Overview"},"content":"Along-track coordinates, x_atc, are measured parallel to each RGT and are in reference to the equator\n\nAcross-track coordinates, y_atc, are measured perpendicular to and in reference to the RGT\n\nAveraging Schemes:\n\nMeasurements can be averaged over a set along-track distance\n\nMeasurements can be averaged over a set number of photons and have a variable along-track length\n\n\n\nFigure 9:ICESat-2 coordinate system (ATL06 ATBD)\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-local-coordinate-system","position":33},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 2: Data Products"},"type":"lvl2","url":"/notebooks/mission-overview#part-2-data-products","position":34},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 2: Data Products"},"content":"\n\n","type":"content","url":"/notebooks/mission-overview#part-2-data-products","position":35},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Data Production","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-data-production","position":36},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Data Production","lvl2":"Part 2: Data Products"},"content":"\n\nData Production Keywords:\n\nATLAS: Advanced Topographic Laser Altimeter System\n\nASAS: ATLAS Science Algorithm Software\n\nPGE: Product Generation Executive\n\nSIPS: Science Investigator-led Processing System\n\nSCF: Science Computing Facility\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-data-production","position":37},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Product Chart","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-product-chart","position":38},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Product Chart","lvl2":"Part 2: Data Products"},"content":"\n\n","type":"content","url":"/notebooks/mission-overview#icesat-2-product-chart","position":39},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Granule Regions","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#granule-regions","position":40},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Granule Regions","lvl2":"Part 2: Data Products"},"content":"Each orbit of ICESat-2 data is broken up into 14 granules in order to limit the overall file sizes and to reduce the number of files that need to be processed to create the higher-level science products\n\n","type":"content","url":"/notebooks/mission-overview#granule-regions","position":41},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"File Naming Conventions","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#file-naming-conventions","position":42},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"File Naming Conventions","lvl2":"Part 2: Data Products"},"content":"ATL[xx]_[yyyymmdd][hhmmss]_[tttt][cc][nn]_[rrr]_[vv].h5\n\nxx: ATLAS product number\n\nyyyymmdd: year, month and day of data acquisition\n\nhhmmss: start time, hour, minute, and second of data acquisition (UTC)\n\ntttt: Reference Ground Track (RGT, ranges from 1–1387)\n\ncc: Orbital Cycle (91-day period)\n\nnn: Granule number (ranges from 1–14, always 01 for atmosphere products)\n\nrrr: Data release number\n\nvv: Data version number\n\nTip\n\nused for ATL03, ATL04, ATL06, ATL08, ATL09, ATL10, ATL12, ATL13, ATL16, ATL17, ATL19, ATL22 and ATL24\n\n","type":"content","url":"/notebooks/mission-overview#file-naming-conventions","position":43},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"File Naming Conventions: Sea Ice","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#file-naming-conventions-sea-ice","position":44},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"File Naming Conventions: Sea Ice","lvl2":"Part 2: Data Products"},"content":"ATL[xx]-[hh]_[yyyymmdd][hhmmss]_[tttt][cc][nn]_[rrr]_[vv].h5\n\nxx: ATLAS product number\n\nhh: Sea ice hemisphere flag (01=north, 02=south)\n\nyyyymmdd: year, month and day of data acquisition\n\nhhmmss: start time, hour, minute, and second of data acquisition (UTC)\n\ntttt: Reference Ground Track (RGT, ranges from 1–1387)\n\ncc: Orbital Cycle (91-day period)\n\nnn: Granule number (always 01 for sea ice products)\n\nrrr: Data release number\n\nvv: Data version number\n\nTip\n\nused for ATL07, ATL10, ATL20, and ATL21\n\n","type":"content","url":"/notebooks/mission-overview#file-naming-conventions-sea-ice","position":45},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL03: Global Geolocated Photon Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl03-global-geolocated-photon-data","position":46},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL03: Global Geolocated Photon Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nGeolocation, time and elevation for all photons telemetered from ATLAS\n\nPhoton classifications for each surface type\n\nGeophysical and atmospheric corrections\n\nInstrumental parameters\n\nAdvantages:\n\nEvery photon is there, and every parameter\n\nCan derive information for all surface types\n\nDisadvantages:\n\nLarge and complex product\n\nMight require applying instrumental corrections\n\nUse if you want to:\n\nLook at surfaces at a scale unresolved in higher-level products\n\nLook at processes the higher-level products were not designed to observe\n\n\n\nFigure 10:ATL03 photon data and YAPC classification\n\n","type":"content","url":"/notebooks/mission-overview#atl03-global-geolocated-photon-data","position":47},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL04 and ATL09: Atmospheric Backscatter Profiles","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl04-and-atl09-atmospheric-backscatter-profiles","position":48},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL04 and ATL09: Atmospheric Backscatter Profiles","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nAtmospheric layer heights and optical properties\n\nAdvantages:\n\nMuch larger height window provided from the atmospheric data channel\n\nDisadvantages:\n\nRelatively large file sizes\n\nUse if you want to:\n\nWant to investigate cloud or suspended particle optical depths\n\nVisualize cloud returns or Antarctic blowing snow\n\nWant to try to understand atmospheric effects on photon ground returns\n\n\n\nFigure 11:Atmospheric backscatter profiles from \n\nPalm et al. (2021)\n\n","type":"content","url":"/notebooks/mission-overview#atl04-and-atl09-atmospheric-backscatter-profiles","position":49},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL06: Land Ice Height Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl06-land-ice-height-data","position":50},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL06: Land Ice Height Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nOverlapping 40-meter linear segments fit to land and land-ice photons\n\nHeight error and segment quality estimates\n\nAdvantages:\n\nLighter product than ATL03\n\nProvides estimated surface heights with cm-level corrections\n\nDisadvantages:\n\n40 meters is too coarse for some applications\n\nOnly designed for single surface returns\n\nUse if you want to:\n\nMake large-scale repeatable measurements of glaciers and ice sheets\n\n\n\nFigure 12:ATL06 segment model \n\n(Smith et al., 2019)\n\n","type":"content","url":"/notebooks/mission-overview#atl06-land-ice-height-data","position":51},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL11: Slope-Corrected Land Ice Height Time Series","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl11-slope-corrected-land-ice-height-time-series","position":52},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL11: Slope-Corrected Land Ice Height Time Series","lvl2":"Part 2: Data Products"},"content":"Contains:\n\n120-meter along-track segments for each beam pair corrected for across-track slope\n\nCrossover estimates from ATL06 at reference points\n\nAdvantages:\n\nContains data for all cycles with along-track data following the Reference Ground Tracks (RGTs)\n\nEasy calculation of height change through time\n\nDisadvantages:\n\n120-m resolution is too coarse for some applications\n\nMay not work well over complex surfaces\n\nUse if you want to:\n\nMake large-scale estimates of glacier and ice sheet height change\n\n\n\nFigure 13:ATL11 height time series at an Antarctic grounding zone\n\n","type":"content","url":"/notebooks/mission-overview#atl11-slope-corrected-land-ice-height-time-series","position":53},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL14 and ATL15: Gridded Land Ice Height and Height Change","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl14-and-atl15-gridded-land-ice-height-and-height-change","position":54},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL14 and ATL15: Gridded Land Ice Height and Height Change","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nATL14: gridded digital elevation model (DEM) and height uncertainty at 100m posting\n\nATL15: gridded land ice height change estimates at 1km, 10km, 20km, and 40km posting\n\nAdvantages:\n\nGridded product combining all available along-track ATL11 data\n\nSimplifies volume change calculations using ICESat-2 data\n\nDisadvantages:\n\nATL14 estimates degrade where measurements are unavailable\n\nQuarter-annual temporal sampling might not be high enough for certain applications\n\nUse if you want to:\n\nUse gridded estimates of height change for ice sheet models\n\nStart creating land ice mass balance estimates from ICESat-2\n\nExtract land ice height change estimates along transects\n\n\n\n\n\nIS2view display of ATL15 height change data and extracted transect using glacier flowlines from \n\nFelikson et al. (2020).\n\n","type":"content","url":"/notebooks/mission-overview#atl14-and-atl15-gridded-land-ice-height-and-height-change","position":55},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL07: Sea Ice Height Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl07-sea-ice-height-data","position":56},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL07: Sea Ice Height Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nAlong-track heights for sea ice and leads\n\nAdvantages:\n\nHigh precision (~2 cm) height retrievals from 150-photon aggregates\n\nClassifications for varying surface types (e.g. open water leads, sea ice)\n\nProvides auxiliary information such as surface roughness and retrieval quality flags\n\nDisadvantages:\n\nSurface retrievals have varying length scales\n\nSurface type flagging is still in development\n\nUse if you want to:\n\nHave base level surface heights for freeboard or surface process studies\n\n\n\nFigure 14:ATL07 sea ice heights from \n\nKwok et al. (2019)\n\n","type":"content","url":"/notebooks/mission-overview#atl07-sea-ice-height-data","position":57},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL10: Sea Ice Freeboard Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl10-sea-ice-freeboard-data","position":58},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL10: Sea Ice Freeboard Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nAlong-track sea ice freeboard and surface heights\n\nSurface type flagging and ancillary information\n\nAdvantages:\n\nLighter product than ATL07 with higher level freeboard and surface types\n\nDisadvantages:\n\nHigher levels of missing/invalid data than ATL07 (low ice concentration, near-coastal)\n\nVarying length scales of retrievals\n\nSummer sea ice retrievals still under investigation (July 2022 field campaign)\n\nUse if you want to:\n\nUse along-track freeboard retrievals\n\nUse a highly accurate product (3 cm or better over 25 km length scales)\n\n\n\nFigure 15:ATL10 sea ice freeboards from \n\nPetty et al. (2020)\n\n","type":"content","url":"/notebooks/mission-overview#atl10-sea-ice-freeboard-data","position":59},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL20: Gridded Sea Ice Freeboard Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl20-gridded-sea-ice-freeboard-data","position":60},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL20: Gridded Sea Ice Freeboard Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\n25 km gridded sea ice freeboard at daily to monthly resolution\n\nAdvantages:\n\nGridded product that is lighter than ATL10\n\nDisadvantages:\n\nCoarse length scale, averages out the high resolution of the ICESat-2 data\n\nUse if you want to:\n\nLook at gridded sea ice freeboard data for large-scale determination of sea ice change\n\nMerge with other coarse-resolution data such as passive microwave products\n\n\n\nFigure 16:ATL20 gridded freeboard from \n\nKwok et al. (2019)\n\n","type":"content","url":"/notebooks/mission-overview#atl20-gridded-sea-ice-freeboard-data","position":61},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL21: Gridded Polar Sea Surface Height Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl21-gridded-polar-sea-surface-height-data","position":62},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL21: Gridded Polar Sea Surface Height Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\n25 km gridded sea surface height anomalies for sea ice covered regions\n\nAdvantages:\n\nGridded product that is lighter than ATL10\n\nUses a sophisticated sea surface height retrieval algorithm to detect leads in polar oceans\n\nDisadvantages:\n\nCoarse length scale, averages out the high resolution of the ICESat-2 data\n\nOnly data from center strong beam available due to time and spatially varying biases\n\nUse if you want to:\n\nLook at large-scale gridded sea surface height anomalies or derive dynamic ocean topography in polar regions\n\n\n\nFigure 17:ATL21 sea surface heights from \n\nBagnardi et al. (2021)\n\n","type":"content","url":"/notebooks/mission-overview#atl21-gridded-polar-sea-surface-height-data","position":63},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL08: Land and Vegetation Height Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl08-land-and-vegetation-height-data","position":64},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL08: Land and Vegetation Height Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nTerrain surface and canopy heights from land photons\n\nAdvantages:\n\nCan handle surfaces with multiple returns (such as vegetated canopies)\n\nProvides photon-level classifications from the ATL08 algorithm\n\nDisadvantages:\n\nCan produce less reliable results over sloping surfaces\n\nUse if you want to:\n\nDetect multiple surfaces, such as vegetated canopies or supraglacial lakes\n\nLook at vegetated terrain and need to detect the ground\n\n\n\nFigure 18:ATL08 vegetation heights (recreated a figure from Amy Neuenschwander, UT Austin)\n\n","type":"content","url":"/notebooks/mission-overview#atl08-land-and-vegetation-height-data","position":65},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL18: Gridded Land and Vegetation Height (in development)","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl18-gridded-land-and-vegetation-height-in-development","position":66},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL18: Gridded Land and Vegetation Height (in development)","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nTerrain and relative canopy heights at 1km resolution\n\nAdvantages:\n\nUses EASE2.0 grids for compatibility with other datasets\n\nWill be updated annually\n\nDisadvantages:\n\nLow spatial resolution limits creating a temporal change product\n\nUse if you want to:\n\nAnalyze large-scale vegetation and land surface change\n\n\n\nFigure 19:ATL18 gridded vegetation height (provided by Amy Neuenschwander, UT Austin)\n\n","type":"content","url":"/notebooks/mission-overview#atl18-gridded-land-and-vegetation-height-in-development","position":67},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL12: Ocean Surface Height Data","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl12-ocean-surface-height-data","position":68},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL12: Ocean Surface Height Data","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nSea surface heights for oceans deeper than 10m\n\nHarmonic coefficients and statistics for waves\n\nGeophysical (e.g. sea state bias) corrections\n\nAdvantages:\n\nAverage height estimates reduce the effects of correlated noise due to waves\n\nAlso provides sea surface heights with cm-level corrections at spatial resolutions up to 10m\n\nDisadvantages:\n\nDoes not represent the sea surface in ice covered areas\n\nUse if you want to:\n\nDetect the instantaneous sea surface height\n\n\n\nFigure 20:Comparison of ATL12 and JASON-3 from \n\nBuzzanga et al. (2021)\n\n","type":"content","url":"/notebooks/mission-overview#atl12-ocean-surface-height-data","position":69},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL19 and ATL23: Gridded Dynamic Ocean Topography","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#atl19-and-atl23-gridded-dynamic-ocean-topography","position":70},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ATL19 and ATL23: Gridded Dynamic Ocean Topography","lvl2":"Part 2: Data Products"},"content":"Contains:\n\nRasterized DOT at ¼° (mid-latitudes) and 25 km (polar) spatial resolution\n\nMonthly (ATL19) and tri-monthly (ATL23) temporal resolution\n\nAdvantages:\n\nLighter product than ATL12\n\nIncludes individual beam averages\n\nDisadvantages:\n\nLower temporal resolution than ATL12\n\nUse if you want to:\n\nCalculate the average DOT over time\n\nLook at large-scale oceanographic features\n\n\n\nFigure 21:ATL19 dynamic ocean topography\n\n\n\nFigure 22:ATL23 dynamic ocean topography\n\nATL19 and ATL23 DOT from Figures 4 and 5 of \n\nMorison et al. (2022)\n\n","type":"content","url":"/notebooks/mission-overview#atl19-and-atl23-gridded-dynamic-ocean-topography","position":71},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Product Information at the National Snow and Ice Data Center (NSIDC)","lvl2":"Part 2: Data Products"},"type":"lvl4","url":"/notebooks/mission-overview#product-information-at-the-national-snow-and-ice-data-center-nsidc","position":72},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"Product Information at the National Snow and Ice Data Center (NSIDC)","lvl2":"Part 2: Data Products"},"content":"The NSIDC DAAC is the primary data manager for ICESat-2 data\n\nOn-prem data stores\n\nCloud-based data stores (AWS s3)\n\nMission landing page for ICESat-2 → \n\nhttps://​nsidc​.org​/data​/icesat-2\n\nProduct landing pages (e.g. ATL03) → \n\nhttps://​nsidc​.org​/data​/atl03\n\nEach product landing page includes:\n\nUser Guides\n\nAlgorithm Theoretical Basis Documents (ATBDs)\n\nData Dictionaries\n\nList of Known Issues\n\nInformation for Data Access\n\n","type":"content","url":"/notebooks/mission-overview#product-information-at-the-national-snow-and-ice-data-center-nsidc","position":73},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 3: Mission Status and Future"},"type":"lvl2","url":"/notebooks/mission-overview#part-3-mission-status-and-future","position":74},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl2":"Part 3: Mission Status and Future"},"content":"\n\n","type":"content","url":"/notebooks/mission-overview#part-3-mission-status-and-future","position":75},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"type":"lvl4","url":"/notebooks/mission-overview#icesat-2-mission-status","position":76},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"content":"","type":"content","url":"/notebooks/mission-overview#icesat-2-mission-status","position":77},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Future Mission Outlook","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"type":"lvl5","url":"/notebooks/mission-overview#future-mission-outlook","position":78},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Future Mission Outlook","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"content":"Current Status: Nominal\n\nPerformance metrics remain nominal and within mission requirements\n\nOver 2000 days in orbit\n\nOver 2 trillion laser pulses fired\n\nLife-limiting factor is on-board fuel → dependent on solar activity","type":"content","url":"/notebooks/mission-overview#future-mission-outlook","position":79},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Mission Product Development","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"type":"lvl5","url":"/notebooks/mission-overview#mission-product-development","position":80},{"hierarchy":{"lvl1":"ICESat-2 Mission Overview","lvl5":"Mission Product Development","lvl4":"ICESat-2 Mission Status","lvl2":"Part 3: Mission Status and Future"},"content":"Release-07 of along-track products to be released in mid-2025\n\nAlong-Track Coastal and Nearshore Bathymetry (ATL24) released in 2025\n\nGridded Land and Vegetation Height product (ATL18) in development\n\nGridded Sea Ice Freeboard Quicklook product (ATL20-QL) in development\n\nPossible future standard products are under development\n\n\n\n\n\nLinks\n\nWebsite: \n\nhttps://​icesat​-2​.gsfc​.nasa​.gov\n\nData: \n\nhttps://​nsidc​.org​/data​/icesat-2\n\nGitHub: \n\nhttps://​github​.com​/icesat-2","type":"content","url":"/notebooks/mission-overview#mission-product-development","position":81},{"hierarchy":{"lvl1":"DRAFT: Sea Ice"},"type":"lvl1","url":"/notebooks/sea-ice","position":0},{"hierarchy":{"lvl1":"DRAFT: Sea Ice"},"content":"","type":"content","url":"/notebooks/sea-ice","position":1},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/sea-ice#author-s","position":2},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Author(s)"},"content":"Younghyun Koo, Alek Petty, Ellen Buckley","type":"content","url":"/notebooks/sea-ice#author-s","position":3},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Existing Notebooks"},"type":"lvl2","url":"/notebooks/sea-ice#existing-notebooks","position":4},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Existing Notebooks"},"content":"Sea Ice Applications (2023)\n\nSea Ice Applications (2020)","type":"content","url":"/notebooks/sea-ice#existing-notebooks","position":5},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/sea-ice#learning-outcomes","position":6},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl2":"Learning Outcomes"},"content":"Learn how to access/download ICESat-2 sea ice products (ATL07/ATL10/ATL20)\nvia icepyx or earthaccess libraries.\n\nExamine what the ICESat-2 sea ice freeboard products (ATL10/ATL20) look like.\n\nDerive sea ice properties (sea ice thickness, floe size distribution, lead\nfraction) using ATL10 product.\n\nMap monthly sea ice freeboard using ATL20 product.","type":"content","url":"/notebooks/sea-ice#learning-outcomes","position":7},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl3":"Notes","lvl2":"Learning Outcomes"},"type":"lvl3","url":"/notebooks/sea-ice#notes","position":8},{"hierarchy":{"lvl1":"DRAFT: Sea Ice","lvl3":"Notes","lvl2":"Learning Outcomes"},"content":"The 2020 tutorials have an assembly of notebooks for the different ATL products.\nThe 2023 tutorial is a single notebook.","type":"content","url":"/notebooks/sea-ice#notes","position":9},{"hierarchy":{"lvl1":"Snow Depth Applications"},"type":"lvl1","url":"/notebooks/snowdepth","position":0},{"hierarchy":{"lvl1":"Snow Depth Applications"},"content":"","type":"content","url":"/notebooks/snowdepth","position":1},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Author(s)"},"type":"lvl2","url":"/notebooks/snowdepth#author-s","position":2},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Author(s)"},"content":"Karina Zikan, Zach Fair","type":"content","url":"/notebooks/snowdepth#author-s","position":3},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Learning Outcomes"},"type":"lvl2","url":"/notebooks/snowdepth#learning-outcomes","position":4},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Learning Outcomes"},"content":"Gain experience in working with SlideRule to access and pre-process ICESat-2\ndata\n\nLearn how to use projections and interpolation to compare ICESat-2 track data\nwith gridded raster products\n\nDevelop a general understanding of how to measure snow depths with LiDAR,\nand learn about opportunities and challenges when using ICEsat-2 along-track\nproducts\n\n","type":"content","url":"/notebooks/snowdepth#learning-outcomes","position":5},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Background"},"type":"lvl2","url":"/notebooks/snowdepth#background","position":6},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Background"},"content":"","type":"content","url":"/notebooks/snowdepth#background","position":7},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"How do we measure snow depth with LiDAR?","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#how-do-we-measure-snow-depth-with-lidar","position":8},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"How do we measure snow depth with LiDAR?","lvl2":"Background"},"content":"LiDAR is a useful tool for collecting high resolution snow depth maps over large spatial areas.\n\nSnow depth is measured from LiDAR by differencing a snow-free LiDAR map from a snow-covered LiDAR map of the same area of interest.\n\nTODO: Insert Figure 6 from Deems et al. here\n\nTODO: Insert Figure 7b from Deems et al\n\n","type":"content","url":"/notebooks/snowdepth#how-do-we-measure-snow-depth-with-lidar","position":9},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Can we do this with ICESat-2?","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#can-we-do-this-with-icesat-2","position":10},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Can we do this with ICESat-2?","lvl2":"Background"},"content":"Yes! By differencing snow-covered ICESat-2 transects from snow-free maps, we can calculate snow depth!\n\nPerforming the calculation with ICESat-2 is a little different from other LiDAR snow depth methods, given that ICESat-2 is a transect of points rather than gridded raster data. ICESat-2 also has sparse coverage in the mid-latitudes, so generating an effective snow-covered or snow-free map will be difficult.\n\nBecause of these limitations, we need an independently-collected snow-free map of a region of interest for comparison. We also need to process the snow-free data into a form that can be differenced from snow-on ICESat-2 data.\n\nIn this tutorial, we will show an example of how to compare ICESat-2 data to raster data.\n\nTODO: Add Karina’s image over Dry Creek\n\n","type":"content","url":"/notebooks/snowdepth#can-we-do-this-with-icesat-2","position":11},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"What do we need to calculate snow depth from ICESat-2?","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#what-do-we-need-to-calculate-snow-depth-from-icesat-2","position":12},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"What do we need to calculate snow depth from ICESat-2?","lvl2":"Background"},"content":"A region of interest, where snow-free (and snow-covered, for validation) digital elevation models (DEMs) are available.\n\nICESat-2 data, ideally from one of the lower-level products (ATL03, ATL06, ATL08, Sliderule Earth).\n\nA snow-free reference DEM for the snow depth calculation.\n\n","type":"content","url":"/notebooks/snowdepth#what-do-we-need-to-calculate-snow-depth-from-icesat-2","position":13},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"What do we need to consider when comparing ICESat-2 and raster data?","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#what-do-we-need-to-consider-when-comparing-icesat-2-and-raster-data","position":14},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"What do we need to consider when comparing ICESat-2 and raster data?","lvl2":"Background"},"content":"Geolocation: To obtain usable results, it is important that we properly align the snow-free raster data with ICESat-2. Even small offsets can create large errors that worsen in rugged terrain.\n\nTODO: Add Figure 9 from Nuth and Kabb\n\nVegetation: Incorrectly categorized vegetation returns can positively bias ground or snow surface height estimation. Additionally, dense vegetation can reduce the number of photon returns, thereby increasing uncertainty in our height estimates.\n\nSlope Effects: Rugged terrain increases uncertainty in ICESat-2 returns and increases the impact of geolocation offsets between ICESat-2 and raster data. Additionally, steep slopes can negatively bias ground or snow surface height estimates.\n\n","type":"content","url":"/notebooks/snowdepth#what-do-we-need-to-consider-when-comparing-icesat-2-and-raster-data","position":15},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Computing Environment","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#computing-environment","position":16},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Computing Environment","lvl2":"Background"},"content":"We’ll be using the following open source Python libraries in this notebook:\n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport rioxarray as rxr\nimport matplotlib.pyplot as plt\nfrom sliderule import icesat2, sliderule\nfrom scipy.interpolate import RectBivariateSpline\n\n","type":"content","url":"/notebooks/snowdepth#computing-environment","position":17},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Data","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#data","position":18},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Data","lvl2":"Background"},"content":"We will use SlideRule to acquire customized ATL06 data. Specific customizations that we will implement include footprint averaging (i.e., along-track sampling rate) and photon identification (signal/noise and ground/vegetation).\n\nWe will look at snow depth data over Upper Kuparuk/Toolik (UKT) on the Arctic North Slope of Alaska. Because UKT is a relatively flat region with little vegetation, we should expect good agreement between ICESat-2 and our rasters of interest.\n\n","type":"content","url":"/notebooks/snowdepth#data","position":19},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Initialize SlideRule","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#initialize-sliderule","position":20},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Initialize SlideRule","lvl2":"Background"},"content":"\n\nicesat2.init(\"slideruleearth.io\")\n\n","type":"content","url":"/notebooks/snowdepth#initialize-sliderule","position":21},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Define Region of Interest","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#define-region-of-interest","position":22},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Define Region of Interest","lvl2":"Background"},"content":"After we initialize SlideRule, we define our region of interest. Notice that there are two options given below. This is because SlideRule accepts either the coordinates of a box/polygon or a geoJSON for its region input.\n\nWe are going to use the bounding box method in this tutorial, but the syntax for the geoJSON method is included for the user’s reference.\n\n# Define region of interest over Toolik, Alaska\nregion = [{\"lon\":-149.5992624418217, \"lat\":68.63358948385529}, \n          {\"lon\":-149.5954459662985, \"lat\":68.60200878043223}, \n          {\"lon\":-149.2821268688734, \"lat\":68.60675802967609}, \n          {\"lon\":-149.2855031235162, \"lat\":68.63834638180673},\n          {\"lon\":-149.5992624418217, \"lat\":68.63358948385529}]\n\nprint(region)\n\n# Alternate method, with geoJSON\npath = \"/path/to/geojson/\"\nregion = sliderule.toregion(path)[\"poly\"]\nprint(region)\n\n","type":"content","url":"/notebooks/snowdepth#define-region-of-interest","position":23},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Build SlideRule Request","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#build-sliderule-request","position":24},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Build SlideRule Request","lvl2":"Background"},"content":"Now we are going to build our SlideRule request by defining ICESat-2 parameters.\n\nSince we want something close to the ATL06 product, we will use the icesat2.atl06p() function in this tutorial. You can find other SlideRule functions and more detail on the icesat2.atl06p() function on the SlideRule API reference. (TODO: Add link to API reference)\n\nWe won’t use every parameter in this tutorial, but here is a reference list for some of them. More information can be found in the SlideRule users guide (TODO: Add link to users guide)\n\nParameters\n\npoly: Polygon defining region of interest.\n\ntrack: Reference pair track number (1, 2, 3; 0 to include all three; defaults to 0).\n\nrgt: Reference ground track (defaults to all).\n\ncycle: Counter of 91-day repeat cycles completed by the mission (defaults to all).\n\nregion: Geographic region for data product (defaults to global).\n\nt0: Start time for filtering granules (%Y-%m%dT%h:%M:%SZ format)\n\nt1: Stop time for filtering granules (%Y-%m%dT%h:%M:%SZ format).\n\nsrt: Surface type (0=land, 1=ocean, 2=sea ice, 3=land ice, 4=inland water).\n\ncnf: Confidence level for photon selection, in integer or list format.\n\natl08_class: List of ATL08 classifications for photon processing (“atl08_noise”, “atl08_ground”, “atl08_canopy”, “atl08_top_of_canopy”, “atl08_unclassified”).\n\nmaxi: Maximum interations of algorithm, not including initial least-squares-fit selection.\n\nH_min_win: Minimum height to which the refined photon-selection window is allowed to shrink, in meters.\n\nsigma_r_max: Maximum robust spread (uncertainty) in meters.\n\ncompact: Return results without most metadata.\n\n## Build SlideRule request\n# Define parameters (described below)\nparms = {\n    \"poly\": region,\n    \"srt\": icesat2.SRT_LAND,\n    \"cnf\": icesat2.CNF_SURFACE_HIGH,\n    \"atl08_class\": [\"atl08_ground\"],\n    \"ats\": 5.0,\n    \"len\": 20.0,\n    \"res\": 10.0,\n    \"maxi\": 5\n}\n\n# Calculated ATL06 dataframe\nis2_df = icesat2.atl06p(parms)\n\n# Print SlideRule output\nprint(is2_df.head())\n\nNote\n\nWe defined our region above, so let’s run through the remaining parameters in our query:\n\nsrt: Only land photons will be considered.\n\ncnf: Only high-confidence photons.\n\natl08_class: Only ground photons, as identified by the ATL08 algorithm.\n\nats: The maximum along-track spread (uncertainty) in aggregated photons will be 5 m.\n\nlen: The length of each segment of aggregated photons will be 20 m.\n\nres: The along-track resolution will be 10 m. Because each segment will be 20 m long, there will be overlap between successive data points.\n\nmaxi: The SlideRule refinement algorithm will iterate 5 times per segment at maximum.\n\n","type":"content","url":"/notebooks/snowdepth#build-sliderule-request","position":25},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Subsetting the Data","lvl2":"Background"},"type":"lvl3","url":"/notebooks/snowdepth#subsetting-the-data","position":26},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Subsetting the Data","lvl2":"Background"},"content":"One may notice that the algorithm took a long time to generate the GeoDataFrame. That is because (i) our region of interest was rather large and (ii) we obtained all ICESat-2 tracks in the ROI since its launch (2018).\n\nFor the sake of interest, let’s take a look at all of the ICESat-2 tracks over Upper Kuparuk/Toolik.\n\nimport contextily as ctx\nfrom shapely.geometry import Polygon\n\n# Convert region to a Polygon\ncoords = [(point[\"lon\"], point[\"lat\"]) for point in region]\npolygon = Polygon(coords)\nregion_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=\"EPSG:4326\")\n\n# Reproject to Web Mercator for contextily\nis2_df_mercator = is2_df.to_crs(epsg=3857)\nregion_mercator = region_gdf.to_crs(epsg=3857)\n\n\nfig, ax = plt.subplots(figsize=(12, 8))\n# Plot surface height\nis2_df_mercator.plot(column='h_mean', \n                  ax=ax, \n                  cmap='viridis',\n                  legend=True,\n                  markersize=10,\n                  alpha=0.8)\n\n# Plot the region bounding box\nregion_mercator.plot(ax=ax, \n                     facecolor='none', \n                     edgecolor='red', \n                     linewidth=2)\n\n# Add ESRI World Imagery basemap\nctx.add_basemap(ax, \n                crs=is2_df_mercator.crs, \n                source=ctx.providers.Esri.WorldImagery)\nplt.tight_layout()\nplt.show()\n\nIt is cool to see all of the available data, but we only have snow-free lidar DEMs available from March 2022. So, we are going to subset the data to include one ICESat-2 track (RGT 152) in March 2023.\n\n# Subset ICESat-2 data to single RGT, time of year\nis2_df_subset = is2_df[is2_df['rgt']==152]\nis2_df_subset = is2_df_subset.loc['2023-03-31']\n\n# Display top of dataframe\nprint(is2_df_subset.head())\n\n","type":"content","url":"/notebooks/snowdepth#subsetting-the-data","position":27},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"type":"lvl2","url":"/notebooks/snowdepth#sample-the-lidar-dtm-to-icesat-2-ground-track","position":28},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"content":"The ICESat-2 data is ready to go! Now it’s time to load the airborne lidar data, and co-register it with ICESat-2.\n\nThe lidar data used here is from the University of Alaska, Fairbanks (UAF). The UAF lidar obtains snow-on and snow-off DEMs/digital terrain models (DTMs) with a 1064 nm (near-infrared) laser, from which it can also derive snow depth.\n\nUAF lidar rasters normally have a spatial resolution of 0.5 m, which can take a long time to process. As a compromise between computation speed and resolution, we will coarsen the rasters to 3 m resolution.\n\nThe best way to handle lidar DEMs/DTMs is through rioxarray:\n\nTODO: Access UAF lidar data without needing it locally.\n\nimport earthaccess\nearthaccess.login(strategy='interactive', persist=True)\nauth = earthaccess.login()\n\n# Coordinates for SW/NE corners\nlon_min = min([coord[0] for coord in coords])\nlat_min = min([coord[1] for coord in coords])\nlon_max = max([coord[0] for coord in coords])\nlat_max = max([coord[1] for coord in coords])\n\n# Data query for lidar point clouds over Fairbanks, AK\nresults = earthaccess.search_data(\n    short_name='SNEX23_Lidar',\n    bounding_box = (lon_min, lat_min, lon_max, lat_max),\n    temporal = ('2023-03-13', '2023-03-14')\n)\n\n# File paths for UAF rasters (TODO: Add lidar files, and update names)\ntifpath = \"/your/path/here\"\nf_snow_off = f\"{tifpath}/uaf_lidar_snowoff.tif\"\nf_snow_on = f\"{tifpath}/uaf_lidar_snowon.tif\"\n\n# Load files as rioxarray datasets\nlidar_snow_off = rxr.open_rasterio(f_snow_off)\nlidar_snow_on = rxr.open_rasterio(f_snow_on)\n\nIt is not immediately obvious, but the uAF rasters are in a different spatial projection than ICESat-2. UAF is in EPSG:32606, and ICESat-2 is in WGS84/EPSG:4326.\n\nIn order to directly compare these two datasets, we are going to add reprojected coordinates to the ICESat-2 GeoDataFrame. In essence, we will go from latitude/longitude to northing/easting. Luckily, there is an easy way to do this with GeoPandas, specifically with the geopandas.to_crs() function.\n\n# Initialize ICESat-2 coordinate projection\nis2_df_subset = is2_df_subset.set_crs(\"EPSG:4326\")\n\n# Change to EPSG:32606\nis2_df_subset = is2_df_subset.to_crs(\"EPSG:32606\")\n\n# Display top of dataframe\nprint(is2_df_subset.head())\n\n","type":"content","url":"/notebooks/snowdepth#sample-the-lidar-dtm-to-icesat-2-ground-track","position":29},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Co-register rasters and ICESat-2","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"type":"lvl3","url":"/notebooks/snowdepth#co-register-rasters-and-icesat-2","position":30},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Co-register rasters and ICESat-2","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"content":"Now, we are going to co-register both rasters to the queried ICESat-2 data. The function below is fairly long, but the gist is that we a re using a spline interpolant to match both the snow-off UAF data (surface height) and UAF snow depths with ICESat-2 surface heights. The resulting GeoDataFrame will have both ICESat-2 and UAF data in it.\n\n# Make coregistration function\ndef coregister_is2(lidar_snow_off, lidar_snow_on, is2_df):\n    \"\"\"\n    Co-registers UAF data with ICESat-2 data with a rectangular \n    bivariate spline.\n\n    Parameters\n    ------------\n    lidar_snow_off: rioxarray dataset\n        Lidar DEM/DTM in rioxarray format.\n    lidar_snow_on: rioxarray dataset\n        Lidar-derived snow depth in rioxarray format.\n    is2_df: GeodataFrame\n        GeoDataFrame for the ICESat-2 data generated with SlideRule.\n\n    Returns\n    ------------\n    is2_uaf_df: GeoDataFrame\n        Contains the coordinate and elevation data that matches best\n        between ICESat-2 and UAF.\n    \"\"\"\n\n    # Helper function to prepare lidar data\n    def prepare_lidar_data(raster):\n        coords_x = np.array(raster.x)\n        coords_y = np.array(raster.y)\n        values = np.array(raster.sel(band=1))[::-1, :]\n        values[np.isnan(values)] = -9999\n        return coords_x, coords_y, values\n\n    # Get coordinates and height/depth values from lidar data\n    x0, y0, dem_heights = prepare_lidar_data(lidar_snow_off)\n    xs, ys, dem_depths = prepare_lidar_data(lidar_snow_on)\n\n    # Generate interpolators\n    interp_height = RectBivariateSpline(y0[::-1], x0, dem_heights)\n    interp_height = RectBivariateSpline(ys[::-1], xs, dem_depths)\n\n    # Pre-filter IS2 data to bounds (apply once instead of per beam)\n    x_bounds = (is2_df.geometry.x > np.min(x0)) & (is2_df.geometry.x < np.max(x0))\n    y_bounds = (is2_df.geometry.y > np.min(y0)) & (is2_df.geometry.y < np.max(y0))\n    is2_filtered = is2_df[x_bounds & y_bounds].copy()\n\n    if is2_filtered.empty:\n        print('Error with GeoDataFrame or raster bounds.')\n        return gpd.GeoDataFrame()\n\n    # Extract coordinates once\n    xn = is2_filtered.geometry.x.values\n    yn = is2_filtered.geometry.y.values\n\n    # Estimate lidar height and snow depth at the ICESat-2 coordinates\n    lidar_heights = interp_height(yn, xn, grid=False)\n    lidar_snow_depths = interp_depth(yn, xn, grid=False)\n\n    # Create result DataFrame in one operation\n    is2_uaf_df = gpd.GeoDataFrame({\n        'x': xn,\n        'y': yn,\n        'time': is2_filtered.index.values,\n        'beam': is2_filtered['gt'].values,\n        'lidar_height': lidar_heights,\n        'lidar_snow_depth': lidar_snow_depths,\n        'is2_height': is2_filtered['h_mean'].values,\n        'h_sigma': is2_filtered['h_sigma'].values,\n        'dh_fit_dx': is2_filtered['dh_fit_dx'].values\n    })\n\n    # Add coordinate transformation\n    transformer = Transformer.from_crs(\"EPSG:32606\", \"EPSG:4326\", always_xy=True)\n    is2_uaf_df['lon'], is2_uaf_df['lat'] = transformer.transform(\n        is2_uaf_df['x'], is2_uaf_df['y']\n    )\n\n    return is2_uaf_df\n\n# Co-locate ICESat-2 and UAF using the above function\nis2_uaf_df = coregister_is2(lidar_snow_off, \n                            lidar_snow_on, \n                            is2_df_subset\n                           )\n# Convert to a GeoDataFrame\ngeom = gpd.points_from_xy(is2_uaf_df.lon, is2_uaf_df.lat)\nis2_uaf_gdf = gpd.GeoDataFrame(is2_uaf_df,\n                               geometry=geom,\n                               crs=\"EPSG:4326\"\n                              )\n# Print head of GeoDataFrame\nis2_uaf_gdf.head()\n\nAs one can see, we now have a GeoDataFrame that includes several useful variables:\n\nbeam: ICESat-2 beam (gt1l, gt2l, etc.)\n\nlidar_height: Snow-off surface height from UAF lidar.\n\nlidar_snow_depth: Snow depth derived from UAF.\n\nis2_height: ICESat-2 surface height (snow-on, in this case).\n\nh_sigma: ICESat-2 height uncertainty.\n\ndh_fit_dx: Along-track slope of the terrain.\n\nWith this GeoDataFrame, it is very simple to derive snow depth!\n\n# Derive snow depth using snow-on/snow-off differencing\nis2_uaf_gdf['is2_snow_depth'] = is2_uaf_gdf['is2_height'] - is2_uaf_gdf['lidar_height']\n\n# Estimate the residual (bias) between IS-2 and UAF depths\nis2_uaf_gdf['snow_depth_residual'] = is2_uaf_gdf['is2_snow_depth'] - is2_uaf_gdf['lidar_snow_depth']\n\nHorray! We finally have ICESat-2 snow depths! Let’s make a couple of plots with the data we have.\n\n","type":"content","url":"/notebooks/snowdepth#co-register-rasters-and-icesat-2","position":31},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Map Plot","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"type":"lvl3","url":"/notebooks/snowdepth#map-plot","position":32},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Map Plot","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"content":"\n\n# Create plot\nfig, ax = plt.subplots(figsize=(12, 8))\n# Plot surface height\nis2_uaf_gdf.to_crs(\"EPSG:3857\").plot(column='is2_snow_depth', \n                  ax=ax, \n                  cmap='viridis',\n                  legend=True,\n                  markersize=10,\n                  alpha=0.8)\n\n# Plot the region bounding box\nregion_mercator.plot(ax=ax, \n                     facecolor='none', \n                     edgecolor='red', \n                     linewidth=2)\n\n# Add ESRI World Imagery basemap\nctx.add_basemap(ax, \n                crs=\"EPSG:3857\", \n                source=ctx.providers.Esri.WorldImagery)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/notebooks/snowdepth#map-plot","position":33},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Along-track plots","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"type":"lvl3","url":"/notebooks/snowdepth#along-track-plots","position":34},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Along-track plots","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"content":"\n\n# Plot snow depths for the three strong beams\nfig,axs = plt.subplots(3)\n\n#Left strong beam\ntmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==10]\naxs[0].plot(tmp_df['lat'], tmp_df['is2_snow_depth'], label='ICESat-2')\naxs[0].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'], label='UAF')\naxs[0].set_title('gt1l')\naxs[0].legend()\n\n# Central strong beam\ntmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==30]\naxs[1].plot(tmp_df['lat'], tmp_df['is2_snow_depth'])\naxs[1].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'])\naxs[1].set_ylabel('Snow depth [m]', fontsize=18)\naxs[1].set_title('gt2l')\n\n# Right strong beam\ntmp_df = is2_uaf_gdf[is2_uaf_gdf['beam']==50]\naxs[2].plot(tmp_df['lat'], tmp_df['is2_snow_depth'])\naxs[2].plot(tmp_df['lat'], tmp_df['lidar_snow_depth'])\naxs[2].set_xlabel('Latitude [m]', fontsize=18)\naxs[2].set_title('gt3l')\nplt.tight_layout()\n\n# Only include outer axis labels\nfor ax in axs:\n    ax.label_outer()\n    ax.set_ylim([0, 1.5])\n\n","type":"content","url":"/notebooks/snowdepth#along-track-plots","position":35},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Scatter Plot","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"type":"lvl3","url":"/notebooks/snowdepth#scatter-plot","position":36},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Scatter Plot","lvl2":"Sample the Lidar DTM to ICESat-2 ground track"},"content":"\n\nfig, ax = plt.subplots(figsize=(12,6))\ns = is2_uaf_gpd.plot.scatter(ax=ax,\n                             x='lidar_snow_depth',\n                             y='is2_snow_depth',\n                             c='snow_depth_residual',\n                             vmin=-0.5, vmax=0.5\n                            )\nax.set_xlabel(\"UAF snow depth [m]\", fontsize=18)\nax.set_ylabel(\"ICESat-2 snow depth [m]\", fontsize=18)\nax.set_xlim([0, 1.5])\nax.set_ylim([0, 1.5])\ncbar = fig.colorbar(s, ax=ax)\ncbar.set_label(\"Snow depth residual [m]\")\nplt.tight_layout()\n\n","type":"content","url":"/notebooks/snowdepth#scatter-plot","position":37},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/snowdepth#summary","position":38},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Summary"},"content":"🎉 Congratulations! You have completed this tutorial and have seen how to compare ICESat-2 to raster data, how to obtain ICESat-2 data with SlideRule, and how to calculate snow depths from ICESat-2 data.\n\n","type":"content","url":"/notebooks/snowdepth#summary","position":39},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Reference"},"type":"lvl2","url":"/notebooks/snowdepth#reference","position":40},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl2":"Reference"},"content":"To further explore the topics of this tutorial, see the following detailed documentation: (TODO: ADD LINKS TO SITES AND PAPERS)\n\nSlideRule Website\n\nSlideRule online demo","type":"content","url":"/notebooks/snowdepth#reference","position":41},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Papers","lvl2":"Reference"},"type":"lvl3","url":"/notebooks/snowdepth#papers","position":42},{"hierarchy":{"lvl1":"Snow Depth Applications","lvl3":"Papers","lvl2":"Reference"},"content":"Deems, Jeffrey S., et al. “Lidar Measurement of Snow Depth: A Review.” Journal of Glaciology, vol. 59, no. 215, 2013, pp. 467–79. \n\nDOI.org (Crossref), \n\nDeems et al. (2013).\n\nNuth, C., and A. Kääb. “Co-Registration and Bias Corrections of Satellite Elevation Data Sets for Quantifying Glacier Thickness Change.” The Cryosphere, vol. 5, no. 1, Mar. 2011, pp. 271–90. \n\nDOI.org (Crossref), \n\nNuth & Kääb (2011).","type":"content","url":"/notebooks/snowdepth#papers","position":43},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine"},"type":"lvl1","url":"/notebooks/visualization","position":0},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine"},"content":"By Philipp Arndt, Chancelor Roberts Scripps Institution of Oceanography, University of California San Diego Github: \n\n, \n\n Contact: \n\nccroberts@ucsd.edu\n\n","type":"content","url":"/notebooks/visualization","position":1},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Prerequisites"},"type":"lvl3","url":"/notebooks/visualization#prerequisites","position":2},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\npandas\n\nNecessary\n\nICESat-2 data in this tutorial will appear as geopandas DataFrames organized within a custom class object called a dataCollector\n\nnumpy/matplotlib\n\nNecessary\n\nWe will plot ICESat-2 data with matplotlib\n\nrasterio\n\nHelpful\n\nWe will plot images with rasterio\n\nICESat-2 Mission Overview\n\nHelpful\n\nHere is where to go to understand the ICESat-2 mission and its goals\n\nTime to learn:  30 min.\n\n","type":"content","url":"/notebooks/visualization#prerequisites","position":3},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Learning Objectives"},"type":"lvl2","url":"/notebooks/visualization#learning-objectives","position":4},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Learning Objectives"},"content":"Concepts\n\nNotes\n\nOpenAltimetry\n\nWe will learn to browse OpenAltimetry to discover ICESat-2 data, then view them as profiles or overlay them on a map\n\nGoogle Earth Engine\n\nWe will learn to browse Google Earth Engine to find the closest-in-time Sentinel-2 image that is cloud-free along ICESat-2’s ground track\n\ngeemap\n\nWe will see a demonstration of the interactive mapping options available through GEEMap’s implementation of the folium and ipyleaflet python libraries\n\ndicts\n\nWe see an example usage of Python’s dictionary data structure to organize incoming ICESat-2 data and Google Earth Engine imagery\n\n","type":"content","url":"/notebooks/visualization#learning-objectives","position":5},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Computing environment"},"type":"lvl2","url":"/notebooks/visualization#computing-environment","position":6},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Computing environment"},"content":"We’ll be using the following Python libraries in this notebook:\n\n#%matplotlib widget \nimport os\nimport ee\nimport geemap\nimport requests\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom ipywidgets import Layout\nimport rasterio as rio\nfrom rasterio import plot as rioplot\nfrom rasterio import warp\n\nThe import below is a class that I wrote myself. It helps us read and store data from the OpenAltimetry API.If you are interested in how this works, you can find the code in utils/oa.py.\n\nimport utils.oa as oa\nfrom utils.oa import dataCollector\n\n","type":"content","url":"/notebooks/visualization#computing-environment","position":7},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Google Earth Engine Authentication and Initialization"},"type":"lvl2","url":"/notebooks/visualization#google-earth-engine-authentication-and-initialization","position":8},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Google Earth Engine Authentication and Initialization"},"content":"GEE requires you to authenticate your access, so if ee.Initialize() does not work you first need to run ee.Authenticate(). This gives you a link at which you can use your google account that is associated with GEE to get an authorization code. Copy the authorization code into the input field and hit enter to complete authentication.\n\ntry:\n    ee.Initialize()\nexcept: \n    ee.Authenticate()\n    ee.Initialize()\n\n","type":"content","url":"/notebooks/visualization#google-earth-engine-authentication-and-initialization","position":9},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Downloading data from the OpenAltimetry API"},"type":"lvl2","url":"/notebooks/visualization#downloading-data-from-the-openaltimetry-api","position":10},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Downloading data from the OpenAltimetry API"},"content":"Let’s say we have found some data that looks weird to us, and we don’t know what’s going on.","type":"content","url":"/notebooks/visualization#downloading-data-from-the-openaltimetry-api","position":11},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"A short explanation of how I got the data:","lvl2":"Downloading data from the OpenAltimetry API"},"type":"lvl3","url":"/notebooks/visualization#a-short-explanation-of-how-i-got-the-data","position":12},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"A short explanation of how I got the data:","lvl2":"Downloading data from the OpenAltimetry API"},"content":"I went to \n\nopenaltimetry.org and selected BROWSE ICESAT-2 DATA. Then I selected ATL 06 (Land Ice Height) on the top right, and switched the projection🌎 to Arctic. Then I selected August 22, 2021 in the calendar📅 on the bottom left, and toggled the cloud☁️ button to show MODIS imagery of that date. I then zoomed in on my region of interest.\n\nTo find out what ICESat-2 has to offer here, I clicked on SELECT A REGION on the top left, and drew a rectangle around that mysterious cloud. When right-clicking on that rectangle, I could select View Elevation profile. This opened a new tab, and showed me ATL06 and ATL08 elevations.\n\nIt looks like ATL06 can’t decide where the surface is, and ATL08 tells me that there’s a forest canopy on the Greenland Ice Sheet? To get to the bottom of this, I scrolled all the way down and selected 🛈Get API URL. The website confirms that the “API endpoint was copied to clipboard.” Now I can use this to access the data myself.\n\nTip\n\nInstead of trying to find this region yourself, you can access the OpenAltimetry page shown above by going to \n\nthis annotation🏷️. Just left-click on the red box and select “View Elevation Profile”.*\n\n","type":"content","url":"/notebooks/visualization#a-short-explanation-of-how-i-got-the-data","position":13},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Getting the OpenAltimetry info into python","lvl2":"Downloading data from the OpenAltimetry API"},"type":"lvl3","url":"/notebooks/visualization#getting-the-openaltimetry-info-into-python","position":14},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Getting the OpenAltimetry info into python","lvl2":"Downloading data from the OpenAltimetry API"},"content":"All we need to do is to paste the API URL that we copied from the webpage into a string.\nWe also need to specify which beam we would like to look at. The GT1R ground track looks funky, so let’s look at that one!\n\n# paste the API URL from OpenAltimetry below, and specify the beam you are interested in\noa_api_url = 'https://openaltimetry.earthdatacloud.nasa.gov/data/icesat2/elevation?minx=-25.4835556641541&miny=76.44321462688005&maxx=-21.976284749133928&maxy=77.33633089376721&zoom_level=5&beams=1,2,3,4,5,6&tracks=1236&date=2024-09-06&product=ATL06&mapType=arctic'\ngtx = 'gt1r'\n\nWe can now initialize a dataCollector object, using the copy-pasted OpenAltimetry API URL, and the beam we would like to look at. (Again, I defined this class in utils/oa.py to do some work for us in the background.)\n\nis2data = dataCollector(oaurl=oa_api_url, beam=gtx, verbose=True)\n\nAlternatively, we could use a date, track number, beam, and lat/lon bounding box as input to the dataCollector.\n\ndate = '2021-08-22'\nrgt = 909\nbeam = 'gt1r'\nlatlims = [77.5326, 77.5722]\nlonlims = [-23.9891, -23.9503]\nis2data = dataCollector(date=date, latlims=latlims, lonlims=lonlims, track=rgt, beam=beam, verbose=True)\n\nNote that this also constructs the API url for us.\n\n","type":"content","url":"/notebooks/visualization#getting-the-openaltimetry-info-into-python","position":15},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Requesting the data from the OpenAltimetry API","lvl2":"Downloading data from the OpenAltimetry API"},"type":"lvl3","url":"/notebooks/visualization#requesting-the-data-from-the-openaltimetry-api","position":16},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Requesting the data from the OpenAltimetry API","lvl2":"Downloading data from the OpenAltimetry API"},"content":"Here we use the requestData() function of the dataCollector class, which is defined in utils/oa.py. It downloads all data products that are available on OpenAltimetry based on the inputs with which we initialized our dataCollector, and writes them to pandas dataframes.\n\nis2data.requestData(verbose=True)\n\nThe data are now stored as data frames in our dataCollector object. To verify this, we can run the cell below.\n\nvars(is2data)\n\n","type":"content","url":"/notebooks/visualization#requesting-the-data-from-the-openaltimetry-api","position":17},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Plotting the ICESat-2 data"},"type":"lvl2","url":"/notebooks/visualization#plotting-the-icesat-2-data","position":18},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Plotting the ICESat-2 data"},"content":"Now let’s plot this data. Here, we are just creating an empty figure fig with axes ax.\n\n# create the figure and axis\nfig, ax = plt.subplots(figsize=[9,5])\n\n# plot the data products\natl06, = ax.plot(is2data.atl06.lat, is2data.atl06.h, c='C0', linestyle='-', label='ATL06')\natl08, = ax.plot(is2data.atl08.lat, is2data.atl08.h, c='C2', linestyle=':', label='ATL08')\nif np.sum(~np.isnan(is2data.atl08.canopy))>0:\n    atl08canopy = ax.scatter(is2data.atl08.lat, is2data.atl08.h+is2data.atl08.canopy, s=2, c='C2', label='ATL08 canopy')\n\n# add labels, title and legend\nax.set_xlabel('latitude')\nax.set_ylabel('elevation in meters')\nax.set_title('Some ICESat-2 data I found on OpenAltimetry!')\nax.legend(loc='upper left')\n\n# add some text to provide info on what is plotted\ninfo = 'ICESat-2 track {track:d}-{beam:s} on {date:s}\\n({lon:.4f}E, {lat:.4f}N)'.format(track=is2data.track, \n                                                                                        beam=is2data.beam.upper(), \n                                                                                        date=is2data.date, \n                                                                                        lon=np.mean(is2data.lonlims), \n                                                                                        lat=np.mean(is2data.latlims))\ninfotext = ax.text(0.01, -0.08, info,\n                   horizontalalignment='left', \n                   verticalalignment='top', \n                   transform=ax.transAxes,\n                   fontsize=7,\n                   bbox=dict(edgecolor=None, facecolor='white', alpha=0.9, linewidth=0))\n\n# set the axis limits\nax.set_xlim((is2data.atl03.lat.min(), is2data.atl03.lat.max()))\nax.set_ylim((741, 818));\n\nLet’s add the ATL03 photons to better understand what might be going on here.\n\natl03 = ax.scatter(is2data.atl03.lat, is2data.atl03.h, s=1, color='black', label='ATL03', zorder=-1)\nax.legend(loc='upper left')\nfig.tight_layout()\ndisplay(fig)\n\n","type":"content","url":"/notebooks/visualization#plotting-the-icesat-2-data","position":19},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Saving the plot to a file","lvl2":"Plotting the ICESat-2 data"},"type":"lvl3","url":"/notebooks/visualization#saving-the-plot-to-a-file","position":20},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Saving the plot to a file","lvl2":"Plotting the ICESat-2 data"},"content":"\n\nfig.savefig('my-plot.jpg', dpi=300)\n\nTo make plots easier to produce, the dataCollector class also has a method to plot the data that we downloaded.\n\nfig = is2data.plotData();\nfig\n\n","type":"content","url":"/notebooks/visualization#saving-the-plot-to-a-file","position":21},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Ground Track Stats"},"type":"lvl2","url":"/notebooks/visualization#ground-track-stats","position":22},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Ground Track Stats"},"content":"So far we have only seen the data in elevation vs. latitude space. It’s probably good to know what the scale on the x-axis is here in units that we’re familiar with.\n\ndef dist_latlon2meters(lat1, lon1, lat2, lon2):\n    # returns the distance between two coordinate points - (lon1, lat1) and (lon2, lat2) along the earth's surface in meters.\n    R = 6371000\n    def deg2rad(deg):\n        return deg * (np.pi/180)\n    dlat = deg2rad(lat2-lat1)\n    dlon = deg2rad(lon2-lon1)\n    a = np.sin(dlat/2) * np.sin(dlat/2) + np.cos(deg2rad(lat1)) * np.cos(deg2rad(lat2)) * np.sin(dlon/2) * np.sin(dlon/2)\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n    return R * c\n\nlat1, lat2 = is2data.atl08.lat[0], is2data.atl08.lat.iloc[-1]\nlon1, lon2 = is2data.atl08.lon[0], is2data.atl08.lon.iloc[-1]\n\nground_track_length = dist_latlon2meters(lat1, lon1, lat2, lon2)\nprint('The ground track is about %.1f kilometers long.' % (ground_track_length/1e3))\n\n","type":"content","url":"/notebooks/visualization#ground-track-stats","position":23},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Google Earth Engine"},"type":"lvl2","url":"/notebooks/visualization#google-earth-engine","position":24},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Google Earth Engine"},"content":"Google Earth Engine (GEE) has a large \n\ncatalog of geospatial raster data, which is ready for analysis in the cloud. It also comes with an online JavaScript code editor.\n\nBut since we all seem to be using python, it would be nice to have these capabilities available in our Jupyter comfort zone...\n\nThankfully, there is a \n\npython API for GEE, which we have imported using import ee earlier. It doesn’t come with an interactive map, but the python package \n\ngeemap has us covered!\n\n","type":"content","url":"/notebooks/visualization#google-earth-engine","position":25},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Show a ground track on a map","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#show-a-ground-track-on-a-map","position":26},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Show a ground track on a map","lvl2":"Google Earth Engine"},"content":"We can start working on our map by calling geemap.Map(). This just gives us a world map with a standard basemap.\n\nfrom ipywidgets import Layout\nMap = geemap.Map(layout=Layout(width='70%', max_height='450px'))\nMap\n\nNow we need to add our ICESat-2 gound track to that map. Let’s use the lon/lat coordinates of the ATL08 data product for this.We also need to specify which Coordinate Reference System (CRS) our data is in. The longitude/latitude system that we are all quite familiar with is referenced by \n\nEPSG:4326. To add the ground track to the map we need to turn it into an \n\nEarth Engine “Feature Collection”.\n\nground_track_coordinates = list(zip(is2data.atl08.lon, is2data.atl08.lat))\nground_track_projection = 'EPSG:4326' # <-- this specifies that our data longitude/latitude in degrees [https://epsg.io/4326]\ngtx_feature = ee.FeatureCollection(ee.Geometry.LineString(coords=ground_track_coordinates, \n                                      proj=ground_track_projection, \n                                      geodesic=True))\ngtx_feature\n\nNow that we have it in the right format, we can add it as a layer to the map.\n\nMap.addLayer(gtx_feature, {'color': 'red'}, 'ground track')\n\nAccording to the cell above this should be a red line. But we still can’t see it, because we first need to tell the map where to look for it.Let’s calculate the center longitude and latitude, and center the map on it.\n\ncenter_lon = (lon1 + lon2) / 2\ncenter_lat = (lat1 + lat2) / 2\nMap.setCenter(center_lon, center_lat, zoom=7);\n\nSo we actually couldn’t see it because it was in Greenland.Unfortunately the basemap here doesn’t give us much more information. Let’s add a satellite imagery basemap.\nThis is a good time to look at the layer control on the top right.\n\nMap.add_basemap('SATELLITE') # <-- this adds a layer called 'Google Satellite'\nMap.setCenter(center_lon, center_lat, zoom=7);\nMap.addLayer(gtx_feature,{'color': 'red'},'ground track')\n\n...looks like this basemap still doesn’t give us any more clues about the nature of this weird ICESat-2 data. Let’s dig deeper.\n\n","type":"content","url":"/notebooks/visualization#show-a-ground-track-on-a-map","position":27},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#query-for-sentinel-2-images","position":28},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"content":"Both of these Sentinel-2 satellites take images of most places on our planet at least every week or so. Maybe these images can tell us what was happening here around the same time that ICESat-2 acquired our data?\n\nThe imagery scenes live in image collections on Google Earth Engine.You can find all collections here: \n\nhttps://​developers​.google​.com​/earth​-engine​/datasets​/catalog/\n\nThe above link tells us we can find some images under 'COPERNICUS/S2_SR_HARMONIZED'.\n\ncollection_name1 = 'COPERNICUS/S2_SR_HARMONIZED'  # Landsat 8 earth engine collection \n# https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T2\n\n","type":"content","url":"/notebooks/visualization#query-for-sentinel-2-images","position":29},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Access an image collection","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"type":"lvl4","url":"/notebooks/visualization#access-an-image-collection","position":30},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Access an image collection","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"content":"To access the collection, we call ee.ImageCollection:\n\ncollection = ee.ImageCollection(collection_name1)\ncollection\n\nCan we find out how many images there are in total?\n\nnumber_of_scenes = collection.size()\nprint(number_of_scenes)\n\nActually, asking for the size of the collection does not do anything! 🤔\n\nIt just tells Earth Engine on the server-side that this variable refers to the size of the collection, which we may need later to do some analysis on the server. As long as this number is not needed, Earth Engine will not go through the trouble actually computing it.\n\nTo force Earth Engine to compute and get any information on the client side (our local machine / Cryocloud), we need to call .getInfo(). In this case that would be number_of_scenes = collection.size().getInfo().\n\nNote\n\nBecause this command would ask Earth Engine to count every single Sentinel-2 file that exists, this command would take a really long time to execute. I will avoid this here and just give you the answer from when I wrote this tutorial.\n\n# number_of_scenes = collection.size().getInfo()\nnumber_of_scenes = 19323842\nprint('There are %i number of scenes in the image collection' % number_of_scenes)\n\n","type":"content","url":"/notebooks/visualization#access-an-image-collection","position":31},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Filter an image collection by location and time","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"type":"lvl4","url":"/notebooks/visualization#filter-an-image-collection-by-location-and-time","position":32},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Filter an image collection by location and time","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"content":"Who wants to look at almost 20 million pictures? I don’t. So let’s try to narrow it down.Let’s start with only images that overlap with the center of our ground track.\n\n# the point of interest (center of the track) as an Earth Engine Geometry\npoint_of_interest = ee.Geometry.Point(center_lon, center_lat)\n\ncollection = collection.filterBounds(point_of_interest)\n\nprint('There are {number:d} images in the spatially filtered collection.'.format(number=collection.size().getInfo()))\n\nMuch better! Now let’s only look at images that were taken soon before or after ICESat-2 passed over this spot.\n\ndays_buffer_imagery = 6\n\ndateformat = '%Y-%m-%d'\ndatetime_requested = datetime.strptime(is2data.date, dateformat)\nsearch_start = (datetime_requested - timedelta(days=days_buffer_imagery)).strftime(dateformat)\nsearch_end = (datetime_requested + timedelta(days=days_buffer_imagery)).strftime(dateformat)\nprint('Search for imagery from {start:s} to {end:s}.'.format(start=search_start, end=search_end))\n\ncollection = collection.filterDate(search_start, search_end)\nprint('There are {number:d} images in the spatially filtered collection.'.format(number=collection.size().getInfo()))\n\nWe can also sort the collection by date ('system:time_start'), to order the images by acquisition time.\n\ncollection = collection.sort('system:time_start') \n\n","type":"content","url":"/notebooks/visualization#filter-an-image-collection-by-location-and-time","position":33},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Get image collection info","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"type":"lvl4","url":"/notebooks/visualization#get-image-collection-info","position":34},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl4":"Get image collection info","lvl3":"Query for Sentinel-2 images","lvl2":"Google Earth Engine"},"content":"Again, we need to use .getInfo() to actually see any information on our end.\n\nImportant\n\nThis data structure is a python dictionary.\n\ninfo = collection.getInfo()\ntype(info)\n\nLet’s see what’s inside!\n\ninfo.keys()\n\n'features' sounds like it could hold information about the images we are trying to find...\n\nlen(info['features'])\n\nA list of 34 things! Those are probably the 34 images in the collection. Let’s pick the first one and dig deeper!\n\nfeature_number = 0\ninfo['features'][0].keys()\n\ninfo['features'][feature_number]['id']\n\nLooks like we found a reference to a Sentinel-2 image! Let’s look at the 'bands'.\n\nfor band in info['features'][feature_number]['bands']:\n    print(band['id'], end=', ')\n\n'properties' could be useful too!\n\ninfo['features'][0]['properties'].keys()\n\nThat’s a lot going on right there! But 'GRANULE_ID' is probably useful. Let’s go through all our features and print the product id.\n\nfor feature in info['features']:\n    print(feature['properties']['GRANULE_ID'])\n\n","type":"content","url":"/notebooks/visualization#get-image-collection-info","position":35},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Add a Sentinel-2 image to the map","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#add-a-sentinel-2-image-to-the-map","position":36},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Add a Sentinel-2 image to the map","lvl2":"Google Earth Engine"},"content":"The visible bands in Sentinel-2 are 'B2':blue, 'B3':green, 'B4':red.So to show a “true color” RGB composite image on the map, we need to select these bands in the R-G-B order:\n\nmyImage = collection.first()\nmyImage_RGB = myImage.select('B4', 'B3', 'B2')\nvis_params = {'min': 0.0, 'max': 10000, 'opacity': 1.0, 'gamma': 1.5}\nMap.addLayer(myImage_RGB, vis_params, name='my image')\nMap.addLayer(gtx_feature,{'color': 'red'},'ground track')\nMap\n\nThis seems to have worked. But there’s clouds everywhere.\n\n","type":"content","url":"/notebooks/visualization#add-a-sentinel-2-image-to-the-map","position":37},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Calculate the along-track cloud probability","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#calculate-the-along-track-cloud-probability","position":38},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Calculate the along-track cloud probability","lvl2":"Google Earth Engine"},"content":"We need a better approach to get anywhere here. To do this, we use not only the \n\nSentinel-2 Surface Reflectance image collection, but also merge it with the \n\nSentinel-2 cloud probability collection, which can be accessed under COPERNICUS/S2_CLOUD_PROBABILITY.\n\nLet’s specify a function that adds the cloud probability band to each Sentinel-2 image and calcultes the mean cloud probability in the neighborhood of the ICESat-2 ground track, then map this function over our location/date filtered collection.\n\ndef get_sentinel2_cloud_collection(is2data, days_buffer=6, gt_buffer=100):\n    \n    # create the area of interest for cloud likelihood assessment\n    ground_track_coordinates = list(zip(is2data.atl08.lon, is2data.atl08.lat))\n    ground_track_projection = 'EPSG:4326' # our data is lon/lat in degrees [https://epsg.io/4326]\n    gtx_feature = ee.Geometry.LineString(coords=ground_track_coordinates,\n                                     proj=ground_track_projection,\n                                     geodesic=True)\n    area_of_interest = gtx_feature.buffer(gt_buffer)\n    \n    datetime_requested = datetime.strptime(is2data.date, '%Y-%m-%d')\n    start_date = (datetime_requested - timedelta(days=days_buffer)).strftime('%Y-%m-%dT%H:%M:%S')\n    end_date = (datetime_requested + timedelta(days=days_buffer)).strftime('%Y-%m-%dT%H:%M:%S')\n    print('Search for imagery from {start:s} to {end:s}.'.format(start=start_date, end=end_date))\n    \n    # Import and filter S2 SR HARMONIZED\n    s2_sr_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n        .filterBounds(area_of_interest)\n        .filterDate(start_date, end_date))\n\n    # Import and filter s2cloudless.\n    s2_cloudless_collection = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n        .filterBounds(area_of_interest)\n        .filterDate(start_date, end_date))\n\n    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n    cloud_collection = ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n        'primary': s2_sr_collection, 'secondary': s2_cloudless_collection,\n        'condition': ee.Filter.equals(**{'leftField': 'system:index','rightField': 'system:index'})}))\n\n    cloud_collection = cloud_collection.map(lambda img: img.addBands(ee.Image(img.get('s2cloudless')).select('probability')))\n    \n    def set_is2_cloudiness(img, aoi=area_of_interest):\n        cloudprob = img.select(['probability']).reduceRegion(reducer=ee.Reducer.mean(), \n                                                             geometry=aoi, \n                                                             bestEffort=True, \n                                                             maxPixels=1e6)\n        return img.set('ground_track_cloud_prob', cloudprob.get('probability'))\n    \n    return cloud_collection.map(set_is2_cloudiness)\n\nGet this collection for our ICESat-2 data, and print all the granule IDs and associated cloudiness over the ground track.\n\ncollection = get_sentinel2_cloud_collection(is2data)\ninfo = collection.getInfo()\nfor feature in info['features']:\n    print('%s --> along-track cloud probability: %5.1f %%' % (feature['properties']['GRANULE_ID'],\n                                                              feature['properties']['ground_track_cloud_prob']))\n\n","type":"content","url":"/notebooks/visualization#calculate-the-along-track-cloud-probability","position":39},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Filter cloudy images","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#filter-cloudy-images","position":40},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Filter cloudy images","lvl2":"Google Earth Engine"},"content":"We specify a certain cloud probability threshold, and then only keep the images that fall below it. Here we are choosing a quite aggressive value of maximum 5% cloud probability...\n\n# filter by maximum allowable cloud probability (in percent)\nMAX_CLOUD_PROB_ALONG_TRACK = 5\ncloudfree_collection = collection.filter(ee.Filter.lt('ground_track_cloud_prob', MAX_CLOUD_PROB_ALONG_TRACK))\nprint('There are %i cloud-free scenes.' % cloudfree_collection.size().getInfo())\n\n","type":"content","url":"/notebooks/visualization#filter-cloudy-images","position":41},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Sort the collection by time difference from the ICESat-2 overpass","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#sort-the-collection-by-time-difference-from-the-icesat-2-overpass","position":42},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Sort the collection by time difference from the ICESat-2 overpass","lvl2":"Google Earth Engine"},"content":"Using the image property 'system:time_start' we can calculate the time difference from the ICESat-2 overpass and set it as a property. This allows us to sort the collection by it and to make sure that the first image in the collection is the closest-in-time to ICESat-2 image that is also cloud-free.\n\n# get the time difference between ICESat-2 overpass and Sentinel-2 acquisitions, set as image property\nis2time = is2data.date + 'T12:00:00'\ndef set_time_difference(img, is2time=is2time):\n    timediff = ee.Date(is2time).difference(img.get('system:time_start'), 'second').abs()\n    return img.set('timediff', timediff)\ncloudfree_collection = cloudfree_collection.map(set_time_difference).sort('timediff')\n\nPrint some stats for the final collection to make sure everything looks alright.\n\ninfo = cloudfree_collection.getInfo()\nfor feature in info['features']:\n    s2datetime = datetime.fromtimestamp(feature['properties']['system:time_start']/1e3)\n    is2datetime = datetime.strptime(is2time, '%Y-%m-%dT%H:%M:%S')\n    timediff = s2datetime - is2datetime\n    timediff -= timedelta(microseconds=timediff.microseconds)\n    diffsign = 'before' if timediff < timedelta(0) else 'after'\n    print('%s --> along-track cloud probability: %5.1f %%, %s %7s ICESat-2' % (feature['properties']['GRANULE_ID'],\n              feature['properties']['ground_track_cloud_prob'],np.abs(timediff), diffsign))\n\n","type":"content","url":"/notebooks/visualization#sort-the-collection-by-time-difference-from-the-icesat-2-overpass","position":43},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Show the final image and ground track on the map","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#show-the-final-image-and-ground-track-on-the-map","position":44},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Show the final image and ground track on the map","lvl2":"Google Earth Engine"},"content":"\n\nfirst_image_rgb = cloudfree_collection.first().select('B4', 'B3', 'B2')\nMap = geemap.Map(layout=Layout(width='70%', max_height='450px'))\nMap.add_basemap('SATELLITE')\nMap.addLayer(first_image_rgb, vis_params, name='my image')\nMap.addLayer(gtx_feature,{'color': 'red'},'ground track')\nMap.centerObject(gtx_feature, zoom=12)\nMap\n\n","type":"content","url":"/notebooks/visualization#show-the-final-image-and-ground-track-on-the-map","position":45},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Download images from Earth Engine","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#download-images-from-earth-engine","position":46},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Download images from Earth Engine","lvl2":"Google Earth Engine"},"content":"We can use \n\n.getDownloadUrl() on an Earth Engine image.\n\nIt asks for a scale, which is just the pixel size in meters (10 m for Sentinel-2 visible bands). It also asks for the region we would like to export; here we use a \n\n.buffer around the center.This function can only be effectively used for small download jobs because there is a request size limit. Here, we only download a small region around the ground track, and convert the image to an 8-bit RGB composite to keep file size low. For larger jobs you should use [`Export.image.toDrive`](https://developers.google.com/earth-engine/apidocs/export-image-todrive):::\n\n# create a region around the ground track over which to download data\npoint_of_interest = ee.Geometry.Point(center_lon, center_lat)\nbuffer_around_center_meters = ground_track_length*0.52\nregion_of_interest = point_of_interest.buffer(buffer_around_center_meters)\n\n# make the image 8-bit RGB\ns2rgb = first_image_rgb.unitScale(ee.Number(0), ee.Number(10000)).clamp(0.0, 1.0).multiply(255.0).uint8()\n\n# get the download URL\ndownloadURL = s2rgb.getDownloadUrl({'name': 'mySatelliteImage',\n                                          'crs': s2rgb.projection().crs(),\n                                          'scale': 10,\n                                          'region': region_of_interest,\n                                          'filePerBand': False,\n                                          'format': 'GEO_TIFF'})\ndownloadURL\n\nWe can save the content of the download URL with the \n\nrequests library.\n\nresponse = requests.get(downloadURL)\nfilename = 'my-satellite-image.tif'\nwith open(filename, 'wb') as f:\n    f.write(response.content)\nprint('Downloaded %s' % filename)\n\n","type":"content","url":"/notebooks/visualization#download-images-from-earth-engine","position":47},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Open a GeoTIFF in rasterio","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#open-a-geotiff-in-rasterio","position":48},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Open a GeoTIFF in rasterio","lvl2":"Google Earth Engine"},"content":"Important\n\nNow that we have saved the file, we can open it locally with the \n\nrasterio library.\n\nmyImage = rio.open(filename)\nmyImage\n\n","type":"content","url":"/notebooks/visualization#open-a-geotiff-in-rasterio","position":49},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Plot a GeoTIFF in Matplotlib","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#plot-a-geotiff-in-matplotlib","position":50},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"Plot a GeoTIFF in Matplotlib","lvl2":"Google Earth Engine"},"content":"Now we can easily plot the image in a matplotlib figure, just using the \n\nrasterio.plot() module.\n\nfig, ax = plt.subplots(figsize=[4,4])\nrioplot.show(myImage, ax=ax);\n\n","type":"content","url":"/notebooks/visualization#plot-a-geotiff-in-matplotlib","position":51},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"transform the ground track into the image CRS","lvl2":"Google Earth Engine"},"type":"lvl3","url":"/notebooks/visualization#transform-the-ground-track-into-the-image-crs","position":52},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl3":"transform the ground track into the image CRS","lvl2":"Google Earth Engine"},"content":"Because our plot is now in the Antarctic Polar Stereographic Coordrinate Reference System, we need to project the coordinates of the ground track from lon/lat values. The \n\nrasterio.warp.transform function has us covered. From then on, it’s just plotting in Matplotlib.\n\ngtx_x, gtx_y = warp.transform(src_crs='epsg:4326', dst_crs=myImage.crs, xs=is2data.atl08.lon, ys=is2data.atl08.lat)\nax.plot(gtx_x, gtx_y, color='red', linestyle='-')\nax.axis('off')\n\ndisplay(fig)\n\n","type":"content","url":"/notebooks/visualization#transform-the-ground-track-into-the-image-crs","position":53},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/visualization#summary","position":54},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"Summary"},"content":"🎉 Congratulations! You’ve completed this tutorial and have seen how we can put ICESat-2 photon-level data into context using Google Earth Engine and the OpenAltimetry API.\n\nHint\n\nYou can explore a few more use cases for this code in \n\nthis notebook.\n\n","type":"content","url":"/notebooks/visualization#summary","position":55},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"References"},"type":"lvl2","url":"/notebooks/visualization#references","position":56},{"hierarchy":{"lvl1":"Interactive Visualizion with Open Altimetry & Google Earth Engine","lvl2":"References"},"content":"To further explore the topics of this tutorial see the following detailed documentation:\n\nThe OpenAltimetry API\n\nGoogle Earth Engine JavaScript and Python Guides\n\nTutorial on Sentinel-2 cloud masking with s2cloudless\n\nThe geemap package and \n\ntutorials","type":"content","url":"/notebooks/visualization#references","position":57}]}